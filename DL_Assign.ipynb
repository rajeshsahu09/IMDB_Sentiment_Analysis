{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuB0HM37teAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "rKlXTA5zfx20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run on **GPU**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_NV6CE-qtvGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Header Files"
      ]
    },
    {
      "metadata": {
        "id": "WE7OEcPOtzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4037ccUuFFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset and Visualise"
      ]
    },
    {
      "metadata": {
        "id": "EhWFepP2t3eA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_train.head()\n",
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Train_20K.csv\"\n",
        "df = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvAXyCoDaR3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "054a6205-4ae1-499e-a9f7-1a417ca2cf0a"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "metadata": {
        "id": "44YtF48vX24a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_1 = df[df['label']==1] # get only label == 1\n",
        "df_0 = df[df['label']==0] # get only label == 0\n",
        "\n",
        "range_1 = int(0.8*len(df_1))\n",
        "range_2 = int(0.8*len(df_0))\n",
        "\n",
        "np.random.seed(42) # fix the seed value\n",
        "df_1 = df_1.iloc[np.random.permutation(len(df_1))] # shuffled the data set of label==1\n",
        "df_0 = df_0.iloc[np.random.permutation(len(df_0))] # shuffled the data set of label==0\n",
        "\n",
        "temp_1_train = df_1.iloc[:range_1]\n",
        "temp_2_train = df_0.iloc[:range_2]\n",
        "df_train = pd.concat([temp_1_train, temp_2_train])\n",
        "\n",
        "temp_1_val = df_1.iloc[range_1:]\n",
        "temp_2_val = df_0.iloc[range_2:]\n",
        "df_val = pd.concat([temp_1_val, temp_2_val])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9FBTqABuRlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fccbcc1-6164-4dd8-c167-27e2e7c6293f"
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train.iloc[np.random.permutation(len(df_train))] # shuffled the data set of label==1\n",
        "df_val = df_val.iloc[np.random.permutation(len(df_val))] # shuffled the data set of label==1\n",
        "len(df_train), len(df_val)"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14399, 3600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "metadata": {
        "id": "0WFB1TtsxD3F",
        "colab_type": "code",
        "outputId": "5de83ddb-1ae9-4737-e0e0-dc1658e01565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_train[df_train['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_train[df_train['label']==1]))\n",
        "print('Number of movie reviews', len(df_train['label']))"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 7195\n",
            "Number of Positive movie reviews 7204\n",
            "Number of movie reviews 14399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYtzJk8r3lm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e26679c-cd85-4951-b505-2c86fa7166db"
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_val[df_val['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_val[df_val['label']==1]))\n",
        "print('Number of movie reviews', len(df_val['label']))"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 1799\n",
            "Number of Positive movie reviews 1801\n",
            "Number of movie reviews 3600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuZxOMpkQoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Test_5K.csv\"\n",
        "df_test = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVzhPcGGxf2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "u-8IR64TKH0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get Train Data"
      ]
    },
    {
      "metadata": {
        "id": "JprKnOXgxXkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_raw_text_reviews = df_train['text'].astype(str).tolist()\n",
        "train_text_labels = df_train['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwU4zROpKLdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "7TsL1ACWJ_3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_raw_text_reviews = df_val['text'].astype(str).tolist()\n",
        "val_text_labels = df_val['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YixDzEnXLZN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "metadata": {
        "id": "MQHaSpnJJ9eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_raw_text_reviews = df_test['text'].astype(str).tolist()\n",
        "test_text_labels = df_test['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui-q6WRqOrB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Cleaning the raw input data"
      ]
    },
    {
      "metadata": {
        "id": "8_4b4FmShb0u",
        "colab_type": "code",
        "outputId": "7befca1b-c662-48fe-c99c-df9c91e31c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Finding stop words\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3AxEhD_z1DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_document(doc):\n",
        "    # negative sense should not be eleminated + some short representation\n",
        "    CONTRACTIONS = {\"mayn't\":\"may not\", \"can't\":\"can not\", \"won't\":\"will not\", \"isn't\":\"is not\", \"amn't\":\"am not\",\\\n",
        "                  \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"couldn't\":\"could not\", \\\n",
        "                  \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\\\n",
        "                  \"i'll\":\"i will\", \"you'll\":\"you will\", \"they'll\":\"they will\",\\\n",
        "                  \"may've\":\"may have\", \"can've\":\"can have\", \"will've\":\"will have\", \"you've\":\"you have\", \\\n",
        "                  \"could've\":\"could have\", \"would've\":\"would have\", \"you've\":\"you have\", \"they\":\"they have\",\\\n",
        "                  \"i've\":\"i have\", \"you've\":\"you have\", \"we've\":\"we have\", \"there's\":\"there is\", \"i'm\":\"i am\",\\\n",
        "                  \"it's\":\"it is\", \"what's\":\"what is\", \"where's\":\"where is\", \"how's\":\"how is\", \"i'd\":\"i had\"}\n",
        "    punctuation = string.punctuation + \"\\n\\n\"\n",
        "    punc_replace = ''.join([' ' for s in punctuation]) # required for replacing punctuation with null ('')\n",
        "    doc_clean = doc.replace('-', ' ') # replace - with null str\n",
        "    doc_clean = (doc_clean.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "    doc_clean = doc_clean.replace('<br />', '') # replace <br /> with ''\n",
        "    doc_clean = doc_clean.replace(\"â€™\", \"'\") # replace <br /> with null str\n",
        "    doc_clean = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in doc_clean.split(' ')] # replacing some common short forms\n",
        "    doc_clean = \" \".join(doc_clean) # list to sentence of strings\n",
        "    doc_clean = re.sub(r'\\W +', ' ', doc_clean) # except [a-zA-Z0-9_]\n",
        "    doc_clean = re.sub(r'\\d+', ' ', doc_clean) # remove numbers [0-9]\n",
        "    trans_table = str.maketrans(punctuation, punc_replace); # replace punctuations with ' '\n",
        "    doc_clean = ' '.join([word.translate(trans_table) for word in doc_clean.split(' ')])\n",
        "    doc_clean = doc_clean.split(' ');\n",
        "    doc_clean = [word for word in doc_clean if len(word) > 0];\n",
        "    # removing the stopwords from a sentence\n",
        "    doc_clean = [word for word in doc_clean if not word in stop_words and word != 'not' and word != 'no']\n",
        "    return doc_clean;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSNuXUopzavX",
        "colab_type": "code",
        "outputId": "9c7a66c2-eb42-4a8f-a05a-0e223b197567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_reviews = [preprocess_document(review.lower()) for review in train_raw_text_reviews]\n",
        "print (train_text_reviews[len(train_text_reviews)-2])\n",
        "print (train_text_labels[len(train_text_labels)-2])"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['film', 'made', 'cast', 'home', 'town', 'remember', 'fuss', 'whole', 'hullabaloo', 'fact', 'molly', 'ringwald', 'town', 'storyline', 'essentially', 'years', 'film', 'laid', 'rest', 'without', 'finished', 'group', 'film', 'students', 'set', 'complete', 'dire', 'consequences', 'would', 'seem', 'someone', 'want', 'film', 'completed', 'storyline', 'flimsy', 'one', 'remember', 'comedy', 'therefore', 'taken', 'little', 'tounge', 'cheek', 'real', 'oomph', 'characters', 'mostly', 'transperant', 'little', 'info', 'recieve', 'care', 'seems', 'irrelevant', 'weird', 'hearing', 'kylie', 'accent', 'australian', 'nice', 'see', 'kid', 'went', 'school', 'starring', 'role', 'redeem', 'film', 'goodness', 'knows', 'makers', 'thought', 'would', 'get', 'molly', 'ringwald', 'perhaps', 'due', 'nature', 'film', 'sort', 'pays', 'homage', 'films', 'bad', 'horror', 'films', 'really', 'aussie', 'actor', 'would', 'done', 'fine', 'far', 'casting', 'concerned', 'lot', 'acting', 'seemed', 'constipated', 'kids', 'especially', 'two', 'main', 'chics', 'played', 'director', 'producer', 'looked', 'like', 'trying', 'act', 'never', 'good', 'look', 'also', 'shots', 'rough', 'feel', 'lit', 'perhaps', 'smooth', 'one', 'used', 'killer', 'lord', 'could', 'less', 'frightening', 'shock', 'factors', 'though', 'couple', 'gross', 'scenes', 'like', 'film', 'great', 'went', 'minutes', 'could', 'gone', 'less', 'perhaps', 'tightened', 'script', 'would', 'better', 'lot', 'characters', 'get', 'killed', 'real', 'build', 'getting', 'slayed', 'maybe', 'killed', 'less', 'people', 'actually', 'concentrated', 'scary', 'atmosphere', 'would', 'better', 'know', 'comedy', 'elements', 'funny', 'unbelieveable', 'funny', 'convinced', 'lm']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6psZ2jxNOoP",
        "colab_type": "code",
        "outputId": "23388605-b6c4-469e-9434-9c6c3d248fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_text_reviews = [preprocess_document(review.lower()) for review in val_raw_text_reviews]\n",
        "print (val_text_reviews[len(val_text_reviews)-2])\n",
        "print (val_text_labels[len(val_text_labels)-2])"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['like', 'streetcar', 'named', 'desire', 'also', 'directed', 'gadg', 'stage', 'screen', 'panic', 'streets', 'depicts', 'new', 'orleans', 'major', 'claim', 'fame', 'birthplace', 'jazz', 'even', 'rate', 'mention', 'richard', 'widmark', 'seventh', 'film', 'arguably', 'went', 'long', 'way', 'establishing', 'fine', 'actor', 'really', 'rather', 'merely', 'psychotic', 'killer', 'gadg', 'appears', 'uncredited', 'small', 'role', 'morgue', 'attendant', 'film', 'rich', 'talent', 'beginning', 'jack', 'palance', 'still', 'billed', 'walter', 'jack', 'palance', 'local', 'mr', 'big', 'followed', 'side', 'kick', 'zero', 'mostel', 'barbara', 'bel', 'geddes', 'emile', 'meyer', 'tommy', 'rettig', 'plus', 'rock', 'solid', 'ever', 'reliable', 'paul', 'douglas', 'cop', 'comes', 'round', 'doc', 'widmark', 'point', 'view', 'rewarding', 'movie', 'little', 'seen', 'catch']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REdaGj3VNOEX",
        "colab_type": "code",
        "outputId": "a9aa0617-7587-4fe1-cc15-3aa267c1afc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_text_reviews = [preprocess_document(review.lower()) for review in test_raw_text_reviews]\n",
        "print (test_text_reviews[len(test_text_reviews)-2])\n",
        "print (test_text_labels[len(test_text_labels)-2])"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['shining', 'know', 'weird', 'movie', 'movie', 'everyone', 'people', 'claim', 'like', 'horror', 'films', 'always', 'say', 'shining', 'terrific', 'film', 'stanley', 'kubrick', 'classic', 'vision', 'stephen', 'king', 'horror', 'tale', 'madness', 'blood', 'incredible', 'film', 'wither', 'seen', 'heard', 'know', 'lines', 'know', 'classic', 'images', 'could', 'forget', 'jack', 'johnny', 'could', 'forget', 'work', 'play', 'make', 'jack', 'dull', 'boy', 'could', 'forget', 'chilling', 'ending', 'film', 'unforgettable', 'honestly', 'opinion', 'kubrick', 'best', 'work', 'know', 'lot', 'argument', 'department', 'lot', 'people', 'say', 'space', 'odyssey', 'clockwork', 'orange', 'even', 'dr', 'strangelove', 'film', 'pioneered', 'film', 'making', 'shining', 'perfected', 'tale', 'isolation', 'madness', 'terrifying', 'images', 'ultimate', 'ghost', 'story', 'crawl', 'underneath', 'skin', 'jack', 'torrance', 'jack', 'son', 'danny', 'jack', 'wife', 'wendy', 'arrive', 'overlook', 'hotel', 'closing', 'day', 'elderly', 'african', 'american', 'chef', 'dick', 'hallorann', 'surprises', 'danny', 'speaking', 'telepathically', 'offering', 'ice', 'cream', 'explains', 'danny', 'grandmother', 'shared', 'gift', 'called', 'communication', 'shining', 'danny', 'asks', 'anything', 'afraid', 'hotel', 'particularly', 'room', 'dick', 'tells', 'danny', 'hotel', 'certain', 'shine', 'many', 'memories', 'good', 'advises', 'stay', 'room', 'circumstances', 'danny', 'curiosity', 'room', 'finally', 'gets', 'better', 'sees', 'room', 'opened', 'danny', 'shows', 'injured', 'visibly', 'traumatized', 'jack', 'tells', 'wendy', 'loves', 'family', 'seeing', 'wendy', 'thinks', 'jack', 'abusing', 'danny', 'jack', 'wanders', 'hotel', 'gold', 'room', 'meets', 'ghostly', 'bartender', 'named', 'lloyd', 'danny', 'starts', 'calling', 'word', 'redrum', 'frantically', 'scribbling', 'walls', 'goes', 'trance', 'withdraws', 'says', 'tony', 'imaginary', 'friend', 'jack', 'sabotages', 'hotel', 'radio', 'cutting', 'communication', 'outside', 'world', 'hallorann', 'received', 'danny', 'telepathic', 'cry', 'help', 'way', 'wendy', 'discovers', 'jack', 'typing', 'endless', 'pages', 'manuscript', 'repeating', 'work', 'play', 'makes', 'jack', 'dull', 'boy', 'formatted', 'various', 'ways', 'horrified', 'jack', 'threatens', 'knocks', 'unconscious', 'baseball', 'bat', 'locking', 'storage', 'locker', 'kitchen', 'jack', 'converses', 'grady', 'door', 'locker', 'unlocks', 'releasing', 'danny', 'written', 'redrum', 'lipstick', 'door', 'wendy', 'bedroom', 'looks', 'mirror', 'sees', 'murder', 'spelled', 'backwards', 'jack', 'picks', 'axe', 'begins', 'chop', 'door', 'leading', 'family', 'living', 'quarters', 'johnny', 'jack', 'legendary', 'image', 'born', 'shining', 'one', 'films', 'seriously', 'make', 'time', 'see', 'incredible', 'film', 'still', 'gives', 'nightmares', 'jack', 'nicholson', 'performance', 'timeless', 'unforgettable', 'one', 'also', 'feel', 'extremely', 'overlooked', 'shelley', 'duvall', 'scene', 'finding', 'jack', 'rant', 'work', 'incredible', 'look', 'horror', 'see', 'fear', 'face', 'realizing', 'husband', 'mad', 'also', 'another', 'incredible', 'scene', 'jack', 'sees', 'ghost', 'woman', 'bathtub', 'honestly', 'one', 'terrifying', 'scenes', 'horror', 'cinema', 'reason', 'film', 'well', 'known', 'film', 'perfection', 'simpsons', 'shown', 'films', 'film', 'forever', 'stay', 'see', 'trust']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydrqMX261kQ-",
        "colab_type": "code",
        "outputId": "7dc531c8-7ee0-45f5-e397-1f2a31f24817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "metadata": {
        "id": "xWfJK2HvwwQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_vocabulary(sentences):\n",
        "    # Build vocabulary\n",
        "    dictWordCount = {}\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] = 0 # initialising the dict value to zero\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] += 1 # updating the dictionary count\n",
        "    \n",
        "    temp = dictWordCount.copy()\n",
        "    for key, val in temp.items():\n",
        "        if(dictWordCount[key] <= 3):\n",
        "            del dictWordCount[key]\n",
        "    \n",
        "    # Mapping from index to word\n",
        "    vocabulary_inv = sorted(dictWordCount, key=dictWordCount.__getitem__, reverse=True)\n",
        "    \n",
        "    # Mapping from word to index\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return vocabulary, vocabulary_inv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKifaS85Dkap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating Tokens and Types"
      ]
    },
    {
      "metadata": {
        "id": "9cpQlJ3TytgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_ix, ix_to_word = build_vocabulary(train_text_reviews+val_text_reviews+test_text_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLBgxuf0xDB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0163fde-7095-4bd5-ce10-faa8dbbce652"
      },
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word_to_ix)\n",
        "ix_to_word[word_to_ix['kick']]=='kick', word_to_ix['kick'], VOCAB_SIZE"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 1829, 30941)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "metadata": {
        "id": "GMbWbZdr1reC",
        "colab_type": "code",
        "outputId": "9100dd20-c995-4a76-8288-64ca2491a66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "metadata": {
        "id": "yNUlKuJeNJEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "SqLOymKPLPug",
        "colab_type": "code",
        "outputId": "8f4d23f7-77ab-41b3-815c-7ee78c0cf194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable # Automatic gradients are calculated and back-propagated through the computational graph\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "metadata": {
        "id": "SaSwXEBh6565",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model Definition for the BOWClassifier"
      ]
    },
    {
      "metadata": {
        "id": "PM5I4GP6lFGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BOWClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BOWClassifier, self).__init__()\n",
        "        SEED = 42\n",
        "        torch.manual_seed(SEED)\n",
        "        torch.cuda.manual_seed(SEED)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size, hidden_size) # initialises weights and biases i2h\n",
        "        self.h2o = nn.Linear(hidden_size, output_size) # initialises weights and biases h2o\n",
        "#         self.i2o = nn.Linear(input_size, output_size) # initialises weights and biases i2o\n",
        "         \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "        x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8MGEFG3Mmww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialise Parameter and Model"
      ]
    },
    {
      "metadata": {
        "id": "MlMeX6577J9A",
        "colab_type": "code",
        "outputId": "258dba2e-7691-45d9-f79a-cd448d960c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "num_of_hidden = 50 # vary this for assignment\n",
        "num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "bow = BOWClassifier(num_of_input, num_of_hidden, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "bow.i2h, bow.h2o # desc network\n",
        "\n",
        "# bow.i2o"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Linear(in_features=30941, out_features=50, bias=True),\n",
              " Linear(in_features=50, out_features=1, bias=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 405
        }
      ]
    },
    {
      "metadata": {
        "id": "8fMMShAzMDjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### visualise the parameter"
      ]
    },
    {
      "metadata": {
        "id": "PRhDPFx87Ptm",
        "colab_type": "code",
        "outputId": "c998e0f6-894e-4b51-90af-795dc0db31da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "for param in bow.parameters(): # desc the parameter value\n",
        "    print(param,param.size())"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0043,  0.0047, -0.0013,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [-0.0031,  0.0019,  0.0001,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [-0.0038, -0.0053, -0.0017,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0009, -0.0011, -0.0037,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0020,  0.0033,  0.0048,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0004, -0.0015, -0.0051,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([-0.0050,  0.0047, -0.0024,  0.0015,  0.0033,  0.0050, -0.0008, -0.0021,\n",
            "         0.0017, -0.0021,  0.0005, -0.0007, -0.0007,  0.0035, -0.0002, -0.0056,\n",
            "         0.0037,  0.0045,  0.0033, -0.0004, -0.0002,  0.0042,  0.0002, -0.0034,\n",
            "        -0.0050, -0.0027, -0.0024,  0.0010,  0.0005,  0.0055, -0.0042,  0.0007,\n",
            "        -0.0037,  0.0035, -0.0021,  0.0048,  0.0030,  0.0056, -0.0033, -0.0032,\n",
            "        -0.0050,  0.0024,  0.0027,  0.0042,  0.0056,  0.0053,  0.0031, -0.0009,\n",
            "        -0.0027,  0.0048], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.0671,  0.0960, -0.0546,  0.1031,  0.0380,  0.0649, -0.0699, -0.0720,\n",
            "          0.1183, -0.1274,  0.0683,  0.0941, -0.1075,  0.1206,  0.1356, -0.1353,\n",
            "          0.0842, -0.1374,  0.0661, -0.0550, -0.0093, -0.1378, -0.0247,  0.0893,\n",
            "          0.0678,  0.0441,  0.1351, -0.1242,  0.0515,  0.0817,  0.0325, -0.1093,\n",
            "         -0.1132, -0.0610, -0.0209,  0.1063,  0.0614,  0.1316,  0.1052, -0.0124,\n",
            "         -0.0939, -0.1136,  0.0548,  0.0545, -0.0190, -0.1386,  0.1056,  0.1076,\n",
            "         -0.1033,  0.0996]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0331], device='cuda:0', requires_grad=True) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWqAwOAI7D54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "UZK9TAQI7Fbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix)).to('cuda:0') #, device=device) # make 1D vector of len = vocab size\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:            \n",
        "#             raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6p3T6oo_T99z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Store in input sentences torch vector"
      ]
    },
    {
      "metadata": {
        "id": "g6Tw8pD5NW2S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7xoiOiAyZN5",
        "colab_type": "code",
        "outputId": "875ac936-ba47-4de9-9ea9-b4e0cb96cc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# store the bag of word vectors for each sentences and wraping to tensor of torch type\n",
        "tic = time.time()\n",
        "train_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in train_text_reviews]\n",
        "num_train_data = len(train_text_reviews)\n",
        "\n",
        "val_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in val_text_reviews]\n",
        "num_val_data = len(val_text_reviews)\n",
        "toc = time.time()\n",
        "num_train_data, num_val_data, (toc-tic)"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14399, 3600, 89.1782169342041)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "metadata": {
        "id": "deO_hz8vT19u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation Accuracy Computation"
      ]
    },
    {
      "metadata": {
        "id": "cStQIVFfESWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_validation_accuracy(data, net):\n",
        "    sum_loss = 0\n",
        "    \n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    \n",
        "    for i, instance in enumerate(data):\n",
        "        label = val_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "        \n",
        "#         vec = Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') # wrap to tensor of torch type for instance\n",
        "        \n",
        "#         prob = net.forward(vec) # forward pass\n",
        "\n",
        "        prob = net.forward(instance)\n",
        "    \n",
        "        _class = 1 if prob.item() > 0.5 else 0 # sigmoid activated\n",
        "        \n",
        "        loss = loss_function(prob, label) # compute the loss\n",
        "        \n",
        "        sum_loss += float(loss.item())\n",
        "#         print (int(label), _class)        \n",
        "        if(int(label) == _class and _class == 1):\n",
        "            true_positive += 1\n",
        "            \n",
        "        if(int(label) == _class and _class == 0):\n",
        "            true_negative += 1\n",
        "        \n",
        "        if(_class == 1 and int(label) == 0):\n",
        "            false_positive += 1\n",
        "            \n",
        "        if(_class == 0 and int(label) == 1):\n",
        "            false_negative += 1\n",
        "    \n",
        "    \n",
        "    precision = float(true_positive) / (true_positive + false_positive)\n",
        "    recall = float(true_positive) / (true_positive + false_negative)\n",
        "    f_score = float(2)*true_positive / (2*true_positive + false_positive + false_negative)\n",
        "    \n",
        "    return float(sum_loss)/len(data), float(100)*(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative), precision, recall, f_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nw0OYbTzBwJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Loss function"
      ]
    },
    {
      "metadata": {
        "id": "PbQcwSIb96V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.BCELoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)#float(1)/epochs)#, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqYSLXcj11HJ",
        "colab_type": "code",
        "outputId": "d8c22a51-997f-4002-a9aa-a4b8223a8c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "metadata": {
        "id": "tuYAAQh2F6J8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "ad6MFVt7F5X8",
        "colab_type": "code",
        "outputId": "0548fcb3-17b8-4742-f6ed-71398235be20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5137
        }
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "epochs = 100\n",
        "# the training loop\n",
        "total_time = 0.0\n",
        "train_epoch_history = []\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "precision = []\n",
        "recall = []\n",
        "f_score = []\n",
        "prev_val_loss = 0\n",
        "flag = 1\n",
        "for e in range(epochs):\n",
        "    tic = time.time() # start the timer\n",
        "    correct = 0\n",
        "    cumulative_loss = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    for i, instance in enumerate(train_data): # train_text_reviews \n",
        "        # get the training data\n",
        "        label = train_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "        \n",
        "        bow.zero_grad() # reset the gradient for each instance\n",
        "        \n",
        "#         bow_vec = Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') # vector repesentation of input sentence\n",
        "        \n",
        "#         pred = bow.forward(bow_vec) # forward pass ==> computes predictied values (1 or 0)\n",
        "        pred = bow.forward(instance)\n",
        "    \n",
        "        loss = loss_function(pred, label) # compute the loss\n",
        "        loss.backward() # backprop the loss\n",
        "        opt.step() # performs parameter updation based on the current gradient\n",
        "        \n",
        "        cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "        \n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "        if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "            correct += 1\n",
        "    \n",
        "    train_loss = float(cumulative_loss)/num_train_data\n",
        "    train_accuracy = correct*float(100)/num_train_data\n",
        "    train_epoch_history.append(e+1)\n",
        "    train_loss_history.append(train_loss)\n",
        "    \n",
        "    val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "    val_loss_history.append(val_loss)\n",
        "    \n",
        "    precision.append(p)\n",
        "    recall.append(r)\n",
        "    f_score.append(f)\n",
        "    \n",
        "#     if(abs(prev_val_loss-val_loss) < 0.001): # early stop if nearly no change\n",
        "#         precision.append(p)\n",
        "#         recall.append(r)\n",
        "#         f_score.append(f)\n",
        "#         stop_bow = copy.deepcopy(bow)\n",
        "#         break\n",
        "    prev_val_loss = val_loss\n",
        "    \n",
        "    toc = time.time() # final time\n",
        "    total_time += (toc-tic)\n",
        "    \n",
        "    print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "    print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "#     if(val_loss > train_loss and flag == 1):\n",
        "#         more_bow = copy.deepcopy(bow)\n",
        "#         flag = 0"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 26.76s, Train Loss: 0.679297373, Train Accuracy: 65.50%\n",
            "[On Validation] ==> Precision: 0.712, Recall: 0.754, F-Score: 0.732, Val loss: 0.661329080, Val Accuracy: 72.42% Total Time: 26.76s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.638872922, Train Accuracy: 75.28%\n",
            "[On Validation] ==> Precision: 0.756, Recall: 0.795, F-Score: 0.775, Val loss: 0.618102632, Val Accuracy: 76.89% Total Time: 52.97s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.592058021, Train Accuracy: 78.58%\n",
            "[On Validation] ==> Precision: 0.779, Recall: 0.817, F-Score: 0.797, Val loss: 0.571868172, Val Accuracy: 79.22% Total Time: 79.17s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.544302700, Train Accuracy: 80.90%\n",
            "[On Validation] ==> Precision: 0.790, Recall: 0.830, F-Score: 0.810, Val loss: 0.527797175, Val Accuracy: 80.47% Total Time: 105.39s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.500748941, Train Accuracy: 82.33%\n",
            "[On Validation] ==> Precision: 0.799, Recall: 0.839, F-Score: 0.819, Val loss: 0.490272140, Val Accuracy: 81.39% Total Time: 131.62s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 26.33s, Train Loss: 0.464012645, Train Accuracy: 83.35%\n",
            "[On Validation] ==> Precision: 0.809, Recall: 0.846, F-Score: 0.827, Val loss: 0.460231487, Val Accuracy: 82.31% Total Time: 157.95s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 26.33s, Train Loss: 0.433817433, Train Accuracy: 84.24%\n",
            "[On Validation] ==> Precision: 0.813, Recall: 0.853, F-Score: 0.833, Val loss: 0.436520805, Val Accuracy: 82.83% Total Time: 184.28s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.408788017, Train Accuracy: 85.01%\n",
            "[On Validation] ==> Precision: 0.821, Recall: 0.859, F-Score: 0.839, Val loss: 0.417603191, Val Accuracy: 83.56% Total Time: 210.68s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.387576039, Train Accuracy: 85.74%\n",
            "[On Validation] ==> Precision: 0.824, Recall: 0.862, F-Score: 0.843, Val loss: 0.402198262, Val Accuracy: 83.89% Total Time: 236.92s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.369172648, Train Accuracy: 86.35%\n",
            "[On Validation] ==> Precision: 0.830, Recall: 0.868, F-Score: 0.849, Val loss: 0.389405566, Val Accuracy: 84.50% Total Time: 263.16s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 26.27s, Train Loss: 0.352903872, Train Accuracy: 86.99%\n",
            "[On Validation] ==> Precision: 0.834, Recall: 0.870, F-Score: 0.852, Val loss: 0.378602531, Val Accuracy: 84.83% Total Time: 289.43s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.338315722, Train Accuracy: 87.57%\n",
            "[On Validation] ==> Precision: 0.838, Recall: 0.869, F-Score: 0.853, Val loss: 0.369344465, Val Accuracy: 85.06% Total Time: 315.65s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.325094583, Train Accuracy: 88.03%\n",
            "[On Validation] ==> Precision: 0.843, Recall: 0.871, F-Score: 0.857, Val loss: 0.361347500, Val Accuracy: 85.42% Total Time: 341.91s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.313028213, Train Accuracy: 88.55%\n",
            "[On Validation] ==> Precision: 0.845, Recall: 0.872, F-Score: 0.858, Val loss: 0.354399026, Val Accuracy: 85.61% Total Time: 368.13s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.301956442, Train Accuracy: 89.07%\n",
            "[On Validation] ==> Precision: 0.849, Recall: 0.873, F-Score: 0.861, Val loss: 0.348330619, Val Accuracy: 85.86% Total Time: 394.37s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.291752214, Train Accuracy: 89.43%\n",
            "[On Validation] ==> Precision: 0.855, Recall: 0.874, F-Score: 0.864, Val loss: 0.343014338, Val Accuracy: 86.25% Total Time: 420.61s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.282309884, Train Accuracy: 89.77%\n",
            "[On Validation] ==> Precision: 0.855, Recall: 0.875, F-Score: 0.865, Val loss: 0.338351696, Val Accuracy: 86.31% Total Time: 446.81s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 26.51s, Train Loss: 0.273542484, Train Accuracy: 90.19%\n",
            "[On Validation] ==> Precision: 0.856, Recall: 0.875, F-Score: 0.865, Val loss: 0.334255563, Val Accuracy: 86.33% Total Time: 473.32s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.265376198, Train Accuracy: 90.64%\n",
            "[On Validation] ==> Precision: 0.858, Recall: 0.876, F-Score: 0.867, Val loss: 0.330651568, Val Accuracy: 86.53% Total Time: 499.55s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 26.42s, Train Loss: 0.257742912, Train Accuracy: 91.02%\n",
            "[On Validation] ==> Precision: 0.861, Recall: 0.877, F-Score: 0.869, Val loss: 0.327480370, Val Accuracy: 86.75% Total Time: 525.97s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 26.26s, Train Loss: 0.250585763, Train Accuracy: 91.33%\n",
            "[On Validation] ==> Precision: 0.862, Recall: 0.878, F-Score: 0.870, Val loss: 0.324691086, Val Accuracy: 86.86% Total Time: 552.23s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.243853380, Train Accuracy: 91.61%\n",
            "[On Validation] ==> Precision: 0.863, Recall: 0.879, F-Score: 0.871, Val loss: 0.322234508, Val Accuracy: 86.97% Total Time: 578.46s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.237501082, Train Accuracy: 91.84%\n",
            "[On Validation] ==> Precision: 0.866, Recall: 0.880, F-Score: 0.873, Val loss: 0.320069896, Val Accuracy: 87.17% Total Time: 604.68s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.231489886, Train Accuracy: 92.10%\n",
            "[On Validation] ==> Precision: 0.865, Recall: 0.882, F-Score: 0.873, Val loss: 0.318167040, Val Accuracy: 87.22% Total Time: 630.89s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.225786321, Train Accuracy: 92.33%\n",
            "[On Validation] ==> Precision: 0.866, Recall: 0.882, F-Score: 0.874, Val loss: 0.316497965, Val Accuracy: 87.31% Total Time: 657.13s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 26.26s, Train Loss: 0.220361219, Train Accuracy: 92.56%\n",
            "[On Validation] ==> Precision: 0.867, Recall: 0.884, F-Score: 0.875, Val loss: 0.315039517, Val Accuracy: 87.42% Total Time: 683.38s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.215188355, Train Accuracy: 92.78%\n",
            "[On Validation] ==> Precision: 0.868, Recall: 0.885, F-Score: 0.876, Val loss: 0.313767145, Val Accuracy: 87.47% Total Time: 709.63s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.210245365, Train Accuracy: 92.98%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.885, F-Score: 0.878, Val loss: 0.312663417, Val Accuracy: 87.72% Total Time: 735.85s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.205512924, Train Accuracy: 93.17%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.886, F-Score: 0.879, Val loss: 0.311712320, Val Accuracy: 87.81% Total Time: 762.07s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 26.52s, Train Loss: 0.200973498, Train Accuracy: 93.31%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.887, F-Score: 0.880, Val loss: 0.310899788, Val Accuracy: 87.89% Total Time: 788.59s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.196612053, Train Accuracy: 93.52%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.310212344, Val Accuracy: 87.94% Total Time: 814.81s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 26.41s, Train Loss: 0.192415325, Train Accuracy: 93.69%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.309642284, Val Accuracy: 88.08% Total Time: 841.22s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.188372243, Train Accuracy: 93.91%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.888, F-Score: 0.882, Val loss: 0.309180433, Val Accuracy: 88.06% Total Time: 867.41s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.184472276, Train Accuracy: 94.03%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.883, Val loss: 0.308819540, Val Accuracy: 88.17% Total Time: 893.63s\n",
            "Epoch 35/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.180706151, Train Accuracy: 94.17%\n",
            "[On Validation] ==> Precision: 0.877, Recall: 0.891, F-Score: 0.884, Val loss: 0.308551417, Val Accuracy: 88.28% Total Time: 919.81s\n",
            "Epoch 36/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.177065644, Train Accuracy: 94.34%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.891, F-Score: 0.883, Val loss: 0.308368647, Val Accuracy: 88.17% Total Time: 946.02s\n",
            "Epoch 37/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.173542993, Train Accuracy: 94.48%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308267432, Val Accuracy: 88.08% Total Time: 972.21s\n",
            "Epoch 38/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.170131476, Train Accuracy: 94.63%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308240262, Val Accuracy: 88.08% Total Time: 998.41s\n",
            "Epoch 39/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.166825024, Train Accuracy: 94.83%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.308284789, Val Accuracy: 88.06% Total Time: 1024.62s\n",
            "Epoch 40/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.163618183, Train Accuracy: 94.96%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.308394902, Val Accuracy: 88.06% Total Time: 1050.82s\n",
            "Epoch 41/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.160505985, Train Accuracy: 95.06%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.889, F-Score: 0.882, Val loss: 0.308566579, Val Accuracy: 88.08% Total Time: 1077.06s\n",
            "Epoch 42/100\n",
            "[On Training] ==> Time: 26.51s, Train Loss: 0.157483689, Train Accuracy: 95.21%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308796396, Val Accuracy: 88.08% Total Time: 1103.57s\n",
            "Epoch 43/100\n",
            "[On Training] ==> Time: 26.41s, Train Loss: 0.154547107, Train Accuracy: 95.37%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.882, Val loss: 0.309080255, Val Accuracy: 88.14% Total Time: 1129.98s\n",
            "Epoch 44/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.151692116, Train Accuracy: 95.49%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.882, Val loss: 0.309414810, Val Accuracy: 88.11% Total Time: 1156.16s\n",
            "Epoch 45/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.148915068, Train Accuracy: 95.63%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.309796255, Val Accuracy: 88.06% Total Time: 1182.38s\n",
            "Epoch 46/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.146212468, Train Accuracy: 95.71%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.310221073, Val Accuracy: 88.08% Total Time: 1208.56s\n",
            "Epoch 47/100\n",
            "[On Training] ==> Time: 26.16s, Train Loss: 0.143581031, Train Accuracy: 95.78%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.310686921, Val Accuracy: 88.06% Total Time: 1234.72s\n",
            "Epoch 48/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.141017880, Train Accuracy: 95.87%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.891, F-Score: 0.883, Val loss: 0.311190352, Val Accuracy: 88.14% Total Time: 1260.92s\n",
            "Epoch 49/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.138520145, Train Accuracy: 96.00%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.311729762, Val Accuracy: 88.06% Total Time: 1287.11s\n",
            "Epoch 50/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.136085344, Train Accuracy: 96.11%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.892, F-Score: 0.883, Val loss: 0.312302100, Val Accuracy: 88.19% Total Time: 1313.29s\n",
            "Epoch 51/100\n",
            "[On Training] ==> Time: 26.17s, Train Loss: 0.133710914, Train Accuracy: 96.26%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.892, F-Score: 0.883, Val loss: 0.312904588, Val Accuracy: 88.22% Total Time: 1339.46s\n",
            "Epoch 52/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.131394590, Train Accuracy: 96.36%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.313536126, Val Accuracy: 88.19% Total Time: 1365.66s\n",
            "Epoch 53/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.129134130, Train Accuracy: 96.49%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.314195512, Val Accuracy: 88.19% Total Time: 1391.85s\n",
            "Epoch 54/100\n",
            "[On Training] ==> Time: 26.53s, Train Loss: 0.126927579, Train Accuracy: 96.57%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.893, F-Score: 0.884, Val loss: 0.314879142, Val Accuracy: 88.28% Total Time: 1418.37s\n",
            "Epoch 55/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.124773108, Train Accuracy: 96.62%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.895, F-Score: 0.884, Val loss: 0.315587096, Val Accuracy: 88.28% Total Time: 1444.77s\n",
            "Epoch 56/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.122668817, Train Accuracy: 96.72%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.895, F-Score: 0.884, Val loss: 0.316317065, Val Accuracy: 88.28% Total Time: 1470.97s\n",
            "Epoch 57/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.120613084, Train Accuracy: 96.81%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.895, F-Score: 0.884, Val loss: 0.317067978, Val Accuracy: 88.31% Total Time: 1497.16s\n",
            "Epoch 58/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.118604452, Train Accuracy: 96.90%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.894, F-Score: 0.884, Val loss: 0.317838886, Val Accuracy: 88.22% Total Time: 1523.36s\n",
            "Epoch 59/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.116641392, Train Accuracy: 96.98%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.318628304, Val Accuracy: 88.22% Total Time: 1549.58s\n",
            "Epoch 60/100\n",
            "[On Training] ==> Time: 26.17s, Train Loss: 0.114722430, Train Accuracy: 97.07%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.319436472, Val Accuracy: 88.25% Total Time: 1575.75s\n",
            "Epoch 61/100\n",
            "[On Training] ==> Time: 26.14s, Train Loss: 0.112846568, Train Accuracy: 97.21%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.320260490, Val Accuracy: 88.25% Total Time: 1601.89s\n",
            "Epoch 62/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.111012556, Train Accuracy: 97.26%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.321100089, Val Accuracy: 88.19% Total Time: 1628.07s\n",
            "Epoch 63/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.109219486, Train Accuracy: 97.32%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.321956148, Val Accuracy: 88.19% Total Time: 1654.27s\n",
            "Epoch 64/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.107466255, Train Accuracy: 97.40%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.322825972, Val Accuracy: 88.06% Total Time: 1680.51s\n",
            "Epoch 65/100\n",
            "[On Training] ==> Time: 26.16s, Train Loss: 0.105751793, Train Accuracy: 97.49%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.891, F-Score: 0.882, Val loss: 0.323710920, Val Accuracy: 88.08% Total Time: 1706.67s\n",
            "Epoch 66/100\n",
            "[On Training] ==> Time: 26.47s, Train Loss: 0.104075409, Train Accuracy: 97.58%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.324609001, Val Accuracy: 88.03% Total Time: 1733.14s\n",
            "Epoch 67/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.102435752, Train Accuracy: 97.62%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.325516345, Val Accuracy: 88.06% Total Time: 1759.54s\n",
            "Epoch 68/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.100831526, Train Accuracy: 97.67%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.326436538, Val Accuracy: 88.00% Total Time: 1785.73s\n",
            "Epoch 69/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.099261922, Train Accuracy: 97.70%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.327367045, Val Accuracy: 87.97% Total Time: 1811.95s\n",
            "Epoch 70/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.097725976, Train Accuracy: 97.78%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.328301827, Val Accuracy: 87.97% Total Time: 1838.13s\n",
            "Epoch 71/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.096222205, Train Accuracy: 97.83%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.329249859, Val Accuracy: 87.97% Total Time: 1864.34s\n",
            "Epoch 72/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.094750187, Train Accuracy: 97.88%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.330205498, Val Accuracy: 87.94% Total Time: 1890.56s\n",
            "Epoch 73/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.093308947, Train Accuracy: 97.91%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.331164432, Val Accuracy: 87.97% Total Time: 1916.80s\n",
            "Epoch 74/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.091897275, Train Accuracy: 98.01%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.332132887, Val Accuracy: 88.00% Total Time: 1942.99s\n",
            "Epoch 75/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.090514228, Train Accuracy: 98.03%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.333107599, Val Accuracy: 88.03% Total Time: 1969.21s\n",
            "Epoch 76/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.089159492, Train Accuracy: 98.09%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.334085990, Val Accuracy: 88.03% Total Time: 1995.43s\n",
            "Epoch 77/100\n",
            "[On Training] ==> Time: 26.29s, Train Loss: 0.087831673, Train Accuracy: 98.15%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.335069037, Val Accuracy: 88.03% Total Time: 2021.72s\n",
            "Epoch 78/100\n",
            "[On Training] ==> Time: 26.54s, Train Loss: 0.086529938, Train Accuracy: 98.17%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.336058138, Val Accuracy: 87.97% Total Time: 2048.27s\n",
            "Epoch 79/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.085254390, Train Accuracy: 98.21%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.337053001, Val Accuracy: 87.97% Total Time: 2074.48s\n",
            "Epoch 80/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.084003299, Train Accuracy: 98.24%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.338050195, Val Accuracy: 88.00% Total Time: 2100.68s\n",
            "Epoch 81/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.082776687, Train Accuracy: 98.29%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.339053772, Val Accuracy: 88.03% Total Time: 2126.89s\n",
            "Epoch 82/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.081573685, Train Accuracy: 98.33%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.340057327, Val Accuracy: 88.00% Total Time: 2153.14s\n",
            "Epoch 83/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.080393474, Train Accuracy: 98.38%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.341066413, Val Accuracy: 88.00% Total Time: 2179.33s\n",
            "Epoch 84/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.079235320, Train Accuracy: 98.41%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.342081223, Val Accuracy: 87.94% Total Time: 2205.52s\n",
            "Epoch 85/100\n",
            "[On Training] ==> Time: 26.27s, Train Loss: 0.078099612, Train Accuracy: 98.44%\n",
            "[On Validation] ==> Precision: 0.871, Recall: 0.890, F-Score: 0.880, Val loss: 0.343093368, Val Accuracy: 87.89% Total Time: 2231.79s\n",
            "Epoch 86/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.076984337, Train Accuracy: 98.47%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.344113503, Val Accuracy: 88.03% Total Time: 2258.03s\n",
            "Epoch 87/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.075890145, Train Accuracy: 98.50%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.345134929, Val Accuracy: 88.03% Total Time: 2284.27s\n",
            "Epoch 88/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.074816057, Train Accuracy: 98.53%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.346159078, Val Accuracy: 88.03% Total Time: 2310.47s\n",
            "Epoch 89/100\n",
            "[On Training] ==> Time: 26.38s, Train Loss: 0.073761446, Train Accuracy: 98.55%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.347186013, Val Accuracy: 88.03% Total Time: 2336.85s\n",
            "Epoch 90/100\n",
            "[On Training] ==> Time: 26.44s, Train Loss: 0.072726029, Train Accuracy: 98.57%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.348216161, Val Accuracy: 87.97% Total Time: 2363.30s\n",
            "Epoch 91/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.071709603, Train Accuracy: 98.62%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.349248491, Val Accuracy: 88.00% Total Time: 2389.54s\n",
            "Epoch 92/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.070711397, Train Accuracy: 98.66%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.881, Val loss: 0.350285411, Val Accuracy: 87.94% Total Time: 2415.73s\n",
            "Epoch 93/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.069731427, Train Accuracy: 98.69%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.881, Val loss: 0.351320800, Val Accuracy: 87.94% Total Time: 2441.91s\n",
            "Epoch 94/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.068768684, Train Accuracy: 98.75%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.352363629, Val Accuracy: 87.89% Total Time: 2468.13s\n",
            "Epoch 95/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.067824077, Train Accuracy: 98.76%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.353403394, Val Accuracy: 87.89% Total Time: 2494.31s\n",
            "Epoch 96/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.066895709, Train Accuracy: 98.80%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.354449597, Val Accuracy: 87.86% Total Time: 2520.55s\n",
            "Epoch 97/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.065984506, Train Accuracy: 98.83%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.355497148, Val Accuracy: 87.89% Total Time: 2546.75s\n",
            "Epoch 98/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.065089669, Train Accuracy: 98.86%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.880, Val loss: 0.356547937, Val Accuracy: 87.92% Total Time: 2572.94s\n",
            "Epoch 99/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.064210602, Train Accuracy: 98.90%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.357605798, Val Accuracy: 87.92% Total Time: 2599.12s\n",
            "Epoch 100/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.063348536, Train Accuracy: 98.92%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.358660772, Val Accuracy: 87.92% Total Time: 2625.35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RsIuCobJmOel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28da51a8-e262-490b-f7a0-d0f971dd7586"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "metadata": {
        "id": "FDUyFfwmXSew",
        "colab_type": "code",
        "outputId": "ae520915-6918-45bd-fd8f-fffa5e100455",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(\"Image\")\n",
        "plt.title(\"Loss vs Epoch\")\n",
        "val_loss_history_plt =  [float(i)/sum(val_loss_history) for i in val_loss_history] # normalised between 0-1\n",
        "train_loss_history_plt =  [float(i)/sum(train_loss_history) for i in train_loss_history] # normalised between 0-1\n",
        "f_score_plt = [float(i)/sum(f_score) for i in f_score] # normalised between 0-1\n",
        "plt.plot(val_loss_history_plt, c=\"red\", label=\"Validation Loss\")\n",
        "plt.plot(train_loss_history_plt, c=\"blue\", label = \"Training Loss\")\n",
        "plt.plot(f_score_plt, c=\"green\", label = \"F-Score\")\n",
        "plt.legend()"
      ],
      "execution_count": 424,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29bfc39278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 424
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gPf_k4VNuaDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1428
        },
        "outputId": "3e42aef5-61c0-48f3-b750-d9683cb166b6"
      },
      "cell_type": "code",
      "source": [
        "# for param in bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())\n",
        "# print ()\n",
        "# for param in stop_bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())\n",
        "# print()\n",
        "# for param in more_bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())    "
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0251,  0.0234,  0.0139,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0283,  0.0236,  0.0196,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0124,  0.0111,  0.0069,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0349,  0.0284,  0.0231,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0321,  0.0285,  0.0222,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0331,  0.0223,  0.0154,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0297,  0.0355,  0.0179,  0.0379,  0.0151,  0.0306,  0.0269,  0.0353,\n",
            "         0.0493,  0.0564,  0.0189,  0.0347,  0.0497,  0.0484,  0.0505,  0.0574,\n",
            "         0.0327,  0.0662,  0.0271,  0.0245, -0.0009,  0.0664,  0.0100,  0.0288,\n",
            "         0.0213,  0.0148,  0.0469,  0.0575,  0.0158,  0.0303, -0.0020,  0.0497,\n",
            "         0.0514,  0.0325,  0.0085,  0.0433,  0.0248,  0.0517,  0.0318,  0.0022,\n",
            "         0.0388,  0.0528,  0.0238,  0.0229,  0.0087,  0.0645,  0.0423,  0.0407,\n",
            "         0.0468,  0.0392], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.3265,  0.3968, -0.1680,  0.4423,  0.1295,  0.3108, -0.2848, -0.3566,\n",
            "          0.5830, -0.5779,  0.2131,  0.4034, -0.5115,  0.5584,  0.5957, -0.6153,\n",
            "          0.3476, -0.6775,  0.2956, -0.2547, -0.0066, -0.6576, -0.0947,  0.3579,\n",
            "          0.2948,  0.1862,  0.5887, -0.5654,  0.1805,  0.2991,  0.0412, -0.5288,\n",
            "         -0.5669, -0.2938, -0.0771,  0.4797,  0.2796,  0.5872,  0.4137, -0.0401,\n",
            "         -0.4411, -0.5464,  0.2503,  0.2109, -0.0322, -0.6095,  0.4870,  0.4859,\n",
            "         -0.5027,  0.4415]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0347], device='cuda:0', requires_grad=True) torch.Size([1])\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.0251,  0.0234,  0.0139,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0283,  0.0236,  0.0196,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0124,  0.0111,  0.0069,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0349,  0.0284,  0.0231,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0321,  0.0285,  0.0222,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0331,  0.0223,  0.0154,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0297,  0.0355,  0.0179,  0.0379,  0.0151,  0.0306,  0.0269,  0.0353,\n",
            "         0.0493,  0.0564,  0.0189,  0.0347,  0.0497,  0.0484,  0.0505,  0.0574,\n",
            "         0.0327,  0.0662,  0.0271,  0.0245, -0.0009,  0.0664,  0.0100,  0.0288,\n",
            "         0.0213,  0.0148,  0.0469,  0.0575,  0.0158,  0.0303, -0.0020,  0.0497,\n",
            "         0.0514,  0.0325,  0.0085,  0.0433,  0.0248,  0.0517,  0.0318,  0.0022,\n",
            "         0.0388,  0.0528,  0.0238,  0.0229,  0.0087,  0.0645,  0.0423,  0.0407,\n",
            "         0.0468,  0.0392], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.3265,  0.3968, -0.1680,  0.4423,  0.1295,  0.3108, -0.2848, -0.3566,\n",
            "          0.5830, -0.5779,  0.2131,  0.4034, -0.5115,  0.5584,  0.5957, -0.6153,\n",
            "          0.3476, -0.6775,  0.2956, -0.2547, -0.0066, -0.6576, -0.0947,  0.3579,\n",
            "          0.2948,  0.1862,  0.5887, -0.5654,  0.1805,  0.2991,  0.0412, -0.5288,\n",
            "         -0.5669, -0.2938, -0.0771,  0.4797,  0.2796,  0.5872,  0.4137, -0.0401,\n",
            "         -0.4411, -0.5464,  0.2503,  0.2109, -0.0322, -0.6095,  0.4870,  0.4859,\n",
            "         -0.5027,  0.4415]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0347], device='cuda:0', requires_grad=True) torch.Size([1])\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.0224,  0.0190,  0.0079,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0186,  0.0160,  0.0158,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0091,  0.0072,  0.0049,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0241,  0.0203,  0.0187,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0281,  0.0233,  0.0154,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0217,  0.0171,  0.0144,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0122,  0.0231,  0.0082,  0.0242,  0.0107,  0.0208,  0.0134,  0.0167,\n",
            "         0.0309,  0.0271,  0.0114,  0.0204,  0.0251,  0.0314,  0.0312,  0.0259,\n",
            "         0.0217,  0.0345,  0.0183,  0.0121, -0.0009,  0.0355,  0.0046,  0.0164,\n",
            "         0.0111,  0.0075,  0.0286,  0.0279,  0.0098,  0.0208, -0.0039,  0.0248,\n",
            "         0.0236,  0.0172,  0.0030,  0.0280,  0.0162,  0.0343,  0.0191, -0.0013,\n",
            "         0.0170,  0.0272,  0.0163,  0.0157,  0.0065,  0.0338,  0.0281,  0.0254,\n",
            "         0.0215,  0.0261], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.1625,  0.2001, -0.0881,  0.2204,  0.0656,  0.1546, -0.1428, -0.1765,\n",
            "          0.2900, -0.2910,  0.1096,  0.2006, -0.2553,  0.2776,  0.2985, -0.3062,\n",
            "          0.1739, -0.3365,  0.1486, -0.1321, -0.0063, -0.3298, -0.0471,  0.1794,\n",
            "          0.1481,  0.0928,  0.2952, -0.2823,  0.0931,  0.1492,  0.0338, -0.2638,\n",
            "         -0.2823, -0.1496, -0.0396,  0.2407,  0.1393,  0.2916,  0.2089, -0.0208,\n",
            "         -0.2183, -0.2727,  0.1239,  0.1076, -0.0202, -0.3057,  0.2407,  0.2449,\n",
            "         -0.2526,  0.2187]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0463], device='cuda:0', requires_grad=True) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fkYBaktsF-sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in test_text_reviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffYv5PAmjyp-",
        "colab_type": "code",
        "outputId": "605b4a5e-9190-49a2-8831-b56192625bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "correct = 0\n",
        "tic = time.time()\n",
        "for i, instance in enumerate(data):\n",
        "    label = test_text_labels[i]\n",
        "    pred = bow.forward(instance)\n",
        "#     pred = more_bow.forward(instance)\n",
        "#     pred = stop_bow.forward(instance)\n",
        "    pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "    \n",
        "    if(int(label) == pred_class):\n",
        "        correct += 1\n",
        "toc = time.time()\n",
        "print(\"Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data)))"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n",
            "Time: 2.3922858238220215, Test Accuracy: 88.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uHAvtGWbudLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cf9aaa61-26d3-4e0e-8dee-a38eb47bcbb1"
      },
      "cell_type": "code",
      "source": [
        "torch.save(bow, 'Task1A.mdl')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"Task1A.mdl\")"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zz5PwYjVudEk",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d5ccd8bf-7d91-4ef7-b37b-e4a39ebd842b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()"
      ],
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79bed7f2-c754-4385-837e-e16ff1f7ab53\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-79bed7f2-c754-4385-837e-e16ff1f7ab53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Task1A.mdl to Task1A (1).mdl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29twCfxpuc8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_model_ = torch.load(io.BytesIO(temp_test['Task1A.mdl']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ixy30WkrH3_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "38c445b3-70f5-45b7-f5fc-a98fd76df239"
      },
      "cell_type": "code",
      "source": [
        "for params in _model_.parameters():\n",
        "    print (params)"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0261,  0.0221,  0.0165,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0266,  0.0270,  0.0171,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0152,  0.0111,  0.0046,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0340,  0.0254,  0.0204,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0323,  0.0227,  0.0225,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0352,  0.0154,  0.0106,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0355,  0.0442,  0.0223,  0.0447,  0.0201,  0.0354,  0.0306,  0.0417,\n",
            "         0.0565,  0.0647,  0.0215,  0.0432,  0.0580,  0.0563,  0.0606,  0.0675,\n",
            "         0.0388,  0.0760,  0.0272,  0.0324, -0.0007,  0.0737,  0.0119,  0.0335,\n",
            "         0.0316,  0.0209,  0.0557,  0.0693,  0.0163,  0.0389,  0.0016,  0.0559,\n",
            "         0.0609,  0.0391,  0.0114,  0.0536,  0.0292,  0.0587,  0.0381,  0.0036,\n",
            "         0.0454,  0.0594,  0.0273,  0.0265,  0.0096,  0.0742,  0.0530,  0.0476,\n",
            "         0.0559,  0.0517], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.5615,  0.6852, -0.2882,  0.7626,  0.2254,  0.5352, -0.4892, -0.6133,\n",
            "          1.0005, -0.9908,  0.3702,  0.7004, -0.8739,  0.9629,  1.0271, -1.0576,\n",
            "          0.6003, -1.1655,  0.5059, -0.4314, -0.0098, -1.1250, -0.1615,  0.6162,\n",
            "          0.5057,  0.3194,  1.0106, -0.9704,  0.3083,  0.5165,  0.0655, -0.9062,\n",
            "         -0.9707, -0.5013, -0.1331,  0.8262,  0.4815,  1.0114,  0.7084, -0.0698,\n",
            "         -0.7600, -0.9379,  0.4303,  0.3599, -0.0572, -1.0431,  0.8399,  0.8347,\n",
            "         -0.8567,  0.7620]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0355], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ub0HKgL8H37z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCraW41hH32S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mhftDt1DH3x6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE_TcX1KH3tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T60wqxmoH3Zl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}