{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuB0HM37teAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "_NV6CE-qtvGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Header Files"
      ]
    },
    {
      "metadata": {
        "id": "WE7OEcPOtzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4037ccUuFFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset and Visualise"
      ]
    },
    {
      "metadata": {
        "id": "EhWFepP2t3eA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_train.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/Train_20K.csv?token=As1EmK3cgssTM5lkrm31LWISZk7YQ2ITks5coFj-wA%3D%3D\"\n",
        "df_train = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9FBTqABuRlO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_val = pd.read_csv(io.StringIO(uploaded['check.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_val.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/check.csv?token=As1EmDvPNu0R2vby65Nq9jSud-I0NolGks5coFk0wA%3D%3D\"\n",
        "df_val = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuZxOMpkQoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_test.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/Test_5K.csv?token=As1EmMTDAQKlqKHodzPF2OQanZ4-wWWLks5coFlLwA%3D%3D\"\n",
        "df_test = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WFB1TtsxD3F",
        "colab_type": "code",
        "outputId": "323b4fc7-ea84-46f0-d09e-b13940485ab9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_train[df_train['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_train[df_train['label']==1]))\n",
        "print('Number of movie reviews', len(df_train['label']))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n",
            "Number of movie reviews 17999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TVzhPcGGxf2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "u-8IR64TKH0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get Train"
      ]
    },
    {
      "metadata": {
        "id": "JprKnOXgxXkE",
        "colab_type": "code",
        "outputId": "40a055f7-188d-4179-906c-d0f7a3723c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_raw_text_reviews = df_train['text'].astype(str).tolist()\n",
        "len(train_raw_text_reviews), train_raw_text_reviews[-2]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999,\n",
              " 'Anyone notice that Tommy only has 3 facial expressions.<br /><br />1. The angry eyes look he gives every enemy. 2. The holding of the hands to face, mouth agape and frightened eyes. 3. The smiling Tommy Turnbull.<br /><br />I have to say that i pretty much hate this show, i don\\'t watch it but it\\'s like Code Lyoko, we\\'ve all watched at least one, i must say that this show is borderline racist, uninteresting and pointless.<br /><br />every episode ends with robotboy winning, except for one exception when robotboy basically let this overly geeky freakazoid fly away on a jetpack.<br /><br />The jokes are pretty crude too, i think it\\'s mostly people saying the word \"Suck\" or farting, i think the bullies of the show are quite shocking too.<br /><br />Isn\\'t there one that hides a bowling ball under his hate, and the other uses a chain, for god sake, what kind of school is he going to. Not to mention his older brother, who is borderline psychopathic and has no other character qualities.<br /><br />The whole show i feel is ripping off megas XLR and Fosters. Like you could say the trio of coop, jamie and Kiva, as well as Robotboy being similar to Megas where he beats everyone no matter what the odds and he\\'s free spirited despite being a robot.<br /><br />There is simply no appeal to this show, i\\'m surprised that it\\'s still running.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "6pyMLy0NyHVx",
        "colab_type": "code",
        "outputId": "800e9a9c-36d7-4fe1-9981-e6151a100419",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_labels = df_train['label'].astype(int)\n",
        "len(train_text_labels), train_text_labels[len(train_text_labels)-2]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "TwU4zROpKLdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Validation"
      ]
    },
    {
      "metadata": {
        "id": "7TsL1ACWJ_3V",
        "colab_type": "code",
        "outputId": "46ffc6c4-d2d4-468a-84f7-eafd92faacda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_raw_text_reviews = df_val['text'].astype(str).tolist()\n",
        "len(val_raw_text_reviews), val_raw_text_reviews[-2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(499,\n",
              " \"This movie starts out brisk, has some slow moments in the middle, but generally moves along well, has a few very good moments, then peters out at the end of Act 3. I was able to get to see this in LA premieres 2 times (with 2 different endings). Jason Lee is a star, but he is not tomorrows leading man. He is humorous and holds his own, but he is better served as a supporting actor. Julia Stiles does 'ok' in a comedy role, new for her, but she doesn't 'steal' this movie, the way a star of her caliber should. For an actress who has so much potential(10 Things, Save the Last Dance, O), it is hard to watch her continue to do roles that are so 'average', and then not have her take the role and run away with the movie (like Daniel Day-Lewis did in 'Gangs'). Selma Blair is a good young actress as well, and does an 'ok' job. I didn't expect an academy award performance from her, and she didn't deliver one, but, her performance was adequate. Chris Koch delivers another film that is 'above average'. Perhaps the problem lies in the script more than anything else. I 'did' like this movie! But, it is not a movie where you walk away and say...'that was great!'...This 'story' has been done so many times before and there was just not much new here. The rehearsal dinner scene was probably the best in the movie, and Larry Miller gives an incredible performance in a supporting role (he could be the best surprise of the film). If you want to go see a movie that will make you laugh a few times, and have an enjoyable evening, I can still recommend this film, but unless they have changed the ending...again...leave during the church scene, or you will surely be disappointed.\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "nXcL1jBEJ-0w",
        "colab_type": "code",
        "outputId": "d7593668-4e21-4795-95dc-0b6efd9dba4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "val_text_labels = df_val['label'].astype(int)\n",
        "len(val_text_labels), val_text_labels[len(val_text_labels)-2]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(499, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "YixDzEnXLZN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Test"
      ]
    },
    {
      "metadata": {
        "id": "MQHaSpnJJ9eT",
        "colab_type": "code",
        "outputId": "a197f789-154f-4a4f-d7ec-04eabf0676a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_raw_text_reviews = df_test['text'].astype(str).tolist()\n",
        "len(test_raw_text_reviews), test_raw_text_reviews[-2]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000,\n",
              " 'The Shining, you know what\\'s weird about this movie? This is the movie that everyone, for people who claim to not like horror films, will always say that The Shining is a terrific film. This is Stanley Kubrick\\'s classic vision of Stephen King\\'s horror tale of madness and blood. This is just an incredible film and wither you have seen it or not, you have heard of it, know a few lines from it, and know some of the classic images. Who could forget Jack\\'s \"Here\\'s Johnny!\"? Who could forget \"All Work and No Play Make Jack a Dull Boy\"? Who could forget that chilling ending? This is the film that is unforgettable and honestly in my opinion is Kubrick\\'s best work. I know there is a lot of argument in that department, a lot of people say it\\'s 2001: A Space Odyssey or Clockwork Orange or even Dr. Strangelove, but if those film pioneered film making, then The Shining perfected it. This is the tale of isolation, madness, terrifying images, and the ultimate ghost story that will crawl underneath your skin. <br /><br />Jack Torrance, Jack\\'s son Danny, and Jack\\'s wife, Wendy arrive at the Overlook Hotel on closing day. The elderly African-American chef, Dick Hallorann, surprises Danny by speaking to him telepathically and offering him some ice cream. He explains to Danny that he and his grandmother shared the gift; they called the communication \"shining.\" Danny asks if there is anything to be afraid of in the hotel, particularly Room 237. Dick tells Danny that the hotel has a certain \"shine\" to it and many memories, not all of them good, and advises him to stay out of room 237 under all circumstances. Danny\\'s curiosity about Room 237 finally gets the better of him when he sees the room has been opened. Danny shows up injured and visibly traumatized after Jack tells Wendy that he loves his family. Seeing this, Wendy thinks Jack has been abusing Danny. Jack wanders into the hotel\\'s Gold Room where he meets a ghostly bartender named Lloyd. Danny starts calling out the word \"redrum\" frantically, and scribbling it on walls. He goes into a trance, and withdraws; he now says that he is Tony, his own \"imaginary friend.\" Jack sabotages the hotel radio, cutting off communication from the outside world, but Hallorann has received Danny\\'s telepathic cry for help and is on his way. Wendy discovers that Jack has been typing endless pages of manuscript repeating \"All work and no play makes Jack a dull boy\" formatted in various ways. Horrified, Jack threatens her and she knocks him unconscious with a baseball bat, locking him in a storage locker in the kitchen. Jack converses with Grady through the door of the locker, which then unlocks releasing him. Danny has written \"REDRUM\" in lipstick on the door of Wendy\\'s bedroom. When she looks in the mirror, she sees that it is \"Murder\" spelled backwards. Jack picks up an axe and begins to chop through the door leading to his family\\'s living quarters. \"Here\\'s Johnny!\", and Jack\\'s legendary image is born.<br /><br />The Shining is one of those films that you seriously have to make time to see, this is an incredible film and still gives me nightmares. Jack Nicholson\\'s performance is timeless and unforgettable. But one I also feel is extremely overlooked is Shelley Duvall, her scene of finding Jack\\'s rant All Work\\x85 is incredible, that\\'s a look of horror and you can see that fear in her face after realizing her husband is mad. Also another incredible scene is when Jack sees a ghost woman in the bathtub, it\\'s honestly one of the most terrifying scenes in horror cinema. The reason this film is so well known is because it\\'s a film of perfection, it\\'s been on The Simpsons, it\\'s been shown in other films and it\\'s a film that will forever stay with you when you see it, trust me.<br /><br />10/10')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "xm_vDSe9J8jO",
        "colab_type": "code",
        "outputId": "6e7cfed0-c719-4de1-a53f-a412fa51f2f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "test_text_labels = df_test['label'].astype(int)\n",
        "len(test_text_labels), test_text_labels[len(val_text_labels)-2]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "s3AxEhD_z1DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def preprocess_document(doc):\n",
        "    # negative sense should not be eleminated + some short representation\n",
        "    CONTRACTIONS = {\"mayn't\":\"may not\", \"can't\":\"can not\", \"won't\":\"will not\", \"isn't\":\"is not\", \"amn't\":\"am not\",\\\n",
        "                  \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"couldn't\":\"could not\", \\\n",
        "                  \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\\\n",
        "                  \"i'll\":\"i will\", \"you'll\":\"you will\", \"they'll\":\"they will\",\\\n",
        "                  \"may've\":\"may have\", \"can've\":\"can have\", \"will've\":\"will have\", \"you've\":\"you have\", \\\n",
        "                  \"could've\":\"could have\", \"would've\":\"would have\", \"you've\":\"you have\", \"they\":\"they have\",\\\n",
        "                  \"i've\":\"i have\", \"you've\":\"you have\", \"we've\":\"we have\", \"there's\":\"there is\", \"i'm\":\"i am\",\\\n",
        "                  \"it's\":\"it is\", \"what's\":\"what is\", \"where's\":\"where is\", \"how's\":\"how is\", \"i'd\":\"i had\"}\n",
        "    punctuation = string.punctuation + \"\\n\\n\"\n",
        "    punc_replace = ''.join([' ' for s in punctuation]); # required for replacing punctuation with null ('')\n",
        "    doc_clean = doc.replace('-', ' '); # replace - with null str\n",
        "    doc_clean = (doc_clean.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "    doc_clean = doc_clean.replace('<br />', ''); # replace <br /> with ''\n",
        "    doc_clean = doc_clean.replace(\"â€™\", \"'\"); # replace <br /> with null str\n",
        "    doc_clean = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in doc_clean.split(' ')] # replacing some common short forms\n",
        "    doc_clean = \" \".join(doc_clean) # list to sentence of strings\n",
        "    doc_clean = re.sub(r'\\W +', ' ', doc_clean) # except [a-zA-Z0-9_]\n",
        "    doc_clean = re.sub(r'\\d+', ' ', doc_clean) # remove numbers [0-9]\n",
        "    trans_table = str.maketrans(punctuation, punc_replace); # replace punctuations with ' '\n",
        "    doc_clean = ' '.join([word.translate(trans_table) for word in doc_clean.split(' ')]);\n",
        "    doc_clean = doc_clean.split(' ');\n",
        "    doc_clean = [word for word in doc_clean if len(word) > 0];\n",
        "\n",
        "    return doc_clean;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSNuXUopzavX",
        "colab_type": "code",
        "outputId": "e87c6866-32c7-49f0-d2df-333b4d0e4ad7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_reviews = [preprocess_document(review.lower()) for review in train_raw_text_reviews]\n",
        "print (train_text_reviews[len(train_text_reviews)-2])\n",
        "print (train_text_labels[len(train_text_labels)-2])"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anyone', 'notice', 'that', 'tommy', 'only', 'has', 'facial', 'expressions', 'the', 'angry', 'eyes', 'look', 'he', 'gives', 'every', 'enemy', 'the', 'holding', 'of', 'the', 'hands', 'to', 'face', 'mouth', 'agape', 'and', 'frightened', 'eyes', 'the', 'smiling', 'tommy', 'turnbull', 'i', 'have', 'to', 'say', 'that', 'i', 'pretty', 'much', 'hate', 'this', 'show', 'i', 'do', 'not', 'watch', 'it', 'but', 'it', 'is', 'like', 'code', 'lyoko', 'we', 'have', 'all', 'watched', 'at', 'least', 'one', 'i', 'must', 'say', 'that', 'this', 'show', 'is', 'borderline', 'racist', 'uninteresting', 'and', 'pointless', 'every', 'episode', 'ends', 'with', 'robotboy', 'winning', 'except', 'for', 'one', 'exception', 'when', 'robotboy', 'basically', 'let', 'this', 'overly', 'geeky', 'freakazoid', 'fly', 'away', 'on', 'a', 'jetpack', 'the', 'jokes', 'are', 'pretty', 'crude', 'too', 'i', 'think', 'it', 'is', 'mostly', 'people', 'saying', 'the', 'word', 'suck', 'or', 'farting', 'i', 'think', 'the', 'bullies', 'of', 'the', 'show', 'are', 'quite', 'shocking', 'too', 'isn', 't', 'there', 'one', 'that', 'hides', 'a', 'bowling', 'ball', 'under', 'his', 'hate', 'and', 'the', 'other', 'uses', 'a', 'chain', 'for', 'god', 'sake', 'what', 'kind', 'of', 'school', 'is', 'he', 'going', 'to', 'not', 'to', 'mention', 'his', 'older', 'brother', 'who', 'is', 'borderline', 'psychopathic', 'and', 'has', 'no', 'other', 'character', 'qualities', 'the', 'whole', 'show', 'i', 'feel', 'is', 'ripping', 'off', 'megas', 'xlr', 'and', 'fosters', 'like', 'you', 'could', 'say', 'the', 'trio', 'of', 'coop', 'jamie', 'and', 'kiva', 'as', 'well', 'as', 'robotboy', 'being', 'similar', 'to', 'megas', 'where', 'he', 'beats', 'everyone', 'no', 'matter', 'what', 'the', 'odds', 'and', 'he', 's', 'free', 'spirited', 'despite', 'being', 'a', 'robot', 'there', 'is', 'simply', 'no', 'appeal', 'to', 'this', 'show', 'i', 'am', 'surprised', 'that', 'it', 'is', 'still', 'running']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6psZ2jxNOoP",
        "colab_type": "code",
        "outputId": "9d8adada-a79d-45c8-ee93-17986a4ce952",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_text_reviews = [preprocess_document(review.lower()) for review in val_raw_text_reviews]\n",
        "print (val_text_reviews[len(val_text_reviews)-2])\n",
        "print (val_text_labels[len(val_text_labels)-2])"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['this', 'movie', 'starts', 'out', 'brisk', 'has', 'some', 'slow', 'moments', 'in', 'the', 'middle', 'but', 'generally', 'moves', 'along', 'well', 'has', 'a', 'few', 'very', 'good', 'moments', 'then', 'peters', 'out', 'at', 'the', 'end', 'of', 'act', 'i', 'was', 'able', 'to', 'get', 'to', 'see', 'this', 'in', 'la', 'premieres', 'times', 'with', 'different', 'endings', 'jason', 'lee', 'is', 'a', 'star', 'but', 'he', 'is', 'not', 'tomorrows', 'leading', 'man', 'he', 'is', 'humorous', 'and', 'holds', 'his', 'own', 'but', 'he', 'is', 'better', 'served', 'as', 'a', 'supporting', 'actor', 'julia', 'stiles', 'does', 'ok', 'in', 'a', 'comedy', 'role', 'new', 'for', 'her', 'but', 'she', 'does', 'not', 'steal', 'this', 'movie', 'the', 'way', 'a', 'star', 'of', 'her', 'caliber', 'should', 'for', 'an', 'actress', 'who', 'has', 'so', 'much', 'potential', 'things', 'save', 'the', 'last', 'dance', 'o', 'it', 'is', 'hard', 'to', 'watch', 'her', 'continue', 'to', 'do', 'roles', 'that', 'are', 'so', 'average', 'and', 'then', 'not', 'have', 'her', 'take', 'the', 'role', 'and', 'run', 'away', 'with', 'the', 'movie', 'like', 'daniel', 'day', 'lewis', 'did', 'in', 'gangs', 'selma', 'blair', 'is', 'a', 'good', 'young', 'actress', 'as', 'well', 'and', 'does', 'an', 'ok', 'job', 'i', 'didn', 't', 'expect', 'an', 'academy', 'award', 'performance', 'from', 'her', 'and', 'she', 'didn', 't', 'deliver', 'one', 'but', 'her', 'performance', 'was', 'adequate', 'chris', 'koch', 'delivers', 'another', 'film', 'that', 'is', 'above', 'average', 'perhaps', 'the', 'problem', 'lies', 'in', 'the', 'script', 'more', 'than', 'anything', 'else', 'i', 'did', 'like', 'this', 'movie', 'but', 'it', 'is', 'not', 'a', 'movie', 'where', 'you', 'walk', 'away', 'and', 'say', 'that', 'was', 'great', 'this', 'story', 'has', 'been', 'done', 'so', 'many', 'times', 'before', 'and', 'there', 'was', 'just', 'not', 'much', 'new', 'here', 'the', 'rehearsal', 'dinner', 'scene', 'was', 'probably', 'the', 'best', 'in', 'the', 'movie', 'and', 'larry', 'miller', 'gives', 'an', 'incredible', 'performance', 'in', 'a', 'supporting', 'role', 'he', 'could', 'be', 'the', 'best', 'surprise', 'of', 'the', 'film', 'if', 'you', 'want', 'to', 'go', 'see', 'a', 'movie', 'that', 'will', 'make', 'you', 'laugh', 'a', 'few', 'times', 'and', 'have', 'an', 'enjoyable', 'evening', 'i', 'can', 'still', 'recommend', 'this', 'film', 'but', 'unless', 'they', 'have', 'have', 'changed', 'the', 'ending', 'again', 'leave', 'during', 'the', 'church', 'scene', 'or', 'you', 'will', 'surely', 'be', 'disappointed']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REdaGj3VNOEX",
        "colab_type": "code",
        "outputId": "8678924d-b656-4831-e78e-b3e62a133e08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_text_reviews = [preprocess_document(review.lower()) for review in test_raw_text_reviews]\n",
        "print (test_text_reviews[len(test_text_reviews)-2])\n",
        "print (test_text_labels[len(test_text_labels)-2])"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['the', 'shining', 'you', 'know', 'what', 'is', 'weird', 'about', 'this', 'movie', 'this', 'is', 'the', 'movie', 'that', 'everyone', 'for', 'people', 'who', 'claim', 'to', 'not', 'like', 'horror', 'films', 'will', 'always', 'say', 'that', 'the', 'shining', 'is', 'a', 'terrific', 'film', 'this', 'is', 'stanley', 'kubrick', 's', 'classic', 'vision', 'of', 'stephen', 'king', 's', 'horror', 'tale', 'of', 'madness', 'and', 'blood', 'this', 'is', 'just', 'an', 'incredible', 'film', 'and', 'wither', 'you', 'have', 'seen', 'it', 'or', 'not', 'you', 'have', 'heard', 'of', 'it', 'know', 'a', 'few', 'lines', 'from', 'it', 'and', 'know', 'some', 'of', 'the', 'classic', 'images', 'who', 'could', 'forget', 'jack', 's', 'here', 's', 'johnny', 'who', 'could', 'forget', 'all', 'work', 'and', 'no', 'play', 'make', 'jack', 'a', 'dull', 'boy', 'who', 'could', 'forget', 'that', 'chilling', 'ending', 'this', 'is', 'the', 'film', 'that', 'is', 'unforgettable', 'and', 'honestly', 'in', 'my', 'opinion', 'is', 'kubrick', 's', 'best', 'work', 'i', 'know', 'there', 'is', 'a', 'lot', 'of', 'argument', 'in', 'that', 'department', 'a', 'lot', 'of', 'people', 'say', 'it', 'is', 'a', 'space', 'odyssey', 'or', 'clockwork', 'orange', 'or', 'even', 'dr', 'strangelove', 'but', 'if', 'those', 'film', 'pioneered', 'film', 'making', 'then', 'the', 'shining', 'perfected', 'it', 'this', 'is', 'the', 'tale', 'of', 'isolation', 'madness', 'terrifying', 'images', 'and', 'the', 'ultimate', 'ghost', 'story', 'that', 'will', 'crawl', 'underneath', 'your', 'skin', 'jack', 'torrance', 'jack', 's', 'son', 'danny', 'and', 'jack', 's', 'wife', 'wendy', 'arrive', 'at', 'the', 'overlook', 'hotel', 'on', 'closing', 'day', 'the', 'elderly', 'african', 'american', 'chef', 'dick', 'hallorann', 'surprises', 'danny', 'by', 'speaking', 'to', 'him', 'telepathically', 'and', 'offering', 'him', 'some', 'ice', 'cream', 'he', 'explains', 'to', 'danny', 'that', 'he', 'and', 'his', 'grandmother', 'shared', 'the', 'gift', 'they', 'have', 'called', 'the', 'communication', 'shining', 'danny', 'asks', 'if', 'there', 'is', 'anything', 'to', 'be', 'afraid', 'of', 'in', 'the', 'hotel', 'particularly', 'room', 'dick', 'tells', 'danny', 'that', 'the', 'hotel', 'has', 'a', 'certain', 'shine', 'to', 'it', 'and', 'many', 'memories', 'not', 'all', 'of', 'them', 'good', 'and', 'advises', 'him', 'to', 'stay', 'out', 'of', 'room', 'under', 'all', 'circumstances', 'danny', 's', 'curiosity', 'about', 'room', 'finally', 'gets', 'the', 'better', 'of', 'him', 'when', 'he', 'sees', 'the', 'room', 'has', 'been', 'opened', 'danny', 'shows', 'up', 'injured', 'and', 'visibly', 'traumatized', 'after', 'jack', 'tells', 'wendy', 'that', 'he', 'loves', 'his', 'family', 'seeing', 'this', 'wendy', 'thinks', 'jack', 'has', 'been', 'abusing', 'danny', 'jack', 'wanders', 'into', 'the', 'hotel', 's', 'gold', 'room', 'where', 'he', 'meets', 'a', 'ghostly', 'bartender', 'named', 'lloyd', 'danny', 'starts', 'calling', 'out', 'the', 'word', 'redrum', 'frantically', 'and', 'scribbling', 'it', 'on', 'walls', 'he', 'goes', 'into', 'a', 'trance', 'and', 'withdraws', 'he', 'now', 'says', 'that', 'he', 'is', 'tony', 'his', 'own', 'imaginary', 'friend', 'jack', 'sabotages', 'the', 'hotel', 'radio', 'cutting', 'off', 'communication', 'from', 'the', 'outside', 'world', 'but', 'hallorann', 'has', 'received', 'danny', 's', 'telepathic', 'cry', 'for', 'help', 'and', 'is', 'on', 'his', 'way', 'wendy', 'discovers', 'that', 'jack', 'has', 'been', 'typing', 'endless', 'pages', 'of', 'manuscript', 'repeating', 'all', 'work', 'and', 'no', 'play', 'makes', 'jack', 'a', 'dull', 'boy', 'formatted', 'in', 'various', 'ways', 'horrified', 'jack', 'threatens', 'her', 'and', 'she', 'knocks', 'him', 'unconscious', 'with', 'a', 'baseball', 'bat', 'locking', 'him', 'in', 'a', 'storage', 'locker', 'in', 'the', 'kitchen', 'jack', 'converses', 'with', 'grady', 'through', 'the', 'door', 'of', 'the', 'locker', 'which', 'then', 'unlocks', 'releasing', 'him', 'danny', 'has', 'written', 'redrum', 'in', 'lipstick', 'on', 'the', 'door', 'of', 'wendy', 's', 'bedroom', 'when', 'she', 'looks', 'in', 'the', 'mirror', 'she', 'sees', 'that', 'it', 'is', 'murder', 'spelled', 'backwards', 'jack', 'picks', 'up', 'an', 'axe', 'and', 'begins', 'to', 'chop', 'through', 'the', 'door', 'leading', 'to', 'his', 'family', 's', 'living', 'quarters', 'here', 's', 'johnny', 'and', 'jack', 's', 'legendary', 'image', 'is', 'born', 'the', 'shining', 'is', 'one', 'of', 'those', 'films', 'that', 'you', 'seriously', 'have', 'to', 'make', 'time', 'to', 'see', 'this', 'is', 'an', 'incredible', 'film', 'and', 'still', 'gives', 'me', 'nightmares', 'jack', 'nicholson', 's', 'performance', 'is', 'timeless', 'and', 'unforgettable', 'but', 'one', 'i', 'also', 'feel', 'is', 'extremely', 'overlooked', 'is', 'shelley', 'duvall', 'her', 'scene', 'of', 'finding', 'jack', 's', 'rant', 'all', 'work', 'is', 'incredible', 'that', 's', 'a', 'look', 'of', 'horror', 'and', 'you', 'can', 'see', 'that', 'fear', 'in', 'her', 'face', 'after', 'realizing', 'her', 'husband', 'is', 'mad', 'also', 'another', 'incredible', 'scene', 'is', 'when', 'jack', 'sees', 'a', 'ghost', 'woman', 'in', 'the', 'bathtub', 'it', 'is', 'honestly', 'one', 'of', 'the', 'most', 'terrifying', 'scenes', 'in', 'horror', 'cinema', 'the', 'reason', 'this', 'film', 'is', 'so', 'well', 'known', 'is', 'because', 'it', 'is', 'a', 'film', 'of', 'perfection', 'it', 'is', 'been', 'on', 'the', 'simpsons', 'it', 'is', 'been', 'shown', 'in', 'other', 'films', 'and', 'it', 'is', 'a', 'film', 'that', 'will', 'forever', 'stay', 'with', 'you', 'when', 'you', 'see', 'it', 'trust', 'me']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydrqMX261kQ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea8be54f-8e71-4f63-e467-889250084f31"
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "451"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 188
        }
      ]
    },
    {
      "metadata": {
        "id": "MKifaS85Dkap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating Tokens and Types"
      ]
    },
    {
      "metadata": {
        "id": "dyQJIGVw4Dau",
        "colab_type": "code",
        "outputId": "cfddef20-2127-4f70-bc7d-9559a5a2160b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Fetching the tokens (all words in a doc) and types(unique words in a doc) in the document\n",
        "types = ()\n",
        "tokens = []\n",
        "for row in train_text_reviews+val_text_reviews+test_text_reviews:\n",
        "    tokens += [words for words in row]\n",
        "types = set(tokens)\n",
        "\n",
        "VOCAB_SIZE, TOKEN_SIZE = len(types), len(tokens)\n",
        "VOCAB_SIZE, TOKEN_SIZE"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(72251, 5580744)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 189
        }
      ]
    },
    {
      "metadata": {
        "id": "B20xEKK-Hwn7",
        "colab_type": "code",
        "outputId": "982cf3bd-8603-4ea3-8656-d4ba708a78c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = {x:i for i, x in enumerate(types)}\n",
        "ix_to_word = [x for i, x in enumerate(types)]\n",
        "\n",
        "ix_to_word[word_to_ix['kick']]=='kick', word_to_ix['kick'], len(ix_to_word)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 13333, 72251)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "metadata": {
        "id": "GMbWbZdr1reC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "958ca898-c414-4e59-ad99-aca3cdb66842"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 191
        }
      ]
    },
    {
      "metadata": {
        "id": "yNUlKuJeNJEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "SqLOymKPLPug",
        "colab_type": "code",
        "outputId": "22604c44-7494-4db7-8835-252b9efdd817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable # Automatic gradients are calculated and back-propagated through the computational graph\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "metadata": {
        "id": "SaSwXEBh6565",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model Definition for the BOWClassifier"
      ]
    },
    {
      "metadata": {
        "id": "PM5I4GP6lFGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BOWClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BOWClassifier, self).__init__()\n",
        "        SEED = 42\n",
        "        torch.manual_seed(SEED)\n",
        "        torch.cuda.manual_seed(SEED)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size, hidden_size) # initialises weights and biases i2h\n",
        "        self.h2o = nn.Linear(hidden_size, output_size) # initialises weights and biases h2o\n",
        "#         self.i2o = nn.Linear(input_size, output_size) # initialises weights and biases i2o\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "        x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8MGEFG3Mmww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialise Parameter and Model"
      ]
    },
    {
      "metadata": {
        "id": "MlMeX6577J9A",
        "colab_type": "code",
        "outputId": "bb3d9d6e-ceb0-4373-baf7-7257789de744",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "num_of_hidden = 50 # vary this for assignment\n",
        "num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "bow = BOWClassifier(num_of_input, num_of_hidden, num_of_output) # initialises weights and biases\n",
        "bow.i2h, bow.h2o # desc network\n",
        "# bow.i2o"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Linear(in_features=72251, out_features=50, bias=True),\n",
              " Linear(in_features=50, out_features=1, bias=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "metadata": {
        "id": "8fMMShAzMDjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### visualise the parameter"
      ]
    },
    {
      "metadata": {
        "id": "PRhDPFx87Ptm",
        "colab_type": "code",
        "outputId": "4c95895c-84c0-45dc-97f1-84a7a10fe793",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "for param in bow.parameters(): # desc the parameter value\n",
        "    print(param,param.size())"
      ],
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0028,  0.0031, -0.0009,  ..., -0.0023, -0.0022,  0.0007],\n",
            "        [ 0.0011, -0.0013, -0.0037,  ...,  0.0023, -0.0004, -0.0032],\n",
            "        [ 0.0019,  0.0003, -0.0013,  ...,  0.0012, -0.0015,  0.0009],\n",
            "        ...,\n",
            "        [-0.0008,  0.0016, -0.0003,  ..., -0.0014,  0.0034, -0.0007],\n",
            "        [-0.0003, -0.0009, -0.0020,  ..., -0.0018,  0.0006,  0.0028],\n",
            "        [ 0.0011,  0.0004,  0.0014,  ..., -0.0020,  0.0002, -0.0006]],\n",
            "       requires_grad=True) torch.Size([50, 72251])\n",
            "Parameter containing:\n",
            "tensor([-0.0031,  0.0027, -0.0023,  0.0023,  0.0012,  0.0014,  0.0006, -0.0036,\n",
            "         0.0021,  0.0009,  0.0005,  0.0017,  0.0019, -0.0026, -0.0023,  0.0010,\n",
            "         0.0003, -0.0025, -0.0007,  0.0029,  0.0034, -0.0005, -0.0016, -0.0008,\n",
            "        -0.0035, -0.0020,  0.0036,  0.0018, -0.0010, -0.0015,  0.0007,  0.0017,\n",
            "        -0.0010, -0.0014, -0.0037, -0.0009, -0.0034,  0.0005, -0.0007, -0.0014,\n",
            "        -0.0036,  0.0031, -0.0028, -0.0022, -0.0012,  0.0021, -0.0002, -0.0014,\n",
            "         0.0024, -0.0036], requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.0300,  0.0144, -0.0536,  0.0314,  0.1047, -0.0678,  0.1030,  0.0508,\n",
            "         -0.0731, -0.0210,  0.0563,  0.0307,  0.1271, -0.0224,  0.0497, -0.0502,\n",
            "          0.0085, -0.0085, -0.0085, -0.0324,  0.0553, -0.1001,  0.0322, -0.0747,\n",
            "         -0.0256,  0.1228,  0.0769, -0.0575, -0.0047, -0.0698,  0.1019,  0.1395,\n",
            "          0.0126, -0.0785, -0.1068, -0.0753, -0.0256, -0.0866,  0.0452,  0.0439,\n",
            "          0.0153, -0.0488,  0.1388,  0.0876,  0.0491, -0.0733, -0.1207,  0.1188,\n",
            "         -0.1104,  0.0704]], requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([-0.1145], requires_grad=True) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWqAwOAI7D54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "UZK9TAQI7Fbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))#, device=device) # make 1D vector of len = vocab size\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:            \n",
        "#             raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nw0OYbTzBwJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Loss function"
      ]
    },
    {
      "metadata": {
        "id": "PbQcwSIb96V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.BCELoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.1) #, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqYSLXcj11HJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ea6b99f-71c8-403a-fcde-39c422197b5e"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "metadata": {
        "id": "tuYAAQh2F6J8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "W7xoiOiAyZN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ff50c255-7fb3-46db-ea4f-394aaa60e832"
      },
      "cell_type": "code",
      "source": [
        "# store the bag of word vectors for each sentences\n",
        "train_data = [make_bow_vector(instance, word_to_ix) for instance in train_text_reviews]\n",
        "num_train_data = len(train_text_reviews)\n",
        "\n",
        "val_data = [make_bow_vector(instance, word_to_ix) for instance in val_text_reviews]\n",
        "num_val_data = len(val_text_reviews)\n",
        "\n",
        "num_train_data, num_val_data"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 499)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "metadata": {
        "id": "hQE9P4a22Hsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "405f1759-ff95-47d0-9bb2-55e6c30db1a8"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 200
        }
      ]
    },
    {
      "metadata": {
        "id": "cStQIVFfESWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_validation_accuracy(data, net):\n",
        "    correct = 0\n",
        "    for i, instance in enumerate(data):\n",
        "        label = val_text_labels[i] # get the label of the corresponding instace\n",
        "        bow_vec = Variable(instance)\n",
        "        logprobs = bow.forward(bow_vec)\n",
        "    \n",
        "        pred_class = np.argmax(logprobs.data.numpy())\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "\n",
        "    return float(100)*correct/len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ad6MFVt7F5X8",
        "colab_type": "code",
        "outputId": "ed500303-caeb-4f18-fe94-b9ec5d849616",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "# the training loop\n",
        "epochs = 100\n",
        "total_time = 0.0\n",
        "train_epoch_history = []\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "for e in range(epochs):\n",
        "    tic = time.time() # start the timer\n",
        "    correct = 0\n",
        "    cumulative_loss = 0\n",
        "    \n",
        "    for i, instance in enumerate(train_text_reviews): \n",
        "        # get the training data\n",
        "        label = train_text_labels[i] # get the label of the corresponding instace\n",
        "        \n",
        "        bow.zero_grad() # reset the gradient for each epoch\n",
        "        \n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix)) # vector repesentation of input sentence\n",
        "\n",
        "        label = Variable(torch.FloatTensor([label])) # wraps a tensor for label\n",
        "        label.resize_((1,1)) # to match up with dim of pred i.e. tensor([1,1])\n",
        "        \n",
        "        pred = bow.forward(bow_vec) # forward pass\n",
        "        \n",
        "        loss += loss_function(pred, label)/float(num_train_data) # compute the loss\n",
        "        loss.backward() # backprop the loss\n",
        "        opt.step() # performs a parameter update based on the current gradient\n",
        "        \n",
        "        cumulative_loss += float(loss.data)\n",
        "        \n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "        if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "            correct += 1\n",
        "\n",
        "    toc = time.time() # final time \n",
        "    total_time += (toc-tic)\n",
        "\n",
        "    train_epoch_history.append(e+1)\n",
        "    train_loss_history.append(cumulative_loss/num_train_data)\n",
        "    \n",
        "    val_accuracy, val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "    val_loss_history.append(val_loss/num_train_data)\n",
        "    \n",
        "    print(\"Epoch {}/{}, Time: {:.2f}, Train Loss: {:.9f}, Train Accuracy: {:.2f}%, Val loss: {:.9f}, Val Accuracy: {:.2f} Total Time: {:.2f}\".format(e+1, epochs, (toc-tic), float(loss.data), (val_loss*float(100)/num_train_data), val_accuracy, correct*float(100)/num_train_data, total_time))"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-202-b817691e70c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_data\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# backprop the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# performs a parameter update based on the current gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "FDUyFfwmXSew",
        "colab_type": "code",
        "outputId": "12ef2f2d-e7a8-4d07-bf11-2ab11a1493df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(\"Image\")\n",
        "plt.title(\"Loss vs Epoch\")\n",
        "# val_loss_history_1 =  [float(i)/sum(val_loss_history_1) for i in val_loss_history_1] # normalised between 0-1\n",
        "train_loss_history_1 =  [float(i)/sum(train_loss_history) for i in train_loss_history] # normalised between 0-1\n",
        "# plt.plot(val_loss_history_1, c=\"red\", label=\"Validation Loss\")\n",
        "plt.plot(train_loss_history, c=\"blue\", label = \"Training Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f3fa9142ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd8AAAFZCAYAAADZ6SWdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nGVP4ioiIlDGFr4iISBn7/x7e4sj7O09UAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gPf_k4VNuaDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkYBaktsF-sm",
        "colab_type": "code",
        "outputId": "8083b485-b323-4db0-ef48-28e17038dcef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "correct = 0\n",
        "data = []\n",
        "data = [make_bow_vector(instance, word_to_ix) for instance in test_text_reviews]\n",
        "tic = time.time()\n",
        "for i, instance in enumerate(data):\n",
        "    label = test_text_labels[i]\n",
        "    bow_vec = Variable(instance)\n",
        "    logprobs = bow.forward(bow_vec)\n",
        "#     print(logprobs)\n",
        "    pred_class = np.argmax(logprobs.data.numpy())\n",
        "    \n",
        "#     print('prediction: {}'.format(pred_class))\n",
        "#     print('actual: {}'.format(label))\n",
        "    if(int(label) == pred_class):\n",
        "        correct += 1\n",
        "toc = time.time()\n",
        "print(\"Test Accuracy: {:.2f}%\".format(correct*100/len(data)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n",
            "Test Accuracy: 87.140%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uHAvtGWbudLN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.save(bow,'model.json')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz5PwYjVudEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "29twCfxpuc8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.load(io.BytesIO(temp_test['model.json']))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}