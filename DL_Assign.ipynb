{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuB0HM37teAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "rKlXTA5zfx20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run on **GPU**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_NV6CE-qtvGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Header Files"
      ]
    },
    {
      "metadata": {
        "id": "WE7OEcPOtzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4037ccUuFFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset and Visualise"
      ]
    },
    {
      "metadata": {
        "id": "EhWFepP2t3eA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_train.head()\n",
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Train_20K.csv\"\n",
        "df = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvAXyCoDaR3b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "054a6205-4ae1-499e-a9f7-1a417ca2cf0a"
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 304
        }
      ]
    },
    {
      "metadata": {
        "id": "44YtF48vX24a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_1 = df[df['label']==1] # get only label == 1\n",
        "df_0 = df[df['label']==0] # get only label == 0\n",
        "\n",
        "range_1 = int(0.8*len(df_1))\n",
        "range_2 = int(0.8*len(df_0))\n",
        "\n",
        "np.random.seed(42) # fix the seed value\n",
        "df_1 = df_1.iloc[np.random.permutation(len(df_1))] # shuffled the data set of label==1\n",
        "df_0 = df_0.iloc[np.random.permutation(len(df_0))] # shuffled the data set of label==0\n",
        "\n",
        "temp_1_train = df_1.iloc[:range_1]\n",
        "temp_2_train = df_0.iloc[:range_2]\n",
        "df_train = pd.concat([temp_1_train, temp_2_train])\n",
        "\n",
        "temp_1_val = df_1.iloc[range_1:]\n",
        "temp_2_val = df_0.iloc[range_2:]\n",
        "df_val = pd.concat([temp_1_val, temp_2_val])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9FBTqABuRlO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fccbcc1-6164-4dd8-c167-27e2e7c6293f"
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train.iloc[np.random.permutation(len(df_train))] # shuffled the data set of label==1\n",
        "df_val = df_val.iloc[np.random.permutation(len(df_val))] # shuffled the data set of label==1\n",
        "len(df_train), len(df_val)"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14399, 3600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "metadata": {
        "id": "0WFB1TtsxD3F",
        "colab_type": "code",
        "outputId": "5de83ddb-1ae9-4737-e0e0-dc1658e01565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_train[df_train['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_train[df_train['label']==1]))\n",
        "print('Number of movie reviews', len(df_train['label']))"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 7195\n",
            "Number of Positive movie reviews 7204\n",
            "Number of movie reviews 14399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYtzJk8r3lm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0e26679c-cd85-4951-b505-2c86fa7166db"
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_val[df_val['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_val[df_val['label']==1]))\n",
        "print('Number of movie reviews', len(df_val['label']))"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 1799\n",
            "Number of Positive movie reviews 1801\n",
            "Number of movie reviews 3600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuZxOMpkQoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Test_5K.csv\"\n",
        "df_test = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVzhPcGGxf2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "u-8IR64TKH0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get Train Data"
      ]
    },
    {
      "metadata": {
        "id": "JprKnOXgxXkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_raw_text_reviews = df_train['text'].astype(str).tolist()\n",
        "train_text_labels = df_train['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwU4zROpKLdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "7TsL1ACWJ_3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_raw_text_reviews = df_val['text'].astype(str).tolist()\n",
        "val_text_labels = df_val['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YixDzEnXLZN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "metadata": {
        "id": "MQHaSpnJJ9eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_raw_text_reviews = df_test['text'].astype(str).tolist()\n",
        "test_text_labels = df_test['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui-q6WRqOrB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Cleaning the raw input data"
      ]
    },
    {
      "metadata": {
        "id": "8_4b4FmShb0u",
        "colab_type": "code",
        "outputId": "7befca1b-c662-48fe-c99c-df9c91e31c49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Finding stop words\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 313,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3AxEhD_z1DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_document(doc):\n",
        "    # negative sense should not be eleminated + some short representation\n",
        "    CONTRACTIONS = {\"mayn't\":\"may not\", \"can't\":\"can not\", \"won't\":\"will not\", \"isn't\":\"is not\", \"amn't\":\"am not\",\\\n",
        "                  \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"couldn't\":\"could not\", \\\n",
        "                  \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\\\n",
        "                  \"i'll\":\"i will\", \"you'll\":\"you will\", \"they'll\":\"they will\",\\\n",
        "                  \"may've\":\"may have\", \"can've\":\"can have\", \"will've\":\"will have\", \"you've\":\"you have\", \\\n",
        "                  \"could've\":\"could have\", \"would've\":\"would have\", \"you've\":\"you have\", \"they\":\"they have\",\\\n",
        "                  \"i've\":\"i have\", \"you've\":\"you have\", \"we've\":\"we have\", \"there's\":\"there is\", \"i'm\":\"i am\",\\\n",
        "                  \"it's\":\"it is\", \"what's\":\"what is\", \"where's\":\"where is\", \"how's\":\"how is\", \"i'd\":\"i had\"}\n",
        "    punctuation = string.punctuation + \"\\n\\n\"\n",
        "    punc_replace = ''.join([' ' for s in punctuation]) # required for replacing punctuation with null ('')\n",
        "    doc_clean = doc.replace('-', ' ') # replace - with null str\n",
        "    doc_clean = (doc_clean.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "    doc_clean = doc_clean.replace('<br />', '') # replace <br /> with ''\n",
        "    doc_clean = doc_clean.replace(\"â€™\", \"'\") # replace <br /> with null str\n",
        "    doc_clean = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in doc_clean.split(' ')] # replacing some common short forms\n",
        "    doc_clean = \" \".join(doc_clean) # list to sentence of strings\n",
        "    doc_clean = re.sub(r'\\W +', ' ', doc_clean) # except [a-zA-Z0-9_]\n",
        "    doc_clean = re.sub(r'\\d+', ' ', doc_clean) # remove numbers [0-9]\n",
        "    trans_table = str.maketrans(punctuation, punc_replace); # replace punctuations with ' '\n",
        "    doc_clean = ' '.join([word.translate(trans_table) for word in doc_clean.split(' ')])\n",
        "    doc_clean = doc_clean.split(' ');\n",
        "    doc_clean = [word for word in doc_clean if len(word) > 0];\n",
        "    # removing the stopwords from a sentence\n",
        "    doc_clean = [word for word in doc_clean if not word in stop_words and word != 'not' and word != 'no']\n",
        "    return doc_clean;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSNuXUopzavX",
        "colab_type": "code",
        "outputId": "9c7a66c2-eb42-4a8f-a05a-0e223b197567",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_reviews = [preprocess_document(review.lower()) for review in train_raw_text_reviews]\n",
        "print (train_text_reviews[len(train_text_reviews)-2])\n",
        "print (train_text_labels[len(train_text_labels)-2])"
      ],
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['film', 'made', 'cast', 'home', 'town', 'remember', 'fuss', 'whole', 'hullabaloo', 'fact', 'molly', 'ringwald', 'town', 'storyline', 'essentially', 'years', 'film', 'laid', 'rest', 'without', 'finished', 'group', 'film', 'students', 'set', 'complete', 'dire', 'consequences', 'would', 'seem', 'someone', 'want', 'film', 'completed', 'storyline', 'flimsy', 'one', 'remember', 'comedy', 'therefore', 'taken', 'little', 'tounge', 'cheek', 'real', 'oomph', 'characters', 'mostly', 'transperant', 'little', 'info', 'recieve', 'care', 'seems', 'irrelevant', 'weird', 'hearing', 'kylie', 'accent', 'australian', 'nice', 'see', 'kid', 'went', 'school', 'starring', 'role', 'redeem', 'film', 'goodness', 'knows', 'makers', 'thought', 'would', 'get', 'molly', 'ringwald', 'perhaps', 'due', 'nature', 'film', 'sort', 'pays', 'homage', 'films', 'bad', 'horror', 'films', 'really', 'aussie', 'actor', 'would', 'done', 'fine', 'far', 'casting', 'concerned', 'lot', 'acting', 'seemed', 'constipated', 'kids', 'especially', 'two', 'main', 'chics', 'played', 'director', 'producer', 'looked', 'like', 'trying', 'act', 'never', 'good', 'look', 'also', 'shots', 'rough', 'feel', 'lit', 'perhaps', 'smooth', 'one', 'used', 'killer', 'lord', 'could', 'less', 'frightening', 'shock', 'factors', 'though', 'couple', 'gross', 'scenes', 'like', 'film', 'great', 'went', 'minutes', 'could', 'gone', 'less', 'perhaps', 'tightened', 'script', 'would', 'better', 'lot', 'characters', 'get', 'killed', 'real', 'build', 'getting', 'slayed', 'maybe', 'killed', 'less', 'people', 'actually', 'concentrated', 'scary', 'atmosphere', 'would', 'better', 'know', 'comedy', 'elements', 'funny', 'unbelieveable', 'funny', 'convinced', 'lm']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6psZ2jxNOoP",
        "colab_type": "code",
        "outputId": "23388605-b6c4-469e-9434-9c6c3d248fce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_text_reviews = [preprocess_document(review.lower()) for review in val_raw_text_reviews]\n",
        "print (val_text_reviews[len(val_text_reviews)-2])\n",
        "print (val_text_labels[len(val_text_labels)-2])"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['like', 'streetcar', 'named', 'desire', 'also', 'directed', 'gadg', 'stage', 'screen', 'panic', 'streets', 'depicts', 'new', 'orleans', 'major', 'claim', 'fame', 'birthplace', 'jazz', 'even', 'rate', 'mention', 'richard', 'widmark', 'seventh', 'film', 'arguably', 'went', 'long', 'way', 'establishing', 'fine', 'actor', 'really', 'rather', 'merely', 'psychotic', 'killer', 'gadg', 'appears', 'uncredited', 'small', 'role', 'morgue', 'attendant', 'film', 'rich', 'talent', 'beginning', 'jack', 'palance', 'still', 'billed', 'walter', 'jack', 'palance', 'local', 'mr', 'big', 'followed', 'side', 'kick', 'zero', 'mostel', 'barbara', 'bel', 'geddes', 'emile', 'meyer', 'tommy', 'rettig', 'plus', 'rock', 'solid', 'ever', 'reliable', 'paul', 'douglas', 'cop', 'comes', 'round', 'doc', 'widmark', 'point', 'view', 'rewarding', 'movie', 'little', 'seen', 'catch']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REdaGj3VNOEX",
        "colab_type": "code",
        "outputId": "a9aa0617-7587-4fe1-cc15-3aa267c1afc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_text_reviews = [preprocess_document(review.lower()) for review in test_raw_text_reviews]\n",
        "print (test_text_reviews[len(test_text_reviews)-2])\n",
        "print (test_text_labels[len(test_text_labels)-2])"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['shining', 'know', 'weird', 'movie', 'movie', 'everyone', 'people', 'claim', 'like', 'horror', 'films', 'always', 'say', 'shining', 'terrific', 'film', 'stanley', 'kubrick', 'classic', 'vision', 'stephen', 'king', 'horror', 'tale', 'madness', 'blood', 'incredible', 'film', 'wither', 'seen', 'heard', 'know', 'lines', 'know', 'classic', 'images', 'could', 'forget', 'jack', 'johnny', 'could', 'forget', 'work', 'play', 'make', 'jack', 'dull', 'boy', 'could', 'forget', 'chilling', 'ending', 'film', 'unforgettable', 'honestly', 'opinion', 'kubrick', 'best', 'work', 'know', 'lot', 'argument', 'department', 'lot', 'people', 'say', 'space', 'odyssey', 'clockwork', 'orange', 'even', 'dr', 'strangelove', 'film', 'pioneered', 'film', 'making', 'shining', 'perfected', 'tale', 'isolation', 'madness', 'terrifying', 'images', 'ultimate', 'ghost', 'story', 'crawl', 'underneath', 'skin', 'jack', 'torrance', 'jack', 'son', 'danny', 'jack', 'wife', 'wendy', 'arrive', 'overlook', 'hotel', 'closing', 'day', 'elderly', 'african', 'american', 'chef', 'dick', 'hallorann', 'surprises', 'danny', 'speaking', 'telepathically', 'offering', 'ice', 'cream', 'explains', 'danny', 'grandmother', 'shared', 'gift', 'called', 'communication', 'shining', 'danny', 'asks', 'anything', 'afraid', 'hotel', 'particularly', 'room', 'dick', 'tells', 'danny', 'hotel', 'certain', 'shine', 'many', 'memories', 'good', 'advises', 'stay', 'room', 'circumstances', 'danny', 'curiosity', 'room', 'finally', 'gets', 'better', 'sees', 'room', 'opened', 'danny', 'shows', 'injured', 'visibly', 'traumatized', 'jack', 'tells', 'wendy', 'loves', 'family', 'seeing', 'wendy', 'thinks', 'jack', 'abusing', 'danny', 'jack', 'wanders', 'hotel', 'gold', 'room', 'meets', 'ghostly', 'bartender', 'named', 'lloyd', 'danny', 'starts', 'calling', 'word', 'redrum', 'frantically', 'scribbling', 'walls', 'goes', 'trance', 'withdraws', 'says', 'tony', 'imaginary', 'friend', 'jack', 'sabotages', 'hotel', 'radio', 'cutting', 'communication', 'outside', 'world', 'hallorann', 'received', 'danny', 'telepathic', 'cry', 'help', 'way', 'wendy', 'discovers', 'jack', 'typing', 'endless', 'pages', 'manuscript', 'repeating', 'work', 'play', 'makes', 'jack', 'dull', 'boy', 'formatted', 'various', 'ways', 'horrified', 'jack', 'threatens', 'knocks', 'unconscious', 'baseball', 'bat', 'locking', 'storage', 'locker', 'kitchen', 'jack', 'converses', 'grady', 'door', 'locker', 'unlocks', 'releasing', 'danny', 'written', 'redrum', 'lipstick', 'door', 'wendy', 'bedroom', 'looks', 'mirror', 'sees', 'murder', 'spelled', 'backwards', 'jack', 'picks', 'axe', 'begins', 'chop', 'door', 'leading', 'family', 'living', 'quarters', 'johnny', 'jack', 'legendary', 'image', 'born', 'shining', 'one', 'films', 'seriously', 'make', 'time', 'see', 'incredible', 'film', 'still', 'gives', 'nightmares', 'jack', 'nicholson', 'performance', 'timeless', 'unforgettable', 'one', 'also', 'feel', 'extremely', 'overlooked', 'shelley', 'duvall', 'scene', 'finding', 'jack', 'rant', 'work', 'incredible', 'look', 'horror', 'see', 'fear', 'face', 'realizing', 'husband', 'mad', 'also', 'another', 'incredible', 'scene', 'jack', 'sees', 'ghost', 'woman', 'bathtub', 'honestly', 'one', 'terrifying', 'scenes', 'horror', 'cinema', 'reason', 'film', 'well', 'known', 'film', 'perfection', 'simpsons', 'shown', 'films', 'film', 'forever', 'stay', 'see', 'trust']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydrqMX261kQ-",
        "colab_type": "code",
        "outputId": "7dc531c8-7ee0-45f5-e397-1f2a31f24817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "572"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 318
        }
      ]
    },
    {
      "metadata": {
        "id": "xWfJK2HvwwQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_vocabulary(sentences):\n",
        "    # Build vocabulary\n",
        "    dictWordCount = {}\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] = 0 # initialising the dict value to zero\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] += 1 # updating the dictionary count\n",
        "    \n",
        "    temp = dictWordCount.copy()\n",
        "    for key, val in temp.items():\n",
        "        if(dictWordCount[key] <= 3):\n",
        "            del dictWordCount[key]\n",
        "    \n",
        "    # Mapping from index to word\n",
        "    vocabulary_inv = sorted(dictWordCount, key=dictWordCount.__getitem__, reverse=True)\n",
        "    \n",
        "    # Mapping from word to index\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return vocabulary, vocabulary_inv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKifaS85Dkap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating Tokens and Types"
      ]
    },
    {
      "metadata": {
        "id": "9cpQlJ3TytgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_ix, ix_to_word = build_vocabulary(train_text_reviews+val_text_reviews+test_text_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLBgxuf0xDB9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a0163fde-7095-4bd5-ce10-faa8dbbce652"
      },
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word_to_ix)\n",
        "ix_to_word[word_to_ix['kick']]=='kick', word_to_ix['kick'], VOCAB_SIZE"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 1829, 30941)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 358
        }
      ]
    },
    {
      "metadata": {
        "id": "GMbWbZdr1reC",
        "colab_type": "code",
        "outputId": "9100dd20-c995-4a76-8288-64ca2491a66f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 324
        }
      ]
    },
    {
      "metadata": {
        "id": "yNUlKuJeNJEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "SqLOymKPLPug",
        "colab_type": "code",
        "outputId": "8f4d23f7-77ab-41b3-815c-7ee78c0cf194",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable # Automatic gradients are calculated and back-propagated through the computational graph\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 359,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 359
        }
      ]
    },
    {
      "metadata": {
        "id": "SaSwXEBh6565",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model Definition for the BOWClassifier"
      ]
    },
    {
      "metadata": {
        "id": "PM5I4GP6lFGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BOWClassifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(BOWClassifier, self).__init__()\n",
        "        SEED = 42\n",
        "        torch.manual_seed(SEED)\n",
        "        torch.cuda.manual_seed(SEED)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.i2h = nn.Linear(input_size, hidden_size) # initialises weights and biases i2h\n",
        "        self.h2o = nn.Linear(hidden_size, output_size) # initialises weights and biases h2o\n",
        "#         self.i2o = nn.Linear(input_size, output_size) # initialises weights and biases i2o\n",
        "         \n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "        x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a8MGEFG3Mmww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Initialise Parameter and Model"
      ]
    },
    {
      "metadata": {
        "id": "MlMeX6577J9A",
        "colab_type": "code",
        "outputId": "258dba2e-7691-45d9-f79a-cd448d960c3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "num_of_hidden = 50 # vary this for assignment\n",
        "num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "bow = BOWClassifier(num_of_input, num_of_hidden, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "bow.i2h, bow.h2o # desc network\n",
        "\n",
        "# bow.i2o"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Linear(in_features=30941, out_features=50, bias=True),\n",
              " Linear(in_features=50, out_features=1, bias=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 405
        }
      ]
    },
    {
      "metadata": {
        "id": "8fMMShAzMDjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### visualise the parameter"
      ]
    },
    {
      "metadata": {
        "id": "PRhDPFx87Ptm",
        "colab_type": "code",
        "outputId": "c998e0f6-894e-4b51-90af-795dc0db31da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "for param in bow.parameters(): # desc the parameter value\n",
        "    print(param,param.size())"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0043,  0.0047, -0.0013,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [-0.0031,  0.0019,  0.0001,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [-0.0038, -0.0053, -0.0017,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0009, -0.0011, -0.0037,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0020,  0.0033,  0.0048,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0004, -0.0015, -0.0051,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([-0.0050,  0.0047, -0.0024,  0.0015,  0.0033,  0.0050, -0.0008, -0.0021,\n",
            "         0.0017, -0.0021,  0.0005, -0.0007, -0.0007,  0.0035, -0.0002, -0.0056,\n",
            "         0.0037,  0.0045,  0.0033, -0.0004, -0.0002,  0.0042,  0.0002, -0.0034,\n",
            "        -0.0050, -0.0027, -0.0024,  0.0010,  0.0005,  0.0055, -0.0042,  0.0007,\n",
            "        -0.0037,  0.0035, -0.0021,  0.0048,  0.0030,  0.0056, -0.0033, -0.0032,\n",
            "        -0.0050,  0.0024,  0.0027,  0.0042,  0.0056,  0.0053,  0.0031, -0.0009,\n",
            "        -0.0027,  0.0048], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.0671,  0.0960, -0.0546,  0.1031,  0.0380,  0.0649, -0.0699, -0.0720,\n",
            "          0.1183, -0.1274,  0.0683,  0.0941, -0.1075,  0.1206,  0.1356, -0.1353,\n",
            "          0.0842, -0.1374,  0.0661, -0.0550, -0.0093, -0.1378, -0.0247,  0.0893,\n",
            "          0.0678,  0.0441,  0.1351, -0.1242,  0.0515,  0.0817,  0.0325, -0.1093,\n",
            "         -0.1132, -0.0610, -0.0209,  0.1063,  0.0614,  0.1316,  0.1052, -0.0124,\n",
            "         -0.0939, -0.1136,  0.0548,  0.0545, -0.0190, -0.1386,  0.1056,  0.1076,\n",
            "         -0.1033,  0.0996]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0331], device='cuda:0', requires_grad=True) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWqAwOAI7D54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "UZK9TAQI7Fbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix)).to('cuda:0') #, device=device) # make 1D vector of len = vocab size\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:            \n",
        "#             raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6p3T6oo_T99z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Store in input sentences torch vector"
      ]
    },
    {
      "metadata": {
        "id": "g6Tw8pD5NW2S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W7xoiOiAyZN5",
        "colab_type": "code",
        "outputId": "875ac936-ba47-4de9-9ea9-b4e0cb96cc5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# store the bag of word vectors for each sentences and wraping to tensor of torch type\n",
        "tic = time.time()\n",
        "train_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in train_text_reviews]\n",
        "num_train_data = len(train_text_reviews)\n",
        "\n",
        "val_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in val_text_reviews]\n",
        "num_val_data = len(val_text_reviews)\n",
        "toc = time.time()\n",
        "num_train_data, num_val_data, (toc-tic)"
      ],
      "execution_count": 344,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14399, 3600, 89.1782169342041)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 344
        }
      ]
    },
    {
      "metadata": {
        "id": "deO_hz8vT19u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation Accuracy Computation"
      ]
    },
    {
      "metadata": {
        "id": "cStQIVFfESWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_validation_accuracy(data, net):\n",
        "    sum_loss = 0\n",
        "    \n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    \n",
        "    for i, instance in enumerate(data):\n",
        "        label = val_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "        \n",
        "#         vec = Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') # wrap to tensor of torch type for instance\n",
        "        \n",
        "#         prob = net.forward(vec) # forward pass\n",
        "\n",
        "        prob = net.forward(instance)\n",
        "    \n",
        "        _class = 1 if prob.item() > 0.5 else 0 # sigmoid activated\n",
        "        \n",
        "        loss = loss_function(prob, label) # compute the loss\n",
        "        \n",
        "        sum_loss += float(loss.item())\n",
        "#         print (int(label), _class)        \n",
        "        if(int(label) == _class and _class == 1):\n",
        "            true_positive += 1\n",
        "            \n",
        "        if(int(label) == _class and _class == 0):\n",
        "            true_negative += 1\n",
        "        \n",
        "        if(_class == 1 and int(label) == 0):\n",
        "            false_positive += 1\n",
        "            \n",
        "        if(_class == 0 and int(label) == 1):\n",
        "            false_negative += 1\n",
        "    \n",
        "    \n",
        "    precision = float(true_positive) / (true_positive + false_positive)\n",
        "    recall = float(true_positive) / (true_positive + false_negative)\n",
        "    f_score = float(2)*true_positive / (2*true_positive + false_positive + false_negative)\n",
        "    \n",
        "    return float(sum_loss)/len(data), float(100)*(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative), precision, recall, f_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nw0OYbTzBwJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define Loss function"
      ]
    },
    {
      "metadata": {
        "id": "PbQcwSIb96V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.BCELoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)#float(1)/epochs)#, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dqYSLXcj11HJ",
        "colab_type": "code",
        "outputId": "d8c22a51-997f-4002-a9aa-a4b8223a8c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "857"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 394
        }
      ]
    },
    {
      "metadata": {
        "id": "tuYAAQh2F6J8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "ad6MFVt7F5X8",
        "colab_type": "code",
        "outputId": "0548fcb3-17b8-4742-f6ed-71398235be20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5137
        }
      },
      "cell_type": "code",
      "source": [
        "import copy\n",
        "epochs = 100\n",
        "# the training loop\n",
        "total_time = 0.0\n",
        "train_epoch_history = []\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "precision = []\n",
        "recall = []\n",
        "f_score = []\n",
        "prev_val_loss = 0\n",
        "flag = 1\n",
        "for e in range(epochs):\n",
        "    tic = time.time() # start the timer\n",
        "    correct = 0\n",
        "    cumulative_loss = 0\n",
        "    incorrect = 0\n",
        "    \n",
        "    for i, instance in enumerate(train_data): # train_text_reviews \n",
        "        # get the training data\n",
        "        label = train_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "        \n",
        "        bow.zero_grad() # reset the gradient for each instance\n",
        "        \n",
        "#         bow_vec = Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') # vector repesentation of input sentence\n",
        "        \n",
        "#         pred = bow.forward(bow_vec) # forward pass ==> computes predictied values (1 or 0)\n",
        "        pred = bow.forward(instance)\n",
        "    \n",
        "        loss = loss_function(pred, label) # compute the loss\n",
        "        loss.backward() # backprop the loss\n",
        "        opt.step() # performs parameter updation based on the current gradient\n",
        "        \n",
        "        cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "        \n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "        if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "            correct += 1\n",
        "    \n",
        "    train_loss = float(cumulative_loss)/num_train_data\n",
        "    train_accuracy = correct*float(100)/num_train_data\n",
        "    train_epoch_history.append(e+1)\n",
        "    train_loss_history.append(train_loss)\n",
        "    \n",
        "    val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "    val_loss_history.append(val_loss)\n",
        "    \n",
        "    precision.append(p)\n",
        "    recall.append(r)\n",
        "    f_score.append(f)\n",
        "    \n",
        "#     if(abs(prev_val_loss-val_loss) < 0.001): # early stop if nearly no change\n",
        "#         precision.append(p)\n",
        "#         recall.append(r)\n",
        "#         f_score.append(f)\n",
        "#         stop_bow = copy.deepcopy(bow)\n",
        "#         break\n",
        "    prev_val_loss = val_loss\n",
        "    \n",
        "    toc = time.time() # final time\n",
        "    total_time += (toc-tic)\n",
        "    \n",
        "    print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "    print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "#     if(val_loss > train_loss and flag == 1):\n",
        "#         more_bow = copy.deepcopy(bow)\n",
        "#         flag = 0"
      ],
      "execution_count": 411,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 26.76s, Train Loss: 0.679297373, Train Accuracy: 65.50%\n",
            "[On Validation] ==> Precision: 0.712, Recall: 0.754, F-Score: 0.732, Val loss: 0.661329080, Val Accuracy: 72.42% Total Time: 26.76s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.638872922, Train Accuracy: 75.28%\n",
            "[On Validation] ==> Precision: 0.756, Recall: 0.795, F-Score: 0.775, Val loss: 0.618102632, Val Accuracy: 76.89% Total Time: 52.97s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.592058021, Train Accuracy: 78.58%\n",
            "[On Validation] ==> Precision: 0.779, Recall: 0.817, F-Score: 0.797, Val loss: 0.571868172, Val Accuracy: 79.22% Total Time: 79.17s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.544302700, Train Accuracy: 80.90%\n",
            "[On Validation] ==> Precision: 0.790, Recall: 0.830, F-Score: 0.810, Val loss: 0.527797175, Val Accuracy: 80.47% Total Time: 105.39s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.500748941, Train Accuracy: 82.33%\n",
            "[On Validation] ==> Precision: 0.799, Recall: 0.839, F-Score: 0.819, Val loss: 0.490272140, Val Accuracy: 81.39% Total Time: 131.62s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 26.33s, Train Loss: 0.464012645, Train Accuracy: 83.35%\n",
            "[On Validation] ==> Precision: 0.809, Recall: 0.846, F-Score: 0.827, Val loss: 0.460231487, Val Accuracy: 82.31% Total Time: 157.95s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 26.33s, Train Loss: 0.433817433, Train Accuracy: 84.24%\n",
            "[On Validation] ==> Precision: 0.813, Recall: 0.853, F-Score: 0.833, Val loss: 0.436520805, Val Accuracy: 82.83% Total Time: 184.28s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.408788017, Train Accuracy: 85.01%\n",
            "[On Validation] ==> Precision: 0.821, Recall: 0.859, F-Score: 0.839, Val loss: 0.417603191, Val Accuracy: 83.56% Total Time: 210.68s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.387576039, Train Accuracy: 85.74%\n",
            "[On Validation] ==> Precision: 0.824, Recall: 0.862, F-Score: 0.843, Val loss: 0.402198262, Val Accuracy: 83.89% Total Time: 236.92s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.369172648, Train Accuracy: 86.35%\n",
            "[On Validation] ==> Precision: 0.830, Recall: 0.868, F-Score: 0.849, Val loss: 0.389405566, Val Accuracy: 84.50% Total Time: 263.16s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 26.27s, Train Loss: 0.352903872, Train Accuracy: 86.99%\n",
            "[On Validation] ==> Precision: 0.834, Recall: 0.870, F-Score: 0.852, Val loss: 0.378602531, Val Accuracy: 84.83% Total Time: 289.43s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.338315722, Train Accuracy: 87.57%\n",
            "[On Validation] ==> Precision: 0.838, Recall: 0.869, F-Score: 0.853, Val loss: 0.369344465, Val Accuracy: 85.06% Total Time: 315.65s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.325094583, Train Accuracy: 88.03%\n",
            "[On Validation] ==> Precision: 0.843, Recall: 0.871, F-Score: 0.857, Val loss: 0.361347500, Val Accuracy: 85.42% Total Time: 341.91s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.313028213, Train Accuracy: 88.55%\n",
            "[On Validation] ==> Precision: 0.845, Recall: 0.872, F-Score: 0.858, Val loss: 0.354399026, Val Accuracy: 85.61% Total Time: 368.13s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.301956442, Train Accuracy: 89.07%\n",
            "[On Validation] ==> Precision: 0.849, Recall: 0.873, F-Score: 0.861, Val loss: 0.348330619, Val Accuracy: 85.86% Total Time: 394.37s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.291752214, Train Accuracy: 89.43%\n",
            "[On Validation] ==> Precision: 0.855, Recall: 0.874, F-Score: 0.864, Val loss: 0.343014338, Val Accuracy: 86.25% Total Time: 420.61s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.282309884, Train Accuracy: 89.77%\n",
            "[On Validation] ==> Precision: 0.855, Recall: 0.875, F-Score: 0.865, Val loss: 0.338351696, Val Accuracy: 86.31% Total Time: 446.81s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 26.51s, Train Loss: 0.273542484, Train Accuracy: 90.19%\n",
            "[On Validation] ==> Precision: 0.856, Recall: 0.875, F-Score: 0.865, Val loss: 0.334255563, Val Accuracy: 86.33% Total Time: 473.32s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.265376198, Train Accuracy: 90.64%\n",
            "[On Validation] ==> Precision: 0.858, Recall: 0.876, F-Score: 0.867, Val loss: 0.330651568, Val Accuracy: 86.53% Total Time: 499.55s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 26.42s, Train Loss: 0.257742912, Train Accuracy: 91.02%\n",
            "[On Validation] ==> Precision: 0.861, Recall: 0.877, F-Score: 0.869, Val loss: 0.327480370, Val Accuracy: 86.75% Total Time: 525.97s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 26.26s, Train Loss: 0.250585763, Train Accuracy: 91.33%\n",
            "[On Validation] ==> Precision: 0.862, Recall: 0.878, F-Score: 0.870, Val loss: 0.324691086, Val Accuracy: 86.86% Total Time: 552.23s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.243853380, Train Accuracy: 91.61%\n",
            "[On Validation] ==> Precision: 0.863, Recall: 0.879, F-Score: 0.871, Val loss: 0.322234508, Val Accuracy: 86.97% Total Time: 578.46s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.237501082, Train Accuracy: 91.84%\n",
            "[On Validation] ==> Precision: 0.866, Recall: 0.880, F-Score: 0.873, Val loss: 0.320069896, Val Accuracy: 87.17% Total Time: 604.68s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.231489886, Train Accuracy: 92.10%\n",
            "[On Validation] ==> Precision: 0.865, Recall: 0.882, F-Score: 0.873, Val loss: 0.318167040, Val Accuracy: 87.22% Total Time: 630.89s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.225786321, Train Accuracy: 92.33%\n",
            "[On Validation] ==> Precision: 0.866, Recall: 0.882, F-Score: 0.874, Val loss: 0.316497965, Val Accuracy: 87.31% Total Time: 657.13s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 26.26s, Train Loss: 0.220361219, Train Accuracy: 92.56%\n",
            "[On Validation] ==> Precision: 0.867, Recall: 0.884, F-Score: 0.875, Val loss: 0.315039517, Val Accuracy: 87.42% Total Time: 683.38s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.215188355, Train Accuracy: 92.78%\n",
            "[On Validation] ==> Precision: 0.868, Recall: 0.885, F-Score: 0.876, Val loss: 0.313767145, Val Accuracy: 87.47% Total Time: 709.63s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.210245365, Train Accuracy: 92.98%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.885, F-Score: 0.878, Val loss: 0.312663417, Val Accuracy: 87.72% Total Time: 735.85s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.205512924, Train Accuracy: 93.17%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.886, F-Score: 0.879, Val loss: 0.311712320, Val Accuracy: 87.81% Total Time: 762.07s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 26.52s, Train Loss: 0.200973498, Train Accuracy: 93.31%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.887, F-Score: 0.880, Val loss: 0.310899788, Val Accuracy: 87.89% Total Time: 788.59s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.196612053, Train Accuracy: 93.52%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.310212344, Val Accuracy: 87.94% Total Time: 814.81s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 26.41s, Train Loss: 0.192415325, Train Accuracy: 93.69%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.309642284, Val Accuracy: 88.08% Total Time: 841.22s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.188372243, Train Accuracy: 93.91%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.888, F-Score: 0.882, Val loss: 0.309180433, Val Accuracy: 88.06% Total Time: 867.41s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.184472276, Train Accuracy: 94.03%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.883, Val loss: 0.308819540, Val Accuracy: 88.17% Total Time: 893.63s\n",
            "Epoch 35/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.180706151, Train Accuracy: 94.17%\n",
            "[On Validation] ==> Precision: 0.877, Recall: 0.891, F-Score: 0.884, Val loss: 0.308551417, Val Accuracy: 88.28% Total Time: 919.81s\n",
            "Epoch 36/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.177065644, Train Accuracy: 94.34%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.891, F-Score: 0.883, Val loss: 0.308368647, Val Accuracy: 88.17% Total Time: 946.02s\n",
            "Epoch 37/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.173542993, Train Accuracy: 94.48%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308267432, Val Accuracy: 88.08% Total Time: 972.21s\n",
            "Epoch 38/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.170131476, Train Accuracy: 94.63%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308240262, Val Accuracy: 88.08% Total Time: 998.41s\n",
            "Epoch 39/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.166825024, Train Accuracy: 94.83%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.308284789, Val Accuracy: 88.06% Total Time: 1024.62s\n",
            "Epoch 40/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.163618183, Train Accuracy: 94.96%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.308394902, Val Accuracy: 88.06% Total Time: 1050.82s\n",
            "Epoch 41/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.160505985, Train Accuracy: 95.06%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.889, F-Score: 0.882, Val loss: 0.308566579, Val Accuracy: 88.08% Total Time: 1077.06s\n",
            "Epoch 42/100\n",
            "[On Training] ==> Time: 26.51s, Train Loss: 0.157483689, Train Accuracy: 95.21%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.308796396, Val Accuracy: 88.08% Total Time: 1103.57s\n",
            "Epoch 43/100\n",
            "[On Training] ==> Time: 26.41s, Train Loss: 0.154547107, Train Accuracy: 95.37%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.882, Val loss: 0.309080255, Val Accuracy: 88.14% Total Time: 1129.98s\n",
            "Epoch 44/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.151692116, Train Accuracy: 95.49%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.890, F-Score: 0.882, Val loss: 0.309414810, Val Accuracy: 88.11% Total Time: 1156.16s\n",
            "Epoch 45/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.148915068, Train Accuracy: 95.63%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.889, F-Score: 0.882, Val loss: 0.309796255, Val Accuracy: 88.06% Total Time: 1182.38s\n",
            "Epoch 46/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.146212468, Train Accuracy: 95.71%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.310221073, Val Accuracy: 88.08% Total Time: 1208.56s\n",
            "Epoch 47/100\n",
            "[On Training] ==> Time: 26.16s, Train Loss: 0.143581031, Train Accuracy: 95.78%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.310686921, Val Accuracy: 88.06% Total Time: 1234.72s\n",
            "Epoch 48/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.141017880, Train Accuracy: 95.87%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.891, F-Score: 0.883, Val loss: 0.311190352, Val Accuracy: 88.14% Total Time: 1260.92s\n",
            "Epoch 49/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.138520145, Train Accuracy: 96.00%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.311729762, Val Accuracy: 88.06% Total Time: 1287.11s\n",
            "Epoch 50/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.136085344, Train Accuracy: 96.11%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.892, F-Score: 0.883, Val loss: 0.312302100, Val Accuracy: 88.19% Total Time: 1313.29s\n",
            "Epoch 51/100\n",
            "[On Training] ==> Time: 26.17s, Train Loss: 0.133710914, Train Accuracy: 96.26%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.892, F-Score: 0.883, Val loss: 0.312904588, Val Accuracy: 88.22% Total Time: 1339.46s\n",
            "Epoch 52/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.131394590, Train Accuracy: 96.36%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.313536126, Val Accuracy: 88.19% Total Time: 1365.66s\n",
            "Epoch 53/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.129134130, Train Accuracy: 96.49%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.314195512, Val Accuracy: 88.19% Total Time: 1391.85s\n",
            "Epoch 54/100\n",
            "[On Training] ==> Time: 26.53s, Train Loss: 0.126927579, Train Accuracy: 96.57%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.893, F-Score: 0.884, Val loss: 0.314879142, Val Accuracy: 88.28% Total Time: 1418.37s\n",
            "Epoch 55/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.124773108, Train Accuracy: 96.62%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.895, F-Score: 0.884, Val loss: 0.315587096, Val Accuracy: 88.28% Total Time: 1444.77s\n",
            "Epoch 56/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.122668817, Train Accuracy: 96.72%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.895, F-Score: 0.884, Val loss: 0.316317065, Val Accuracy: 88.28% Total Time: 1470.97s\n",
            "Epoch 57/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.120613084, Train Accuracy: 96.81%\n",
            "[On Validation] ==> Precision: 0.875, Recall: 0.895, F-Score: 0.884, Val loss: 0.317067978, Val Accuracy: 88.31% Total Time: 1497.16s\n",
            "Epoch 58/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.118604452, Train Accuracy: 96.90%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.894, F-Score: 0.884, Val loss: 0.317838886, Val Accuracy: 88.22% Total Time: 1523.36s\n",
            "Epoch 59/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.116641392, Train Accuracy: 96.98%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.318628304, Val Accuracy: 88.22% Total Time: 1549.58s\n",
            "Epoch 60/100\n",
            "[On Training] ==> Time: 26.17s, Train Loss: 0.114722430, Train Accuracy: 97.07%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.319436472, Val Accuracy: 88.25% Total Time: 1575.75s\n",
            "Epoch 61/100\n",
            "[On Training] ==> Time: 26.14s, Train Loss: 0.112846568, Train Accuracy: 97.21%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.884, Val loss: 0.320260490, Val Accuracy: 88.25% Total Time: 1601.89s\n",
            "Epoch 62/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.111012556, Train Accuracy: 97.26%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.321100089, Val Accuracy: 88.19% Total Time: 1628.07s\n",
            "Epoch 63/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.109219486, Train Accuracy: 97.32%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.893, F-Score: 0.883, Val loss: 0.321956148, Val Accuracy: 88.19% Total Time: 1654.27s\n",
            "Epoch 64/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.107466255, Train Accuracy: 97.40%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.890, F-Score: 0.882, Val loss: 0.322825972, Val Accuracy: 88.06% Total Time: 1680.51s\n",
            "Epoch 65/100\n",
            "[On Training] ==> Time: 26.16s, Train Loss: 0.105751793, Train Accuracy: 97.49%\n",
            "[On Validation] ==> Precision: 0.874, Recall: 0.891, F-Score: 0.882, Val loss: 0.323710920, Val Accuracy: 88.08% Total Time: 1706.67s\n",
            "Epoch 66/100\n",
            "[On Training] ==> Time: 26.47s, Train Loss: 0.104075409, Train Accuracy: 97.58%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.324609001, Val Accuracy: 88.03% Total Time: 1733.14s\n",
            "Epoch 67/100\n",
            "[On Training] ==> Time: 26.40s, Train Loss: 0.102435752, Train Accuracy: 97.62%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.325516345, Val Accuracy: 88.06% Total Time: 1759.54s\n",
            "Epoch 68/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.100831526, Train Accuracy: 97.67%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.326436538, Val Accuracy: 88.00% Total Time: 1785.73s\n",
            "Epoch 69/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.099261922, Train Accuracy: 97.70%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.327367045, Val Accuracy: 87.97% Total Time: 1811.95s\n",
            "Epoch 70/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.097725976, Train Accuracy: 97.78%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.328301827, Val Accuracy: 87.97% Total Time: 1838.13s\n",
            "Epoch 71/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.096222205, Train Accuracy: 97.83%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.329249859, Val Accuracy: 87.97% Total Time: 1864.34s\n",
            "Epoch 72/100\n",
            "[On Training] ==> Time: 26.22s, Train Loss: 0.094750187, Train Accuracy: 97.88%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.888, F-Score: 0.881, Val loss: 0.330205498, Val Accuracy: 87.94% Total Time: 1890.56s\n",
            "Epoch 73/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.093308947, Train Accuracy: 97.91%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.889, F-Score: 0.881, Val loss: 0.331164432, Val Accuracy: 87.97% Total Time: 1916.80s\n",
            "Epoch 74/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.091897275, Train Accuracy: 98.01%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.332132887, Val Accuracy: 88.00% Total Time: 1942.99s\n",
            "Epoch 75/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.090514228, Train Accuracy: 98.03%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.333107599, Val Accuracy: 88.03% Total Time: 1969.21s\n",
            "Epoch 76/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.089159492, Train Accuracy: 98.09%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.334085990, Val Accuracy: 88.03% Total Time: 1995.43s\n",
            "Epoch 77/100\n",
            "[On Training] ==> Time: 26.29s, Train Loss: 0.087831673, Train Accuracy: 98.15%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.335069037, Val Accuracy: 88.03% Total Time: 2021.72s\n",
            "Epoch 78/100\n",
            "[On Training] ==> Time: 26.54s, Train Loss: 0.086529938, Train Accuracy: 98.17%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.336058138, Val Accuracy: 87.97% Total Time: 2048.27s\n",
            "Epoch 79/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.085254390, Train Accuracy: 98.21%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.337053001, Val Accuracy: 87.97% Total Time: 2074.48s\n",
            "Epoch 80/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.084003299, Train Accuracy: 98.24%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.338050195, Val Accuracy: 88.00% Total Time: 2100.68s\n",
            "Epoch 81/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.082776687, Train Accuracy: 98.29%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.891, F-Score: 0.882, Val loss: 0.339053772, Val Accuracy: 88.03% Total Time: 2126.89s\n",
            "Epoch 82/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.081573685, Train Accuracy: 98.33%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.340057327, Val Accuracy: 88.00% Total Time: 2153.14s\n",
            "Epoch 83/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.080393474, Train Accuracy: 98.38%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.341066413, Val Accuracy: 88.00% Total Time: 2179.33s\n",
            "Epoch 84/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.079235320, Train Accuracy: 98.41%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.342081223, Val Accuracy: 87.94% Total Time: 2205.52s\n",
            "Epoch 85/100\n",
            "[On Training] ==> Time: 26.27s, Train Loss: 0.078099612, Train Accuracy: 98.44%\n",
            "[On Validation] ==> Precision: 0.871, Recall: 0.890, F-Score: 0.880, Val loss: 0.343093368, Val Accuracy: 87.89% Total Time: 2231.79s\n",
            "Epoch 86/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.076984337, Train Accuracy: 98.47%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.344113503, Val Accuracy: 88.03% Total Time: 2258.03s\n",
            "Epoch 87/100\n",
            "[On Training] ==> Time: 26.23s, Train Loss: 0.075890145, Train Accuracy: 98.50%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.345134929, Val Accuracy: 88.03% Total Time: 2284.27s\n",
            "Epoch 88/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.074816057, Train Accuracy: 98.53%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.346159078, Val Accuracy: 88.03% Total Time: 2310.47s\n",
            "Epoch 89/100\n",
            "[On Training] ==> Time: 26.38s, Train Loss: 0.073761446, Train Accuracy: 98.55%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.891, F-Score: 0.882, Val loss: 0.347186013, Val Accuracy: 88.03% Total Time: 2336.85s\n",
            "Epoch 90/100\n",
            "[On Training] ==> Time: 26.44s, Train Loss: 0.072726029, Train Accuracy: 98.57%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.890, F-Score: 0.881, Val loss: 0.348216161, Val Accuracy: 87.97% Total Time: 2363.30s\n",
            "Epoch 91/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.071709603, Train Accuracy: 98.62%\n",
            "[On Validation] ==> Precision: 0.873, Recall: 0.890, F-Score: 0.881, Val loss: 0.349248491, Val Accuracy: 88.00% Total Time: 2389.54s\n",
            "Epoch 92/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.070711397, Train Accuracy: 98.66%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.881, Val loss: 0.350285411, Val Accuracy: 87.94% Total Time: 2415.73s\n",
            "Epoch 93/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.069731427, Train Accuracy: 98.69%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.881, Val loss: 0.351320800, Val Accuracy: 87.94% Total Time: 2441.91s\n",
            "Epoch 94/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.068768684, Train Accuracy: 98.75%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.352363629, Val Accuracy: 87.89% Total Time: 2468.13s\n",
            "Epoch 95/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.067824077, Train Accuracy: 98.76%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.353403394, Val Accuracy: 87.89% Total Time: 2494.31s\n",
            "Epoch 96/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.066895709, Train Accuracy: 98.80%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.354449597, Val Accuracy: 87.86% Total Time: 2520.55s\n",
            "Epoch 97/100\n",
            "[On Training] ==> Time: 26.20s, Train Loss: 0.065984506, Train Accuracy: 98.83%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.355497148, Val Accuracy: 87.89% Total Time: 2546.75s\n",
            "Epoch 98/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.065089669, Train Accuracy: 98.86%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.889, F-Score: 0.880, Val loss: 0.356547937, Val Accuracy: 87.92% Total Time: 2572.94s\n",
            "Epoch 99/100\n",
            "[On Training] ==> Time: 26.18s, Train Loss: 0.064210602, Train Accuracy: 98.90%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.357605798, Val Accuracy: 87.92% Total Time: 2599.12s\n",
            "Epoch 100/100\n",
            "[On Training] ==> Time: 26.24s, Train Loss: 0.063348536, Train Accuracy: 98.92%\n",
            "[On Validation] ==> Precision: 0.872, Recall: 0.888, F-Score: 0.880, Val loss: 0.358660772, Val Accuracy: 87.92% Total Time: 2625.35s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RsIuCobJmOel",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28da51a8-e262-490b-f7a0-d0f971dd7586"
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "682"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 412
        }
      ]
    },
    {
      "metadata": {
        "id": "FDUyFfwmXSew",
        "colab_type": "code",
        "outputId": "d4ad7699-7eac-45fd-9f7c-3ec4ad3ee351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(\"Image\")\n",
        "plt.title(\"Loss vs Epoch\")\n",
        "val_loss_history =  [float(i)/sum(val_loss_history) for i in val_loss_history] # normalised between 0-1\n",
        "train_loss_history =  [float(i)/sum(train_loss_history) for i in train_loss_history] # normalised between 0-1\n",
        "plt.plot(val_loss_history, c=\"blue\", label=\"Validation Loss\")\n",
        "plt.plot(train_loss_history, c=\"red\", label = \"Training Loss\")\n",
        "plt.legend()"
      ],
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29b4c54ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 413
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAFZCAYAAAC173eYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjT6qgGhQgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "gPf_k4VNuaDi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1428
        },
        "outputId": "3e42aef5-61c0-48f3-b750-d9683cb166b6"
      },
      "cell_type": "code",
      "source": [
        "# for param in bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())\n",
        "# print ()\n",
        "# for param in stop_bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())\n",
        "# print()\n",
        "# for param in more_bow.parameters(): # desc the parameter value\n",
        "#     print(param,param.size())    "
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0251,  0.0234,  0.0139,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0283,  0.0236,  0.0196,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0124,  0.0111,  0.0069,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0349,  0.0284,  0.0231,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0321,  0.0285,  0.0222,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0331,  0.0223,  0.0154,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0297,  0.0355,  0.0179,  0.0379,  0.0151,  0.0306,  0.0269,  0.0353,\n",
            "         0.0493,  0.0564,  0.0189,  0.0347,  0.0497,  0.0484,  0.0505,  0.0574,\n",
            "         0.0327,  0.0662,  0.0271,  0.0245, -0.0009,  0.0664,  0.0100,  0.0288,\n",
            "         0.0213,  0.0148,  0.0469,  0.0575,  0.0158,  0.0303, -0.0020,  0.0497,\n",
            "         0.0514,  0.0325,  0.0085,  0.0433,  0.0248,  0.0517,  0.0318,  0.0022,\n",
            "         0.0388,  0.0528,  0.0238,  0.0229,  0.0087,  0.0645,  0.0423,  0.0407,\n",
            "         0.0468,  0.0392], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.3265,  0.3968, -0.1680,  0.4423,  0.1295,  0.3108, -0.2848, -0.3566,\n",
            "          0.5830, -0.5779,  0.2131,  0.4034, -0.5115,  0.5584,  0.5957, -0.6153,\n",
            "          0.3476, -0.6775,  0.2956, -0.2547, -0.0066, -0.6576, -0.0947,  0.3579,\n",
            "          0.2948,  0.1862,  0.5887, -0.5654,  0.1805,  0.2991,  0.0412, -0.5288,\n",
            "         -0.5669, -0.2938, -0.0771,  0.4797,  0.2796,  0.5872,  0.4137, -0.0401,\n",
            "         -0.4411, -0.5464,  0.2503,  0.2109, -0.0322, -0.6095,  0.4870,  0.4859,\n",
            "         -0.5027,  0.4415]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0347], device='cuda:0', requires_grad=True) torch.Size([1])\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.0251,  0.0234,  0.0139,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0283,  0.0236,  0.0196,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0124,  0.0111,  0.0069,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0349,  0.0284,  0.0231,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0321,  0.0285,  0.0222,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0331,  0.0223,  0.0154,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0297,  0.0355,  0.0179,  0.0379,  0.0151,  0.0306,  0.0269,  0.0353,\n",
            "         0.0493,  0.0564,  0.0189,  0.0347,  0.0497,  0.0484,  0.0505,  0.0574,\n",
            "         0.0327,  0.0662,  0.0271,  0.0245, -0.0009,  0.0664,  0.0100,  0.0288,\n",
            "         0.0213,  0.0148,  0.0469,  0.0575,  0.0158,  0.0303, -0.0020,  0.0497,\n",
            "         0.0514,  0.0325,  0.0085,  0.0433,  0.0248,  0.0517,  0.0318,  0.0022,\n",
            "         0.0388,  0.0528,  0.0238,  0.0229,  0.0087,  0.0645,  0.0423,  0.0407,\n",
            "         0.0468,  0.0392], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.3265,  0.3968, -0.1680,  0.4423,  0.1295,  0.3108, -0.2848, -0.3566,\n",
            "          0.5830, -0.5779,  0.2131,  0.4034, -0.5115,  0.5584,  0.5957, -0.6153,\n",
            "          0.3476, -0.6775,  0.2956, -0.2547, -0.0066, -0.6576, -0.0947,  0.3579,\n",
            "          0.2948,  0.1862,  0.5887, -0.5654,  0.1805,  0.2991,  0.0412, -0.5288,\n",
            "         -0.5669, -0.2938, -0.0771,  0.4797,  0.2796,  0.5872,  0.4137, -0.0401,\n",
            "         -0.4411, -0.5464,  0.2503,  0.2109, -0.0322, -0.6095,  0.4870,  0.4859,\n",
            "         -0.5027,  0.4415]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0347], device='cuda:0', requires_grad=True) torch.Size([1])\n",
            "\n",
            "Parameter containing:\n",
            "tensor([[ 0.0224,  0.0190,  0.0079,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0186,  0.0160,  0.0158,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0091,  0.0072,  0.0049,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0241,  0.0203,  0.0187,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0281,  0.0233,  0.0154,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0217,  0.0171,  0.0144,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True) torch.Size([50, 30941])\n",
            "Parameter containing:\n",
            "tensor([ 0.0122,  0.0231,  0.0082,  0.0242,  0.0107,  0.0208,  0.0134,  0.0167,\n",
            "         0.0309,  0.0271,  0.0114,  0.0204,  0.0251,  0.0314,  0.0312,  0.0259,\n",
            "         0.0217,  0.0345,  0.0183,  0.0121, -0.0009,  0.0355,  0.0046,  0.0164,\n",
            "         0.0111,  0.0075,  0.0286,  0.0279,  0.0098,  0.0208, -0.0039,  0.0248,\n",
            "         0.0236,  0.0172,  0.0030,  0.0280,  0.0162,  0.0343,  0.0191, -0.0013,\n",
            "         0.0170,  0.0272,  0.0163,  0.0157,  0.0065,  0.0338,  0.0281,  0.0254,\n",
            "         0.0215,  0.0261], device='cuda:0', requires_grad=True) torch.Size([50])\n",
            "Parameter containing:\n",
            "tensor([[-0.1625,  0.2001, -0.0881,  0.2204,  0.0656,  0.1546, -0.1428, -0.1765,\n",
            "          0.2900, -0.2910,  0.1096,  0.2006, -0.2553,  0.2776,  0.2985, -0.3062,\n",
            "          0.1739, -0.3365,  0.1486, -0.1321, -0.0063, -0.3298, -0.0471,  0.1794,\n",
            "          0.1481,  0.0928,  0.2952, -0.2823,  0.0931,  0.1492,  0.0338, -0.2638,\n",
            "         -0.2823, -0.1496, -0.0396,  0.2407,  0.1393,  0.2916,  0.2089, -0.0208,\n",
            "         -0.2183, -0.2727,  0.1239,  0.1076, -0.0202, -0.3057,  0.2407,  0.2449,\n",
            "         -0.2526,  0.2187]], device='cuda:0', requires_grad=True) torch.Size([1, 50])\n",
            "Parameter containing:\n",
            "tensor([0.0463], device='cuda:0', requires_grad=True) torch.Size([1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fkYBaktsF-sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in test_text_reviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffYv5PAmjyp-",
        "colab_type": "code",
        "outputId": "605b4a5e-9190-49a2-8831-b56192625bba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "correct = 0\n",
        "tic = time.time()\n",
        "for i, instance in enumerate(data):\n",
        "    label = test_text_labels[i]\n",
        "    pred = bow.forward(instance)\n",
        "#     pred = more_bow.forward(instance)\n",
        "#     pred = stop_bow.forward(instance)\n",
        "    pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "    \n",
        "    if(int(label) == pred_class):\n",
        "        correct += 1\n",
        "toc = time.time()\n",
        "print(\"Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data)))"
      ],
      "execution_count": 414,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n",
            "Time: 2.3922858238220215, Test Accuracy: 88.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uHAvtGWbudLN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "cf9aaa61-26d3-4e0e-8dee-a38eb47bcbb1"
      },
      "cell_type": "code",
      "source": [
        "torch.save(bow, 'Task1A.mdl')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"Task1A.mdl\")"
      ],
      "execution_count": 415,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zz5PwYjVudEk",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d5ccd8bf-7d91-4ef7-b37b-e4a39ebd842b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()"
      ],
      "execution_count": 416,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-79bed7f2-c754-4385-837e-e16ff1f7ab53\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-79bed7f2-c754-4385-837e-e16ff1f7ab53\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Task1A.mdl to Task1A (1).mdl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29twCfxpuc8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_model_ = torch.load(io.BytesIO(temp_test['Task1A.mdl']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ixy30WkrH3_-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "38c445b3-70f5-45b7-f5fc-a98fd76df239"
      },
      "cell_type": "code",
      "source": [
        "for params in _model_.parameters():\n",
        "    print (params)"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0261,  0.0221,  0.0165,  ..., -0.0042, -0.0004, -0.0055],\n",
            "        [ 0.0266,  0.0270,  0.0171,  ..., -0.0006, -0.0056,  0.0031],\n",
            "        [ 0.0152,  0.0111,  0.0046,  ..., -0.0007,  0.0044,  0.0056],\n",
            "        ...,\n",
            "        [ 0.0340,  0.0254,  0.0204,  ...,  0.0040,  0.0004, -0.0002],\n",
            "        [ 0.0323,  0.0227,  0.0225,  ..., -0.0038, -0.0009,  0.0004],\n",
            "        [ 0.0352,  0.0154,  0.0106,  ...,  0.0023, -0.0001,  0.0027]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0355,  0.0442,  0.0223,  0.0447,  0.0201,  0.0354,  0.0306,  0.0417,\n",
            "         0.0565,  0.0647,  0.0215,  0.0432,  0.0580,  0.0563,  0.0606,  0.0675,\n",
            "         0.0388,  0.0760,  0.0272,  0.0324, -0.0007,  0.0737,  0.0119,  0.0335,\n",
            "         0.0316,  0.0209,  0.0557,  0.0693,  0.0163,  0.0389,  0.0016,  0.0559,\n",
            "         0.0609,  0.0391,  0.0114,  0.0536,  0.0292,  0.0587,  0.0381,  0.0036,\n",
            "         0.0454,  0.0594,  0.0273,  0.0265,  0.0096,  0.0742,  0.0530,  0.0476,\n",
            "         0.0559,  0.0517], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.5615,  0.6852, -0.2882,  0.7626,  0.2254,  0.5352, -0.4892, -0.6133,\n",
            "          1.0005, -0.9908,  0.3702,  0.7004, -0.8739,  0.9629,  1.0271, -1.0576,\n",
            "          0.6003, -1.1655,  0.5059, -0.4314, -0.0098, -1.1250, -0.1615,  0.6162,\n",
            "          0.5057,  0.3194,  1.0106, -0.9704,  0.3083,  0.5165,  0.0655, -0.9062,\n",
            "         -0.9707, -0.5013, -0.1331,  0.8262,  0.4815,  1.0114,  0.7084, -0.0698,\n",
            "         -0.7600, -0.9379,  0.4303,  0.3599, -0.0572, -1.0431,  0.8399,  0.8347,\n",
            "         -0.8567,  0.7620]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0355], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ub0HKgL8H37z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCraW41hH32S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mhftDt1DH3x6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE_TcX1KH3tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T60wqxmoH3Zl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}