{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuB0HM37teAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "rKlXTA5zfx20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Run on **GPU**\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "_NV6CE-qtvGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Header Files"
      ]
    },
    {
      "metadata": {
        "id": "WE7OEcPOtzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4037ccUuFFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset and Visualise"
      ]
    },
    {
      "metadata": {
        "id": "EhWFepP2t3eA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_train.head()\n",
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Train_20K.csv\"\n",
        "df = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mvAXyCoDaR3b",
        "colab_type": "code",
        "outputId": "5a2e15e4-3bfb-4c90-f5a9-460d0305825b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "44YtF48vX24a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_1 = df[df['label']==1] # get only label == 1\n",
        "df_0 = df[df['label']==0] # get only label == 0\n",
        "\n",
        "range_1 = int(0.9*len(df_1))\n",
        "range_2 = int(0.9*len(df_0))\n",
        "\n",
        "np.random.seed(42) # fix the seed value\n",
        "df_1 = df_1.iloc[np.random.permutation(len(df_1))] # shuffled the data set of label==1\n",
        "df_0 = df_0.iloc[np.random.permutation(len(df_0))] # shuffled the data set of label==0\n",
        "\n",
        "temp_1_train = df_1.iloc[:range_1]\n",
        "temp_2_train = df_0.iloc[:range_2]\n",
        "df_train = pd.concat([temp_1_train, temp_2_train])\n",
        "\n",
        "temp_1_val = df_1.iloc[range_1:]\n",
        "temp_2_val = df_0.iloc[range_2:]\n",
        "df_val = pd.concat([temp_1_val, temp_2_val])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9FBTqABuRlO",
        "colab_type": "code",
        "outputId": "6f72a4a2-3bf6-4848-9ea0-7bd5babce437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "df_train = df_train.iloc[np.random.permutation(len(df_train))] # shuffled the data set of label==1\n",
        "df_val = df_val.iloc[np.random.permutation(len(df_val))] # shuffled the data set of label==1\n",
        "len(df_train), len(df_val)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16198, 1801)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "0WFB1TtsxD3F",
        "colab_type": "code",
        "outputId": "82750718-45dc-456c-aeb5-834e95d7ba8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_train[df_train['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_train[df_train['label']==1]))\n",
        "print('Number of movie reviews', len(df_train['label']))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8094\n",
            "Number of Positive movie reviews 8104\n",
            "Number of movie reviews 16198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sYtzJk8r3lm5",
        "colab_type": "code",
        "outputId": "02cc2745-51a6-4288-82a1-1ae12f8a8162",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_val[df_val['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_val[df_val['label']==1]))\n",
        "print('Number of movie reviews', len(df_val['label']))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 900\n",
            "Number of Positive movie reviews 901\n",
            "Number of movie reviews 1801\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uuZxOMpkQoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/binny-mathew/IITKGP_CS69002_Spring_2019/master/Dataset/Test_5K.csv\"\n",
        "df_test = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TVzhPcGGxf2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "u-8IR64TKH0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Get Train Data"
      ]
    },
    {
      "metadata": {
        "id": "JprKnOXgxXkE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_raw_text_reviews = df_train['text'].astype(str).tolist()\n",
        "train_text_labels = df_train['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TwU4zROpKLdQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Validation Data"
      ]
    },
    {
      "metadata": {
        "id": "7TsL1ACWJ_3V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_raw_text_reviews = df_val['text'].astype(str).tolist()\n",
        "val_text_labels = df_val['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YixDzEnXLZN-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Get Test Data"
      ]
    },
    {
      "metadata": {
        "id": "MQHaSpnJJ9eT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_raw_text_reviews = df_test['text'].astype(str).tolist()\n",
        "test_text_labels = df_test['label'].astype(int).tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ui-q6WRqOrB4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Cleaning the raw input data"
      ]
    },
    {
      "metadata": {
        "id": "8_4b4FmShb0u",
        "colab_type": "code",
        "outputId": "3c2c9b47-4eea-4d18-b5fa-ac1c9d0930e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "# import nltk\n",
        "# nltk.download(\"stopwords\")\n",
        "# from nltk.corpus import stopwords\n",
        "\n",
        "# # Finding stop words\n",
        "# stop_words = set(stopwords.words('english'))\n",
        "\n",
        "import spacy\n",
        "print('spaCy Version: %s' % (spacy.__version__))\n",
        "spacy_nlp = spacy.load('en_core_web_sm')\n",
        "# stop word list\n",
        "stop_words = set(spacy.lang.en.stop_words.STOP_WORDS)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spaCy Version: 2.0.18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s3AxEhD_z1DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def preprocess_document(doc):\n",
        "    # negative sense should not be eleminated + some short representation\n",
        "    CONTRACTIONS = {\"didn't\":\"did not\", \"mayn't\":\"may not\", \"can't\":\"can not\", \"won't\":\"will not\", \"isn't\":\"is not\", \"amn't\":\"am not\",\\\n",
        "                  \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"couldn't\":\"could not\", \\\n",
        "                  \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\\\n",
        "                  \"i'll\":\"i will\", \"you'll\":\"you will\", \"they'll\":\"they will\",\\\n",
        "                  \"may've\":\"may have\", \"can've\":\"can have\", \"will've\":\"will have\", \"you've\":\"you have\", \\\n",
        "                  \"could've\":\"could have\", \"would've\":\"would have\", \"you've\":\"you have\", \"they\":\"they have\",\\\n",
        "                  \"i've\":\"i have\", \"you've\":\"you have\", \"we've\":\"we have\", \"there's\":\"there is\", \"i'm\":\"i am\",\\\n",
        "                  \"it's\":\"it is\", \"what's\":\"what is\", \"where's\":\"where is\", \"how's\":\"how is\", \"i'd\":\"i had\"}\n",
        "    punctuation = string.punctuation + \"\\n\\n\"\n",
        "    punc_replace = ''.join([' ' for s in punctuation]) # required for replacing punctuation with null ('')\n",
        "    doc_clean = doc.replace('-', ' ') # replace - with null str\n",
        "    doc_clean = (doc_clean.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "    doc_clean = doc_clean.replace('<br />', '') # replace <br /> with ''\n",
        "    doc_clean = doc_clean.replace(\"’\", \"'\") # replace <br /> with null str\n",
        "    doc_clean = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in doc_clean.split(' ')] # replacing some common short forms\n",
        "    doc_clean = \" \".join(doc_clean) # list to sentence of strings\n",
        "    doc_clean = re.sub(r'\\W +', ' ', doc_clean) # except [a-zA-Z0-9_]\n",
        "    doc_clean = re.sub(r'\\d+', ' ', doc_clean) # remove numbers [0-9]\n",
        "    trans_table = str.maketrans(punctuation, punc_replace); # replace punctuations with ' '\n",
        "    doc_clean = ' '.join([word.translate(trans_table) for word in doc_clean.split(' ')])\n",
        "    doc_clean = doc_clean.split(' ')\n",
        "    doc_clean = [word for word in doc_clean if len(word) > 0]\n",
        "    # removing the stopwords from a sentence\n",
        "    doc_clean = [word for word in doc_clean if not word.lower() in stop_words or word.lower() == 'not' or word.lower() == 'no']\n",
        "    return doc_clean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSNuXUopzavX",
        "colab_type": "code",
        "outputId": "274b598d-9bcf-45c7-ba52-205d26c132fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_reviews = [preprocess_document(review.lower()) for review in train_raw_text_reviews]\n",
        "print (train_text_reviews[len(train_text_reviews)-2])\n",
        "print (train_text_labels[len(train_text_labels)-2])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tales', 'told', 'film', 'shot', 'knowledge', 'combined', 'vignette', 'film', 'makers', 'relate', 'vignettes', 'having', 'connected', 'shrink', 'martin', 'kove', 'leads', 'kove', 'vignette', 'sexy', 'vivian', 'schilling', 'woman', 'afraid', 'sun', 'makes', 'adrian', 'monk', 'look', 'brave', 'having', 'paranoia', 'laced', 'evening', 'home', 'literally', 'scream', 'vivian', 'ridiculous', 'things', 'spends', 'majority', 'time', 'nighty', 'shows', 'amazing', 'features', 'film', 'worst', 'not', 'nail', 'biting', 'second', 'vignette', 'owned', 'bill', 'paxton', 'portrays', 'roommate', 'hell', 'geeky', 'roommate', 'allows', 'complete', 'advantage', 'bill', 'vignette', 'funny', 'man', 'fears', 'death', 'moment', 'like', 'pal', 'choked', 'death', 'olive', 'not', 'interesting', 'movie', 'chopped', 'little', 'thought', 'involved', 'bill', 'paxton', 'fans']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W6psZ2jxNOoP",
        "colab_type": "code",
        "outputId": "52f8ede2-9231-4f73-a580-9cbb94a8af23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "val_text_reviews = [preprocess_document(review.lower()) for review in val_raw_text_reviews]\n",
        "print (val_text_reviews[len(val_text_reviews)-2])\n",
        "print (val_text_labels[len(val_text_labels)-2])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['not', 'realize', 'sellers', 'poor', 'health', 'time', 'filming', 'passed', 'away', 'film', 's', 'release', 'fiendish', 'plot', 'dr', 'fu', 'manchu', 'painful', 'viewing', 'supposedly', 'lampoon', 'sax', 'rohmer', 's', 'famous', 'oriental', 'villain', 'lacks', 'focus', 'potential', 'satirical', 'commentary', 'anti', 'oriental', 'overtones', 'rohmer', 's', 'concept', 'ignored', 'movie', 'employs', 'racist', 'insults', 'hardly', 'actual', 'jokes', 'gags', 'actors', 'behaving', 'idiotically', 'spouting', 'dreary', 'lines', 'especially', 'distressing', 'sid', 'caesar', 'forced', 'spout', 'curses', 'racial', 'slurs', 'attempted', 'laughs', 'actors', 'embarrass', 'peter', 'sellers', 'plays', 'dual', 'roles', 'sinister', 'fu', 'manchu', 'trying', 'concoct', 'formula', 'regain', 'youth', 'stalwart', 'british', 'foe', 'nayland', 'smith', 'sellers', 'not', 'cent', 'bad', 'conveys', 'quirky', 'warmth', 'smith', 'discusses', 'fetishistic', 'attachment', 'lawn', 'mower', 's', 'oddly', 'moving', 'manchu', 'expresses', 'love', 'english', 'music', 'hall', 'entertainment', 'time', 'plays', 'roles', 'weary', 'grimness', 'sabotaging', 'comical', 'possibilities', 'sellers', 'routines', 'revitalizes', 'fading', 'strength', 'electric', 'shocks', 'particularly', 'excruciating', 'convincingly', 'agonized', 'funny', 'genuinely', 'witty', 'lines', 'apt', 'slapstick', 'bit', 'burt', 'kwouk', 'cato', 'pink', 'panther', 'films', 'manchu', 's', 'minions', 'helen', 'mirren', 's', 'amusing', 'musical', 'numbers', 'salvage', 'mess', 'wants', 'understand', 'peter', 'sellers', 'considered', 'comedic', 'genius', 'not', 'learn', 'fiendish', 'plot', 'dr', 'fu', 'manchu']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REdaGj3VNOEX",
        "colab_type": "code",
        "outputId": "2a0949db-8448-497b-ccff-eccf74583f92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "test_text_reviews = [preprocess_document(review.lower()) for review in test_raw_text_reviews]\n",
        "print (test_text_reviews[len(test_text_reviews)-2])\n",
        "print (test_text_labels[len(test_text_labels)-2])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['shining', 'know', 'weird', 'movie', 'movie', 'people', 'claim', 'not', 'like', 'horror', 'films', 'shining', 'terrific', 'film', 'stanley', 'kubrick', 's', 'classic', 'vision', 'stephen', 'king', 's', 'horror', 'tale', 'madness', 'blood', 'incredible', 'film', 'wither', 'seen', 'not', 'heard', 'know', 'lines', 'know', 'classic', 'images', 'forget', 'jack', 's', 's', 'johnny', 'forget', 'work', 'no', 'play', 'jack', 'dull', 'boy', 'forget', 'chilling', 'ending', 'film', 'unforgettable', 'honestly', 'opinion', 'kubrick', 's', 'best', 'work', 'know', 'lot', 'argument', 'department', 'lot', 'people', 'space', 'odyssey', 'clockwork', 'orange', 'dr', 'strangelove', 'film', 'pioneered', 'film', 'making', 'shining', 'perfected', 'tale', 'isolation', 'madness', 'terrifying', 'images', 'ultimate', 'ghost', 'story', 'crawl', 'underneath', 'skin', 'jack', 'torrance', 'jack', 's', 'son', 'danny', 'jack', 's', 'wife', 'wendy', 'arrive', 'overlook', 'hotel', 'closing', 'day', 'elderly', 'african', 'american', 'chef', 'dick', 'hallorann', 'surprises', 'danny', 'speaking', 'telepathically', 'offering', 'ice', 'cream', 'explains', 'danny', 'grandmother', 'shared', 'gift', 'called', 'communication', 'shining', 'danny', 'asks', 'afraid', 'hotel', 'particularly', 'room', 'dick', 'tells', 'danny', 'hotel', 'certain', 'shine', 'memories', 'not', 'good', 'advises', 'stay', 'room', 'circumstances', 'danny', 's', 'curiosity', 'room', 'finally', 'gets', 'better', 'sees', 'room', 'opened', 'danny', 'shows', 'injured', 'visibly', 'traumatized', 'jack', 'tells', 'wendy', 'loves', 'family', 'seeing', 'wendy', 'thinks', 'jack', 'abusing', 'danny', 'jack', 'wanders', 'hotel', 's', 'gold', 'room', 'meets', 'ghostly', 'bartender', 'named', 'lloyd', 'danny', 'starts', 'calling', 'word', 'redrum', 'frantically', 'scribbling', 'walls', 'goes', 'trance', 'withdraws', 'says', 'tony', 'imaginary', 'friend', 'jack', 'sabotages', 'hotel', 'radio', 'cutting', 'communication', 'outside', 'world', 'hallorann', 'received', 'danny', 's', 'telepathic', 'cry', 'help', 'way', 'wendy', 'discovers', 'jack', 'typing', 'endless', 'pages', 'manuscript', 'repeating', 'work', 'no', 'play', 'makes', 'jack', 'dull', 'boy', 'formatted', 'ways', 'horrified', 'jack', 'threatens', 'knocks', 'unconscious', 'baseball', 'bat', 'locking', 'storage', 'locker', 'kitchen', 'jack', 'converses', 'grady', 'door', 'locker', 'unlocks', 'releasing', 'danny', 'written', 'redrum', 'lipstick', 'door', 'wendy', 's', 'bedroom', 'looks', 'mirror', 'sees', 'murder', 'spelled', 'backwards', 'jack', 'picks', 'axe', 'begins', 'chop', 'door', 'leading', 'family', 's', 'living', 'quarters', 's', 'johnny', 'jack', 's', 'legendary', 'image', 'born', 'shining', 'films', 'seriously', 'time', 'incredible', 'film', 'gives', 'nightmares', 'jack', 'nicholson', 's', 'performance', 'timeless', 'unforgettable', 'feel', 'extremely', 'overlooked', 'shelley', 'duvall', 'scene', 'finding', 'jack', 's', 'rant', 'work', 'incredible', 's', 'look', 'horror', 'fear', 'face', 'realizing', 'husband', 'mad', 'incredible', 'scene', 'jack', 'sees', 'ghost', 'woman', 'bathtub', 'honestly', 'terrifying', 'scenes', 'horror', 'cinema', 'reason', 'film', 'known', 'film', 'perfection', 'simpsons', 'shown', 'films', 'film', 'forever', 'stay', 'trust']\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ydrqMX261kQ-",
        "colab_type": "code",
        "outputId": "8fb69af3-576d-4255-db7e-996d15273808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "metadata": {
        "id": "xWfJK2HvwwQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_vocabulary(sentences):\n",
        "    # Build vocabulary\n",
        "    dictWordCount = {}\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] = 0 # initialising the dict value to zero\n",
        "    for sent in sentences:\n",
        "        for word in sent:\n",
        "            dictWordCount[word] += 1 # updating the dictionary count\n",
        "    \n",
        "    temp = dictWordCount.copy()\n",
        "    for key, val in temp.items():\n",
        "        if(dictWordCount[key] <= 10):\n",
        "            del dictWordCount[key]\n",
        "    \n",
        "    # Mapping from index to word\n",
        "    vocabulary_inv = sorted(dictWordCount, key=dictWordCount.__getitem__, reverse=True)\n",
        "    \n",
        "    # Mapping from word to index\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return vocabulary, vocabulary_inv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MKifaS85Dkap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating Tokens and Types"
      ]
    },
    {
      "metadata": {
        "id": "9cpQlJ3TytgZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_to_ix, ix_to_word = build_vocabulary(train_text_reviews+val_text_reviews+test_text_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PLBgxuf0xDB9",
        "colab_type": "code",
        "outputId": "b20eaeb0-3478-4bd1-9b4c-8290bf910bc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(word_to_ix)\n",
        "ix_to_word[word_to_ix['kick']]=='kick', word_to_ix['kick'], VOCAB_SIZE"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 1710, 17746)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "GMbWbZdr1reC",
        "colab_type": "code",
        "outputId": "661abc29-731c-4bc5-ee59-0c5b8084af20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "403"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "metadata": {
        "id": "yNUlKuJeNJEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "SqLOymKPLPug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable # Automatic gradients are calculated and back-propagated through the computational graph\n",
        "import copy\n",
        "import csv\n",
        "import time\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sWqAwOAI7D54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "UZK9TAQI7Fbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix)).to('cuda:0') #, device=device) # make 1D vector of len = vocab size\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "#             raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6p3T6oo_T99z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare Input Train and Validation torch vector"
      ]
    },
    {
      "metadata": {
        "id": "W7xoiOiAyZN5",
        "colab_type": "code",
        "outputId": "e4c1d517-aa76-41a5-f6c0-7ebb6cba46a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# store the bag of word vectors for each sentences and wraping to tensor of torch type\n",
        "tic = time.time()\n",
        "train_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in train_text_reviews]\n",
        "num_train_data = len(train_text_reviews)\n",
        "\n",
        "val_data = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in val_text_reviews]\n",
        "num_val_data = len(val_text_reviews)\n",
        "toc = time.time()\n",
        "num_train_data, num_val_data, (toc-tic)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16198, 1801, 98.38699841499329)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "metadata": {
        "id": "HAi56d_fmMwI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Prepare Test Instance"
      ]
    },
    {
      "metadata": {
        "id": "fkYBaktsF-sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_test = []\n",
        "data_test = [Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') for instance in test_text_reviews]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "deO_hz8vT19u",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Validation Accuracy Computation"
      ]
    },
    {
      "metadata": {
        "id": "cStQIVFfESWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def evaluate_validation_accuracy(data, net):\n",
        "    sum_loss = 0\n",
        "    \n",
        "    true_positive = 0\n",
        "    true_negative = 0\n",
        "    false_positive = 0\n",
        "    false_negative = 0\n",
        "    \n",
        "    for i, instance in enumerate(data):\n",
        "        label = val_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "        \n",
        "#         vec = Variable(make_bow_vector(instance, word_to_ix)).to('cuda:0') # wrap to tensor of torch type for instance\n",
        "        \n",
        "#         prob = net.forward(vec) # forward pass\n",
        "\n",
        "        prob = net.forward(instance)\n",
        "    \n",
        "        _class = 1 if prob.item() > 0.5 else 0 # sigmoid activated\n",
        "        \n",
        "        loss = loss_function(prob, label) # compute the loss\n",
        "        \n",
        "        sum_loss += float(loss.item())\n",
        "        \n",
        "#         if(int(label) == _class and _class == 1):\n",
        "#             true_positive += 1\n",
        "            \n",
        "#         if(int(label) == _class and _class == 0):\n",
        "#             true_negative += 1\n",
        "        \n",
        "#         if(_class == 1 and int(label) == 0):\n",
        "#             false_positive += 1\n",
        "            \n",
        "#         if(_class == 0 and int(label) == 1):\n",
        "#             false_negative += 1\n",
        "    \n",
        "    \n",
        "#     precision = float(true_positive) / (true_positive + false_positive)\n",
        "#     recall = float(true_positive) / (true_positive + false_negative)\n",
        "#     f_score = float(2)*precision*recall / (precision + recall)\n",
        "#     accuracy = float(1)*(true_positive+true_negative)/(true_positive+true_negative+false_positive+false_negative)\n",
        "    \n",
        "    return float(sum_loss)/len(data)#, float(100)*accuracy, precision, recall, f_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaSwXEBh6565",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task-1"
      ]
    },
    {
      "metadata": {
        "id": "aCYGwbP7zy8i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task1 = [(50, 'Task1A.mdl'), (100, 'Task1B.mdl'), (200, 'Task1C.mdl'), (500, 'Task1D.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PM5I4GP6lFGu",
        "colab_type": "code",
        "outputId": "a9574239-0ada-4242-ea58-f876f9dcc53a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7228
        }
      },
      "cell_type": "code",
      "source": [
        "for num_of_hidden, task_name in task1:\n",
        "    class BOWClassifier(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size, output_size):\n",
        "            super(BOWClassifier, self).__init__()\n",
        "            SEED = 42\n",
        "            torch.manual_seed(SEED)\n",
        "            torch.cuda.manual_seed(SEED)\n",
        "            self.hidden_size = hidden_size\n",
        "            self.i2h = nn.Linear(input_size, hidden_size) # initialises weights and biases i2h\n",
        "            self.h2o = nn.Linear(hidden_size, output_size) # initialises weights and biases h2o\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "            x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "            return x\n",
        "\n",
        "    num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "    num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "    bow = BOWClassifier(num_of_input, num_of_hidden, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "    \n",
        "    # define a loss function and an optimizer\n",
        "    loss_function = nn.BCELoss()\n",
        "    opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "    \n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        \n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "        \n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "    \n",
        "    torch.save(bow, task_name) ## Save the model\n",
        "    \n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "    \n",
        "    print ('\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 23.92s, Train Loss: 0.681506928, Train Accuracy: 60.14%\n",
            "[On Validation] ==> Val loss: 0.666210379, Total Time: 23.92s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 24.28s, Train Loss: 0.650062438, Train Accuracy: 70.73%\n",
            "[On Validation] ==> Val loss: 0.630566867, Total Time: 48.20s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 24.59s, Train Loss: 0.611577513, Train Accuracy: 74.47%\n",
            "[On Validation] ==> Val loss: 0.590137132, Total Time: 72.79s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 23.74s, Train Loss: 0.568415287, Train Accuracy: 77.61%\n",
            "[On Validation] ==> Val loss: 0.548192693, Total Time: 96.53s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 23.59s, Train Loss: 0.525151165, Train Accuracy: 80.02%\n",
            "[On Validation] ==> Val loss: 0.509592303, Total Time: 120.12s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 23.96s, Train Loss: 0.486261342, Train Accuracy: 81.88%\n",
            "[On Validation] ==> Val loss: 0.477335682, Total Time: 144.09s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 23.91s, Train Loss: 0.453430340, Train Accuracy: 83.12%\n",
            "[On Validation] ==> Val loss: 0.451558806, Total Time: 167.99s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 23.92s, Train Loss: 0.426088758, Train Accuracy: 83.95%\n",
            "[On Validation] ==> Val loss: 0.430994930, Total Time: 191.91s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 23.96s, Train Loss: 0.403005897, Train Accuracy: 84.81%\n",
            "[On Validation] ==> Val loss: 0.414303547, Total Time: 215.86s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 23.85s, Train Loss: 0.383097886, Train Accuracy: 85.53%\n",
            "[On Validation] ==> Val loss: 0.400465772, Total Time: 239.72s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 23.87s, Train Loss: 0.365602011, Train Accuracy: 86.28%\n",
            "[On Validation] ==> Val loss: 0.388808603, Total Time: 263.59s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 23.90s, Train Loss: 0.350015529, Train Accuracy: 87.05%\n",
            "[On Validation] ==> Val loss: 0.378886678, Total Time: 287.49s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 23.92s, Train Loss: 0.335996537, Train Accuracy: 87.66%\n",
            "[On Validation] ==> Val loss: 0.370398928, Total Time: 311.41s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 24.00s, Train Loss: 0.323303335, Train Accuracy: 88.21%\n",
            "[On Validation] ==> Val loss: 0.363116557, Total Time: 335.41s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 25.02s, Train Loss: 0.311752643, Train Accuracy: 88.67%\n",
            "[On Validation] ==> Val loss: 0.356867087, Total Time: 360.43s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 25.21s, Train Loss: 0.301198694, Train Accuracy: 88.98%\n",
            "[On Validation] ==> Val loss: 0.351498146, Total Time: 385.64s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 24.29s, Train Loss: 0.291512951, Train Accuracy: 89.53%\n",
            "[On Validation] ==> Val loss: 0.346889639, Total Time: 409.93s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 24.74s, Train Loss: 0.282587982, Train Accuracy: 89.88%\n",
            "[On Validation] ==> Val loss: 0.342926136, Total Time: 434.67s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 24.47s, Train Loss: 0.274327331, Train Accuracy: 90.22%\n",
            "[On Validation] ==> Val loss: 0.339518834, Total Time: 459.14s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 24.56s, Train Loss: 0.266649286, Train Accuracy: 90.54%\n",
            "[On Validation] ==> Val loss: 0.336587417, Total Time: 483.70s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 24.34s, Train Loss: 0.259483702, Train Accuracy: 90.78%\n",
            "[On Validation] ==> Val loss: 0.334064022, Total Time: 508.04s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 24.38s, Train Loss: 0.252771134, Train Accuracy: 91.05%\n",
            "[On Validation] ==> Val loss: 0.331894540, Total Time: 532.43s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 24.20s, Train Loss: 0.246461087, Train Accuracy: 91.28%\n",
            "[On Validation] ==> Val loss: 0.330033941, Total Time: 556.63s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 24.10s, Train Loss: 0.240508478, Train Accuracy: 91.52%\n",
            "[On Validation] ==> Val loss: 0.328443121, Total Time: 580.73s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 23.97s, Train Loss: 0.234874740, Train Accuracy: 91.72%\n",
            "[On Validation] ==> Val loss: 0.327090138, Total Time: 604.70s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 23.96s, Train Loss: 0.229527650, Train Accuracy: 91.94%\n",
            "[On Validation] ==> Val loss: 0.325952057, Total Time: 628.66s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 24.42s, Train Loss: 0.224438960, Train Accuracy: 92.17%\n",
            "[On Validation] ==> Val loss: 0.325005224, Total Time: 653.08s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 24.04s, Train Loss: 0.219583645, Train Accuracy: 92.37%\n",
            "[On Validation] ==> Val loss: 0.324232950, Total Time: 677.11s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 24.59s, Train Loss: 0.214942418, Train Accuracy: 92.56%\n",
            "[On Validation] ==> Val loss: 0.323616776, Total Time: 701.71s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 24.01s, Train Loss: 0.210496231, Train Accuracy: 92.79%\n",
            "[On Validation] ==> Val loss: 0.323145193, Total Time: 725.72s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 23.98s, Train Loss: 0.206228551, Train Accuracy: 92.94%\n",
            "[On Validation] ==> Val loss: 0.322803108, Total Time: 749.69s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 24.12s, Train Loss: 0.202125751, Train Accuracy: 93.14%\n",
            "[On Validation] ==> Val loss: 0.322581234, Total Time: 773.81s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 24.11s, Train Loss: 0.198175171, Train Accuracy: 93.30%\n",
            "[On Validation] ==> Val loss: 0.322466136, Total Time: 797.92s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 24.07s, Train Loss: 0.194365822, Train Accuracy: 93.41%\n",
            "[On Validation] ==> Val loss: 0.322452669, Total Time: 821.99s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task1A.mdl\n",
            "[On Testing] Time: 2.395127296447754, Test Accuracy: 87.38%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 26.19s, Train Loss: 0.681662652, Train Accuracy: 56.80%\n",
            "[On Validation] ==> Val loss: 0.665698624, Total Time: 26.19s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 26.29s, Train Loss: 0.648235821, Train Accuracy: 70.39%\n",
            "[On Validation] ==> Val loss: 0.627552664, Total Time: 52.48s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 26.17s, Train Loss: 0.606963007, Train Accuracy: 75.35%\n",
            "[On Validation] ==> Val loss: 0.585346470, Total Time: 78.65s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 26.30s, Train Loss: 0.562110687, Train Accuracy: 78.37%\n",
            "[On Validation] ==> Val loss: 0.542950579, Total Time: 104.94s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 27.93s, Train Loss: 0.518668633, Train Accuracy: 80.39%\n",
            "[On Validation] ==> Val loss: 0.504989100, Total Time: 132.87s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 28.08s, Train Loss: 0.480584246, Train Accuracy: 82.00%\n",
            "[On Validation] ==> Val loss: 0.473803180, Total Time: 160.95s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 27.88s, Train Loss: 0.448781527, Train Accuracy: 83.19%\n",
            "[On Validation] ==> Val loss: 0.448997129, Total Time: 188.82s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 28.08s, Train Loss: 0.422315639, Train Accuracy: 84.21%\n",
            "[On Validation] ==> Val loss: 0.429170797, Total Time: 216.90s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 28.18s, Train Loss: 0.399878873, Train Accuracy: 85.00%\n",
            "[On Validation] ==> Val loss: 0.412995659, Total Time: 245.08s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 28.11s, Train Loss: 0.380433728, Train Accuracy: 85.65%\n",
            "[On Validation] ==> Val loss: 0.399527351, Total Time: 273.20s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 28.12s, Train Loss: 0.363276105, Train Accuracy: 86.35%\n",
            "[On Validation] ==> Val loss: 0.388139966, Total Time: 301.32s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 28.10s, Train Loss: 0.347940151, Train Accuracy: 87.13%\n",
            "[On Validation] ==> Val loss: 0.378426249, Total Time: 329.42s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 28.26s, Train Loss: 0.334115201, Train Accuracy: 87.67%\n",
            "[On Validation] ==> Val loss: 0.370096635, Total Time: 357.68s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 28.24s, Train Loss: 0.321578068, Train Accuracy: 88.21%\n",
            "[On Validation] ==> Val loss: 0.362947420, Total Time: 385.92s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 28.17s, Train Loss: 0.310156160, Train Accuracy: 88.66%\n",
            "[On Validation] ==> Val loss: 0.356804996, Total Time: 414.08s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 27.47s, Train Loss: 0.299709402, Train Accuracy: 89.14%\n",
            "[On Validation] ==> Val loss: 0.351530599, Total Time: 441.55s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 27.89s, Train Loss: 0.290118027, Train Accuracy: 89.47%\n",
            "[On Validation] ==> Val loss: 0.346998376, Total Time: 469.44s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 27.37s, Train Loss: 0.281275611, Train Accuracy: 89.88%\n",
            "[On Validation] ==> Val loss: 0.343101831, Total Time: 496.81s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 27.39s, Train Loss: 0.273088832, Train Accuracy: 90.28%\n",
            "[On Validation] ==> Val loss: 0.339749167, Total Time: 524.20s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 27.44s, Train Loss: 0.265476382, Train Accuracy: 90.54%\n",
            "[On Validation] ==> Val loss: 0.336863031, Total Time: 551.64s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 27.47s, Train Loss: 0.258368665, Train Accuracy: 90.84%\n",
            "[On Validation] ==> Val loss: 0.334376152, Total Time: 579.11s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 27.51s, Train Loss: 0.251707074, Train Accuracy: 91.12%\n",
            "[On Validation] ==> Val loss: 0.332240145, Total Time: 606.62s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 27.40s, Train Loss: 0.245440790, Train Accuracy: 91.33%\n",
            "[On Validation] ==> Val loss: 0.330409623, Total Time: 634.01s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 27.39s, Train Loss: 0.239526925, Train Accuracy: 91.57%\n",
            "[On Validation] ==> Val loss: 0.328847373, Total Time: 661.40s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 27.54s, Train Loss: 0.233927982, Train Accuracy: 91.78%\n",
            "[On Validation] ==> Val loss: 0.327522772, Total Time: 688.94s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 27.68s, Train Loss: 0.228612066, Train Accuracy: 91.98%\n",
            "[On Validation] ==> Val loss: 0.326409765, Total Time: 716.63s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 27.48s, Train Loss: 0.223552043, Train Accuracy: 92.14%\n",
            "[On Validation] ==> Val loss: 0.325487590, Total Time: 744.11s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 28.07s, Train Loss: 0.218723471, Train Accuracy: 92.37%\n",
            "[On Validation] ==> Val loss: 0.324735932, Total Time: 772.18s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 27.38s, Train Loss: 0.214106333, Train Accuracy: 92.56%\n",
            "[On Validation] ==> Val loss: 0.324141253, Total Time: 799.56s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 27.69s, Train Loss: 0.209682374, Train Accuracy: 92.72%\n",
            "[On Validation] ==> Val loss: 0.323688532, Total Time: 827.25s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 28.23s, Train Loss: 0.205435677, Train Accuracy: 92.88%\n",
            "[On Validation] ==> Val loss: 0.323364210, Total Time: 855.48s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 27.89s, Train Loss: 0.201352657, Train Accuracy: 93.05%\n",
            "[On Validation] ==> Val loss: 0.323160061, Total Time: 883.37s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 27.81s, Train Loss: 0.197420077, Train Accuracy: 93.34%\n",
            "[On Validation] ==> Val loss: 0.323064358, Total Time: 911.18s\n",
            "--- AFTER TRAINING ---\tModel: Task1B.mdl\n",
            "[On Testing] Time: 2.3973772525787354, Test Accuracy: 87.46%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 30.64s, Train Loss: 0.683597120, Train Accuracy: 54.48%\n",
            "[On Validation] ==> Val loss: 0.670351001, Total Time: 30.64s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 30.62s, Train Loss: 0.654218420, Train Accuracy: 69.07%\n",
            "[On Validation] ==> Val loss: 0.635055829, Total Time: 61.26s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 30.96s, Train Loss: 0.615297153, Train Accuracy: 74.06%\n",
            "[On Validation] ==> Val loss: 0.594019257, Total Time: 92.23s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 30.72s, Train Loss: 0.571294052, Train Accuracy: 77.50%\n",
            "[On Validation] ==> Val loss: 0.551362922, Total Time: 122.95s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 31.23s, Train Loss: 0.527341516, Train Accuracy: 79.86%\n",
            "[On Validation] ==> Val loss: 0.512196657, Total Time: 154.18s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 30.38s, Train Loss: 0.488052110, Train Accuracy: 81.66%\n",
            "[On Validation] ==> Val loss: 0.479592130, Total Time: 184.57s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 29.84s, Train Loss: 0.455030181, Train Accuracy: 82.89%\n",
            "[On Validation] ==> Val loss: 0.453634016, Total Time: 214.41s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 29.87s, Train Loss: 0.427588944, Train Accuracy: 83.83%\n",
            "[On Validation] ==> Val loss: 0.432971163, Total Time: 244.28s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 29.83s, Train Loss: 0.404430683, Train Accuracy: 84.74%\n",
            "[On Validation] ==> Val loss: 0.416219469, Total Time: 274.11s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 29.91s, Train Loss: 0.384449170, Train Accuracy: 85.60%\n",
            "[On Validation] ==> Val loss: 0.402342023, Total Time: 304.02s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 30.00s, Train Loss: 0.366873074, Train Accuracy: 86.26%\n",
            "[On Validation] ==> Val loss: 0.390648605, Total Time: 334.02s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 30.01s, Train Loss: 0.351194167, Train Accuracy: 87.00%\n",
            "[On Validation] ==> Val loss: 0.380700751, Total Time: 364.03s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 30.21s, Train Loss: 0.337079826, Train Accuracy: 87.59%\n",
            "[On Validation] ==> Val loss: 0.372183530, Total Time: 394.24s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 29.86s, Train Loss: 0.324289393, Train Accuracy: 88.08%\n",
            "[On Validation] ==> Val loss: 0.364864518, Total Time: 424.10s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 30.40s, Train Loss: 0.312643822, Train Accuracy: 88.60%\n",
            "[On Validation] ==> Val loss: 0.358575348, Total Time: 454.50s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 29.92s, Train Loss: 0.301997446, Train Accuracy: 89.04%\n",
            "[On Validation] ==> Val loss: 0.353169759, Total Time: 484.42s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 29.87s, Train Loss: 0.292228997, Train Accuracy: 89.37%\n",
            "[On Validation] ==> Val loss: 0.348523785, Total Time: 514.29s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 29.91s, Train Loss: 0.283230009, Train Accuracy: 89.75%\n",
            "[On Validation] ==> Val loss: 0.344527993, Total Time: 544.20s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 29.96s, Train Loss: 0.274904876, Train Accuracy: 90.18%\n",
            "[On Validation] ==> Val loss: 0.341090380, Total Time: 574.16s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 30.71s, Train Loss: 0.267171542, Train Accuracy: 90.47%\n",
            "[On Validation] ==> Val loss: 0.338129366, Total Time: 604.87s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 30.60s, Train Loss: 0.259957606, Train Accuracy: 90.80%\n",
            "[On Validation] ==> Val loss: 0.335578460, Total Time: 635.47s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 30.65s, Train Loss: 0.253202920, Train Accuracy: 91.02%\n",
            "[On Validation] ==> Val loss: 0.333383480, Total Time: 666.12s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 31.12s, Train Loss: 0.246855547, Train Accuracy: 91.26%\n",
            "[On Validation] ==> Val loss: 0.331496255, Total Time: 697.24s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 30.64s, Train Loss: 0.240868804, Train Accuracy: 91.54%\n",
            "[On Validation] ==> Val loss: 0.329879663, Total Time: 727.88s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 31.26s, Train Loss: 0.235204011, Train Accuracy: 91.72%\n",
            "[On Validation] ==> Val loss: 0.328500364, Total Time: 759.13s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 30.58s, Train Loss: 0.229827996, Train Accuracy: 91.91%\n",
            "[On Validation] ==> Val loss: 0.327334308, Total Time: 789.71s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 30.66s, Train Loss: 0.224712206, Train Accuracy: 92.10%\n",
            "[On Validation] ==> Val loss: 0.326360521, Total Time: 820.37s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 30.71s, Train Loss: 0.219832303, Train Accuracy: 92.35%\n",
            "[On Validation] ==> Val loss: 0.325556958, Total Time: 851.08s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 30.62s, Train Loss: 0.215166956, Train Accuracy: 92.54%\n",
            "[On Validation] ==> Val loss: 0.324909905, Total Time: 881.70s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 30.10s, Train Loss: 0.210698230, Train Accuracy: 92.81%\n",
            "[On Validation] ==> Val loss: 0.324403964, Total Time: 911.79s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 29.90s, Train Loss: 0.206409168, Train Accuracy: 93.07%\n",
            "[On Validation] ==> Val loss: 0.324028401, Total Time: 941.69s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 29.86s, Train Loss: 0.202285971, Train Accuracy: 93.20%\n",
            "[On Validation] ==> Val loss: 0.323771002, Total Time: 971.56s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 30.16s, Train Loss: 0.198315634, Train Accuracy: 93.34%\n",
            "[On Validation] ==> Val loss: 0.323622603, Total Time: 1001.72s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 29.66s, Train Loss: 0.194487073, Train Accuracy: 93.50%\n",
            "[On Validation] ==> Val loss: 0.323574158, Total Time: 1031.38s\n",
            "--- AFTER TRAINING ---\tModel: Task1C.mdl\n",
            "[On Testing] Time: 2.141007661819458, Test Accuracy: 87.44%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 50.15s, Train Loss: 0.682295337, Train Accuracy: 64.78%\n",
            "[On Validation] ==> Val loss: 0.669982962, Total Time: 50.15s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 50.04s, Train Loss: 0.655772567, Train Accuracy: 70.38%\n",
            "[On Validation] ==> Val loss: 0.638024409, Total Time: 100.20s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 50.10s, Train Loss: 0.619334371, Train Accuracy: 73.68%\n",
            "[On Validation] ==> Val loss: 0.598488264, Total Time: 150.29s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 50.19s, Train Loss: 0.576346129, Train Accuracy: 76.97%\n",
            "[On Validation] ==> Val loss: 0.556202917, Total Time: 200.48s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 50.83s, Train Loss: 0.532349359, Train Accuracy: 79.52%\n",
            "[On Validation] ==> Val loss: 0.516552868, Total Time: 251.32s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 50.40s, Train Loss: 0.492510989, Train Accuracy: 81.34%\n",
            "[On Validation] ==> Val loss: 0.483194167, Total Time: 301.71s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 52.25s, Train Loss: 0.458887006, Train Accuracy: 82.52%\n",
            "[On Validation] ==> Val loss: 0.456546855, Total Time: 353.96s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 52.03s, Train Loss: 0.430964184, Train Accuracy: 83.65%\n",
            "[On Validation] ==> Val loss: 0.435343225, Total Time: 405.99s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 52.04s, Train Loss: 0.407440259, Train Accuracy: 84.44%\n",
            "[On Validation] ==> Val loss: 0.418170969, Total Time: 458.03s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 52.09s, Train Loss: 0.387177843, Train Accuracy: 85.41%\n",
            "[On Validation] ==> Val loss: 0.403969685, Total Time: 510.12s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 50.37s, Train Loss: 0.369375076, Train Accuracy: 86.05%\n",
            "[On Validation] ==> Val loss: 0.392009318, Total Time: 560.49s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 49.88s, Train Loss: 0.353499737, Train Accuracy: 86.78%\n",
            "[On Validation] ==> Val loss: 0.381824917, Total Time: 610.37s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 50.18s, Train Loss: 0.339203134, Train Accuracy: 87.41%\n",
            "[On Validation] ==> Val loss: 0.373093951, Total Time: 660.55s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 50.03s, Train Loss: 0.326244969, Train Accuracy: 87.94%\n",
            "[On Validation] ==> Val loss: 0.365598748, Total Time: 710.58s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 50.00s, Train Loss: 0.314444969, Train Accuracy: 88.41%\n",
            "[On Validation] ==> Val loss: 0.359164421, Total Time: 760.58s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 50.02s, Train Loss: 0.303659023, Train Accuracy: 88.81%\n",
            "[On Validation] ==> Val loss: 0.353640577, Total Time: 810.60s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 50.34s, Train Loss: 0.293761763, Train Accuracy: 89.26%\n",
            "[On Validation] ==> Val loss: 0.348897120, Total Time: 860.94s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 51.37s, Train Loss: 0.284643780, Train Accuracy: 89.73%\n",
            "[On Validation] ==> Val loss: 0.344827674, Total Time: 912.32s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 52.18s, Train Loss: 0.276211266, Train Accuracy: 90.17%\n",
            "[On Validation] ==> Val loss: 0.341336225, Total Time: 964.50s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 51.88s, Train Loss: 0.268381293, Train Accuracy: 90.42%\n",
            "[On Validation] ==> Val loss: 0.338340394, Total Time: 1016.37s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 51.00s, Train Loss: 0.261081024, Train Accuracy: 90.74%\n",
            "[On Validation] ==> Val loss: 0.335770357, Total Time: 1067.38s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 49.91s, Train Loss: 0.254247355, Train Accuracy: 90.99%\n",
            "[On Validation] ==> Val loss: 0.333566487, Total Time: 1117.29s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 49.99s, Train Loss: 0.247827193, Train Accuracy: 91.23%\n",
            "[On Validation] ==> Val loss: 0.331683252, Total Time: 1167.27s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 49.92s, Train Loss: 0.241774429, Train Accuracy: 91.51%\n",
            "[On Validation] ==> Val loss: 0.330077923, Total Time: 1217.20s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 50.46s, Train Loss: 0.236048921, Train Accuracy: 91.76%\n",
            "[On Validation] ==> Val loss: 0.328718622, Total Time: 1267.65s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 50.21s, Train Loss: 0.230616750, Train Accuracy: 91.92%\n",
            "[On Validation] ==> Val loss: 0.327578547, Total Time: 1317.87s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 50.01s, Train Loss: 0.225449653, Train Accuracy: 92.09%\n",
            "[On Validation] ==> Val loss: 0.326634323, Total Time: 1367.88s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 50.06s, Train Loss: 0.220522126, Train Accuracy: 92.31%\n",
            "[On Validation] ==> Val loss: 0.325864744, Total Time: 1417.93s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 50.65s, Train Loss: 0.215812758, Train Accuracy: 92.51%\n",
            "[On Validation] ==> Val loss: 0.325253658, Total Time: 1468.58s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 50.17s, Train Loss: 0.211302546, Train Accuracy: 92.75%\n",
            "[On Validation] ==> Val loss: 0.324786413, Total Time: 1518.75s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 51.99s, Train Loss: 0.206975202, Train Accuracy: 92.88%\n",
            "[On Validation] ==> Val loss: 0.324450623, Total Time: 1570.74s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 51.80s, Train Loss: 0.202815676, Train Accuracy: 93.09%\n",
            "[On Validation] ==> Val loss: 0.324233028, Total Time: 1622.54s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 51.91s, Train Loss: 0.198811058, Train Accuracy: 93.25%\n",
            "[On Validation] ==> Val loss: 0.324125169, Total Time: 1674.45s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 52.80s, Train Loss: 0.194950174, Train Accuracy: 93.40%\n",
            "[On Validation] ==> Val loss: 0.324116959, Total Time: 1727.25s\n",
            "--- AFTER TRAINING ---\tModel: Task1D.mdl\n",
            "[On Testing] Time: 2.514296293258667, Test Accuracy: 87.46%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4XoHF1M8IVdf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task1A.mdl')\n",
        "files.download('Task1B.mdl')\n",
        "files.download('Task1C.mdl')\n",
        "files.download('Task1D.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxO_e5P1mX3I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task-2"
      ]
    },
    {
      "metadata": {
        "id": "lpUB7Obs197T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task2 = [(10, 10, 'Task2A.mdl'), (20, 10, 'Task2B.mdl'), (30, 30, 'Task2C.mdl'), (50, 50, 'Task2D.mdl'), (100, 50, 'Task2E.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UiqcS_4XmXbd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5358
        },
        "outputId": "78d4f4ec-7985-433e-e9a2-3225b25e1219"
      },
      "cell_type": "code",
      "source": [
        "for num_of_hidden1, num_of_hidden2, task_name in task2:\n",
        "    class BOWClassifier(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "            super(BOWClassifier, self).__init__()\n",
        "            SEED = 42\n",
        "            torch.manual_seed(SEED)\n",
        "            torch.cuda.manual_seed(SEED)\n",
        "            self.i2h = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h\n",
        "            self.h2h = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h2h\n",
        "            self.h2o = nn.Linear(hidden_size2, output_size) # initialises weights and biases h2o\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "            x = torch.relu(self.h2h(x)) # relu activation @ hidden layer\n",
        "            x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "            return x\n",
        "\n",
        "    num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "    num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "    bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "\n",
        "    # define a loss function and an optimizer\n",
        "    loss_function = nn.BCELoss()\n",
        "    opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        \n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "\n",
        "    torch.save(bow, task_name)\n",
        "\n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "    \n",
        "    print(\"\\n\")"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 26.86s, Train Loss: 0.689191229, Train Accuracy: 58.30%\n",
            "[On Validation] ==> Val loss: 0.683963105, Total Time: 26.86s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 26.21s, Train Loss: 0.678321193, Train Accuracy: 66.12%\n",
            "[On Validation] ==> Val loss: 0.672020574, Total Time: 53.07s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 26.62s, Train Loss: 0.664094258, Train Accuracy: 69.19%\n",
            "[On Validation] ==> Val loss: 0.654753870, Total Time: 79.70s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 26.77s, Train Loss: 0.643077088, Train Accuracy: 72.42%\n",
            "[On Validation] ==> Val loss: 0.629783991, Total Time: 106.47s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 27.25s, Train Loss: 0.613262530, Train Accuracy: 75.71%\n",
            "[On Validation] ==> Val loss: 0.595665983, Total Time: 133.71s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 26.94s, Train Loss: 0.573307074, Train Accuracy: 78.87%\n",
            "[On Validation] ==> Val loss: 0.552970880, Total Time: 160.66s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 26.39s, Train Loss: 0.525504909, Train Accuracy: 81.36%\n",
            "[On Validation] ==> Val loss: 0.506822415, Total Time: 187.05s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 26.91s, Train Loss: 0.475599322, Train Accuracy: 83.21%\n",
            "[On Validation] ==> Val loss: 0.463770055, Total Time: 213.96s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 26.53s, Train Loss: 0.429717367, Train Accuracy: 84.60%\n",
            "[On Validation] ==> Val loss: 0.428802834, Total Time: 240.50s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 26.63s, Train Loss: 0.390767278, Train Accuracy: 85.76%\n",
            "[On Validation] ==> Val loss: 0.401879119, Total Time: 267.13s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 26.25s, Train Loss: 0.358132052, Train Accuracy: 86.78%\n",
            "[On Validation] ==> Val loss: 0.381258704, Total Time: 293.38s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 27.17s, Train Loss: 0.330480625, Train Accuracy: 87.91%\n",
            "[On Validation] ==> Val loss: 0.365489888, Total Time: 320.55s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 26.30s, Train Loss: 0.306764588, Train Accuracy: 88.82%\n",
            "[On Validation] ==> Val loss: 0.353439115, Total Time: 346.84s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 27.32s, Train Loss: 0.286247282, Train Accuracy: 89.60%\n",
            "[On Validation] ==> Val loss: 0.344637163, Total Time: 374.16s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 26.66s, Train Loss: 0.268414337, Train Accuracy: 90.41%\n",
            "[On Validation] ==> Val loss: 0.338287762, Total Time: 400.82s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 26.94s, Train Loss: 0.252696170, Train Accuracy: 91.02%\n",
            "[On Validation] ==> Val loss: 0.333905359, Total Time: 427.76s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 27.97s, Train Loss: 0.238721919, Train Accuracy: 91.47%\n",
            "[On Validation] ==> Val loss: 0.330998247, Total Time: 455.73s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 28.32s, Train Loss: 0.226075972, Train Accuracy: 91.95%\n",
            "[On Validation] ==> Val loss: 0.329266428, Total Time: 484.04s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 29.19s, Train Loss: 0.214514933, Train Accuracy: 92.44%\n",
            "[On Validation] ==> Val loss: 0.328488875, Total Time: 513.23s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task2A.mdl\n",
            "[On Testing] Time: 2.4614241123199463, Test Accuracy: 87.46%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 27.90s, Train Loss: 0.694110947, Train Accuracy: 49.98%\n",
            "[On Validation] ==> Val loss: 0.689399113, Total Time: 27.90s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 28.00s, Train Loss: 0.684947238, Train Accuracy: 52.11%\n",
            "[On Validation] ==> Val loss: 0.679449860, Total Time: 55.91s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 28.79s, Train Loss: 0.673846138, Train Accuracy: 66.24%\n",
            "[On Validation] ==> Val loss: 0.666359857, Total Time: 84.70s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 27.79s, Train Loss: 0.657531419, Train Accuracy: 73.60%\n",
            "[On Validation] ==> Val loss: 0.646202123, Total Time: 112.49s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 27.25s, Train Loss: 0.631880520, Train Accuracy: 75.31%\n",
            "[On Validation] ==> Val loss: 0.615079856, Total Time: 139.74s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 27.70s, Train Loss: 0.592946047, Train Accuracy: 77.53%\n",
            "[On Validation] ==> Val loss: 0.570723300, Total Time: 167.44s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 26.80s, Train Loss: 0.541167442, Train Accuracy: 79.80%\n",
            "[On Validation] ==> Val loss: 0.518011518, Total Time: 194.24s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 27.09s, Train Loss: 0.485405189, Train Accuracy: 82.01%\n",
            "[On Validation] ==> Val loss: 0.468670754, Total Time: 221.33s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 26.46s, Train Loss: 0.435912676, Train Accuracy: 83.70%\n",
            "[On Validation] ==> Val loss: 0.430036937, Total Time: 247.79s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 27.02s, Train Loss: 0.395599284, Train Accuracy: 84.97%\n",
            "[On Validation] ==> Val loss: 0.401362454, Total Time: 274.80s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 27.03s, Train Loss: 0.362529906, Train Accuracy: 86.33%\n",
            "[On Validation] ==> Val loss: 0.379772906, Total Time: 301.83s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 26.62s, Train Loss: 0.334525165, Train Accuracy: 87.42%\n",
            "[On Validation] ==> Val loss: 0.363257903, Total Time: 328.45s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 26.62s, Train Loss: 0.310401960, Train Accuracy: 88.33%\n",
            "[On Validation] ==> Val loss: 0.350773899, Total Time: 355.07s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 27.36s, Train Loss: 0.289394333, Train Accuracy: 89.09%\n",
            "[On Validation] ==> Val loss: 0.341546665, Total Time: 382.43s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 26.98s, Train Loss: 0.271054896, Train Accuracy: 90.00%\n",
            "[On Validation] ==> Val loss: 0.334809794, Total Time: 409.42s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 27.36s, Train Loss: 0.254894558, Train Accuracy: 90.60%\n",
            "[On Validation] ==> Val loss: 0.329914744, Total Time: 436.78s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 27.09s, Train Loss: 0.240528029, Train Accuracy: 91.22%\n",
            "[On Validation] ==> Val loss: 0.326568117, Total Time: 463.87s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 26.79s, Train Loss: 0.227608812, Train Accuracy: 91.79%\n",
            "[On Validation] ==> Val loss: 0.324451622, Total Time: 490.66s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 27.59s, Train Loss: 0.215837060, Train Accuracy: 92.28%\n",
            "[On Validation] ==> Val loss: 0.323419180, Total Time: 518.26s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 27.18s, Train Loss: 0.205024511, Train Accuracy: 92.80%\n",
            "[On Validation] ==> Val loss: 0.323260336, Total Time: 545.43s\n",
            "--- AFTER TRAINING ---\tModel: Task2B.mdl\n",
            "[On Testing] Time: 2.469329357147217, Test Accuracy: 87.40%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 29.04s, Train Loss: 0.691432371, Train Accuracy: 50.61%\n",
            "[On Validation] ==> Val loss: 0.687778054, Total Time: 29.04s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 28.42s, Train Loss: 0.683688559, Train Accuracy: 59.68%\n",
            "[On Validation] ==> Val loss: 0.678569445, Total Time: 57.46s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 28.60s, Train Loss: 0.672149448, Train Accuracy: 68.86%\n",
            "[On Validation] ==> Val loss: 0.663875476, Total Time: 86.06s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 28.68s, Train Loss: 0.652859051, Train Accuracy: 72.85%\n",
            "[On Validation] ==> Val loss: 0.639299000, Total Time: 114.74s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 28.38s, Train Loss: 0.620963520, Train Accuracy: 75.88%\n",
            "[On Validation] ==> Val loss: 0.600571775, Total Time: 143.12s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 28.30s, Train Loss: 0.573944918, Train Accuracy: 78.28%\n",
            "[On Validation] ==> Val loss: 0.549162505, Total Time: 171.42s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 28.30s, Train Loss: 0.517132174, Train Accuracy: 80.99%\n",
            "[On Validation] ==> Val loss: 0.495351769, Total Time: 199.72s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 27.21s, Train Loss: 0.462126391, Train Accuracy: 82.84%\n",
            "[On Validation] ==> Val loss: 0.450332253, Total Time: 226.93s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 26.98s, Train Loss: 0.416264881, Train Accuracy: 84.26%\n",
            "[On Validation] ==> Val loss: 0.416867455, Total Time: 253.91s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 27.36s, Train Loss: 0.379252339, Train Accuracy: 85.63%\n",
            "[On Validation] ==> Val loss: 0.392120758, Total Time: 281.28s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 27.68s, Train Loss: 0.348513202, Train Accuracy: 86.86%\n",
            "[On Validation] ==> Val loss: 0.373354639, Total Time: 308.96s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 27.06s, Train Loss: 0.322281326, Train Accuracy: 87.97%\n",
            "[On Validation] ==> Val loss: 0.358916060, Total Time: 336.01s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 26.95s, Train Loss: 0.299612864, Train Accuracy: 88.81%\n",
            "[On Validation] ==> Val loss: 0.348049385, Total Time: 362.96s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 27.14s, Train Loss: 0.279938614, Train Accuracy: 89.71%\n",
            "[On Validation] ==> Val loss: 0.340114316, Total Time: 390.10s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 28.02s, Train Loss: 0.262744970, Train Accuracy: 90.47%\n",
            "[On Validation] ==> Val loss: 0.334416066, Total Time: 418.12s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 27.91s, Train Loss: 0.247580492, Train Accuracy: 91.07%\n",
            "[On Validation] ==> Val loss: 0.330452274, Total Time: 446.03s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 27.87s, Train Loss: 0.234022565, Train Accuracy: 91.65%\n",
            "[On Validation] ==> Val loss: 0.327879657, Total Time: 473.90s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 27.08s, Train Loss: 0.221741822, Train Accuracy: 92.08%\n",
            "[On Validation] ==> Val loss: 0.326424730, Total Time: 500.98s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 27.21s, Train Loss: 0.210478567, Train Accuracy: 92.63%\n",
            "[On Validation] ==> Val loss: 0.325933298, Total Time: 528.19s\n",
            "--- AFTER TRAINING ---\tModel: Task2C.mdl\n",
            "[On Testing] Time: 2.553337812423706, Test Accuracy: 87.42%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 27.72s, Train Loss: 0.690946414, Train Accuracy: 57.14%\n",
            "[On Validation] ==> Val loss: 0.688296510, Total Time: 27.72s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 28.33s, Train Loss: 0.685050785, Train Accuracy: 66.94%\n",
            "[On Validation] ==> Val loss: 0.681066098, Total Time: 56.04s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 28.25s, Train Loss: 0.676093782, Train Accuracy: 70.47%\n",
            "[On Validation] ==> Val loss: 0.669649687, Total Time: 84.29s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 27.95s, Train Loss: 0.661131238, Train Accuracy: 73.52%\n",
            "[On Validation] ==> Val loss: 0.650469273, Total Time: 112.24s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 29.07s, Train Loss: 0.635408156, Train Accuracy: 75.86%\n",
            "[On Validation] ==> Val loss: 0.618251938, Total Time: 141.31s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 29.78s, Train Loss: 0.593977313, Train Accuracy: 78.10%\n",
            "[On Validation] ==> Val loss: 0.570139082, Total Time: 171.09s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 30.44s, Train Loss: 0.538267647, Train Accuracy: 80.52%\n",
            "[On Validation] ==> Val loss: 0.513867828, Total Time: 201.53s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 29.28s, Train Loss: 0.480042377, Train Accuracy: 82.36%\n",
            "[On Validation] ==> Val loss: 0.463673799, Total Time: 230.81s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 29.20s, Train Loss: 0.430030629, Train Accuracy: 84.07%\n",
            "[On Validation] ==> Val loss: 0.425723867, Total Time: 260.01s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 29.87s, Train Loss: 0.389918460, Train Accuracy: 85.35%\n",
            "[On Validation] ==> Val loss: 0.398076847, Total Time: 289.88s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 29.52s, Train Loss: 0.357074906, Train Accuracy: 86.42%\n",
            "[On Validation] ==> Val loss: 0.377443837, Total Time: 319.40s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 28.13s, Train Loss: 0.329336399, Train Accuracy: 87.75%\n",
            "[On Validation] ==> Val loss: 0.361861052, Total Time: 347.53s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 28.17s, Train Loss: 0.305512215, Train Accuracy: 88.62%\n",
            "[On Validation] ==> Val loss: 0.350213241, Total Time: 375.70s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 28.00s, Train Loss: 0.284880372, Train Accuracy: 89.52%\n",
            "[On Validation] ==> Val loss: 0.341615430, Total Time: 403.70s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 27.56s, Train Loss: 0.266913662, Train Accuracy: 90.30%\n",
            "[On Validation] ==> Val loss: 0.335385919, Total Time: 431.26s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 27.76s, Train Loss: 0.251100081, Train Accuracy: 90.91%\n",
            "[On Validation] ==> Val loss: 0.331038543, Total Time: 459.02s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 28.25s, Train Loss: 0.237009167, Train Accuracy: 91.40%\n",
            "[On Validation] ==> Val loss: 0.328156153, Total Time: 487.27s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 28.86s, Train Loss: 0.224300518, Train Accuracy: 91.92%\n",
            "[On Validation] ==> Val loss: 0.326469781, Total Time: 516.13s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 28.31s, Train Loss: 0.212697192, Train Accuracy: 92.42%\n",
            "[On Validation] ==> Val loss: 0.325798780, Total Time: 544.45s\n",
            "--- AFTER TRAINING ---\tModel: Task2D.mdl\n",
            "[On Testing] Time: 2.503040313720703, Test Accuracy: 87.50%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 30.84s, Train Loss: 0.692430629, Train Accuracy: 50.18%\n",
            "[On Validation] ==> Val loss: 0.690304747, Total Time: 30.84s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 31.02s, Train Loss: 0.687107371, Train Accuracy: 56.36%\n",
            "[On Validation] ==> Val loss: 0.683707732, Total Time: 61.86s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 31.14s, Train Loss: 0.678479034, Train Accuracy: 65.10%\n",
            "[On Validation] ==> Val loss: 0.672188786, Total Time: 93.00s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 30.97s, Train Loss: 0.663604441, Train Accuracy: 70.82%\n",
            "[On Validation] ==> Val loss: 0.653153814, Total Time: 123.97s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 30.96s, Train Loss: 0.638661886, Train Accuracy: 73.97%\n",
            "[On Validation] ==> Val loss: 0.622380889, Total Time: 154.93s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 31.80s, Train Loss: 0.599714120, Train Accuracy: 76.84%\n",
            "[On Validation] ==> Val loss: 0.577640100, Total Time: 186.73s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.23s, Train Loss: 0.547406944, Train Accuracy: 79.37%\n",
            "[On Validation] ==> Val loss: 0.524255042, Total Time: 217.96s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 32.90s, Train Loss: 0.490830067, Train Accuracy: 81.81%\n",
            "[On Validation] ==> Val loss: 0.474324524, Total Time: 250.86s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 32.95s, Train Loss: 0.440582461, Train Accuracy: 83.45%\n",
            "[On Validation] ==> Val loss: 0.435256942, Total Time: 283.81s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 32.63s, Train Loss: 0.399716976, Train Accuracy: 84.82%\n",
            "[On Validation] ==> Val loss: 0.406408552, Total Time: 316.45s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 32.83s, Train Loss: 0.366201301, Train Accuracy: 86.08%\n",
            "[On Validation] ==> Val loss: 0.384650699, Total Time: 349.28s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 33.45s, Train Loss: 0.337814043, Train Accuracy: 87.30%\n",
            "[On Validation] ==> Val loss: 0.367962450, Total Time: 382.73s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 33.26s, Train Loss: 0.313287539, Train Accuracy: 88.22%\n",
            "[On Validation] ==> Val loss: 0.355227251, Total Time: 415.99s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 32.38s, Train Loss: 0.291971757, Train Accuracy: 89.22%\n",
            "[On Validation] ==> Val loss: 0.345716735, Total Time: 448.37s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 31.11s, Train Loss: 0.273396144, Train Accuracy: 89.97%\n",
            "[On Validation] ==> Val loss: 0.338748626, Total Time: 479.48s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 30.74s, Train Loss: 0.257089430, Train Accuracy: 90.70%\n",
            "[On Validation] ==> Val loss: 0.333760884, Total Time: 510.22s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 31.27s, Train Loss: 0.242607984, Train Accuracy: 91.26%\n",
            "[On Validation] ==> Val loss: 0.330327975, Total Time: 541.49s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 30.80s, Train Loss: 0.229578927, Train Accuracy: 91.72%\n",
            "[On Validation] ==> Val loss: 0.328183945, Total Time: 572.28s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 30.77s, Train Loss: 0.217712157, Train Accuracy: 92.31%\n",
            "[On Validation] ==> Val loss: 0.327109742, Total Time: 603.05s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 30.85s, Train Loss: 0.206801448, Train Accuracy: 92.73%\n",
            "[On Validation] ==> Val loss: 0.326949500, Total Time: 633.90s\n",
            "--- AFTER TRAINING ---\tModel: Task2E.mdl\n",
            "[On Testing] Time: 2.5451338291168213, Test Accuracy: 87.52%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eMMAv_S1WLNF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task2A.mdl')\n",
        "files.download('Task2B.mdl')\n",
        "files.download('Task2C.mdl')\n",
        "files.download('Task2D.mdl')\n",
        "files.download('Task2E.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n2JByG_xnrr1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task-3"
      ]
    },
    {
      "metadata": {
        "id": "vtAGGeuU2ect",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task3 = [(100, 50, 10, 'Task3A.mdl'), (200, 100, 10, 'Task3B.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rz1rm-runrPt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2400
        },
        "outputId": "da11bbda-5a14-4a44-e359-97cf46d99198"
      },
      "cell_type": "code",
      "source": [
        "for num_of_hidden1, num_of_hidden2, num_of_hidden3, task_name in task3:\n",
        "    class BOWClassifier(nn.Module):\n",
        "        def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "            super(BOWClassifier, self).__init__()\n",
        "            SEED = 42\n",
        "            torch.manual_seed(SEED)\n",
        "            torch.cuda.manual_seed(SEED)\n",
        "            self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "            self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "            self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "            self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "        def forward(self, x):\n",
        "            x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "            x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "            x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "            x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "            return x\n",
        "\n",
        "    num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "    num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "    bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "\n",
        "    # define a loss function and an optimizer\n",
        "    loss_function = nn.BCELoss()\n",
        "    opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "\n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "    \n",
        "    torch.save(bow, task_name)\n",
        "    \n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 35.35s, Train Loss: 0.694936959, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.693881880, Total Time: 35.35s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 34.67s, Train Loss: 0.693303970, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.692671734, Total Time: 70.02s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 34.74s, Train Loss: 0.692250105, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.691733172, Total Time: 104.76s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 34.85s, Train Loss: 0.691292826, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.690753229, Total Time: 139.61s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 35.50s, Train Loss: 0.690191506, Train Accuracy: 50.54%\n",
            "[On Validation] ==> Val loss: 0.689503467, Total Time: 175.12s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 35.95s, Train Loss: 0.688624498, Train Accuracy: 59.42%\n",
            "[On Validation] ==> Val loss: 0.687499562, Total Time: 211.07s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 34.86s, Train Loss: 0.685902498, Train Accuracy: 65.77%\n",
            "[On Validation] ==> Val loss: 0.684154764, Total Time: 245.93s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 36.58s, Train Loss: 0.681887111, Train Accuracy: 67.79%\n",
            "[On Validation] ==> Val loss: 0.679290330, Total Time: 282.51s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 36.74s, Train Loss: 0.675740227, Train Accuracy: 69.28%\n",
            "[On Validation] ==> Val loss: 0.671536327, Total Time: 319.24s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 36.59s, Train Loss: 0.665762349, Train Accuracy: 70.71%\n",
            "[On Validation] ==> Val loss: 0.658958359, Total Time: 355.83s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 36.33s, Train Loss: 0.649490480, Train Accuracy: 72.53%\n",
            "[On Validation] ==> Val loss: 0.638795841, Total Time: 392.17s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 36.79s, Train Loss: 0.623642092, Train Accuracy: 74.92%\n",
            "[On Validation] ==> Val loss: 0.607494356, Total Time: 428.96s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 36.61s, Train Loss: 0.585032141, Train Accuracy: 78.03%\n",
            "[On Validation] ==> Val loss: 0.563878313, Total Time: 465.57s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 35.40s, Train Loss: 0.533043920, Train Accuracy: 81.17%\n",
            "[On Validation] ==> Val loss: 0.510620205, Total Time: 500.97s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 34.49s, Train Loss: 0.473056962, Train Accuracy: 83.36%\n",
            "[On Validation] ==> Val loss: 0.456876301, Total Time: 535.47s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 35.20s, Train Loss: 0.415033929, Train Accuracy: 84.93%\n",
            "[On Validation] ==> Val loss: 0.412929995, Total Time: 570.66s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 35.11s, Train Loss: 0.366036695, Train Accuracy: 86.55%\n",
            "[On Validation] ==> Val loss: 0.381284977, Total Time: 605.78s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 35.06s, Train Loss: 0.326195217, Train Accuracy: 88.02%\n",
            "[On Validation] ==> Val loss: 0.359666224, Total Time: 640.84s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 34.57s, Train Loss: 0.293506011, Train Accuracy: 89.26%\n",
            "[On Validation] ==> Val loss: 0.345301930, Total Time: 675.41s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 35.03s, Train Loss: 0.266328226, Train Accuracy: 90.38%\n",
            "[On Validation] ==> Val loss: 0.336702514, Total Time: 710.43s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 34.65s, Train Loss: 0.243477949, Train Accuracy: 91.31%\n",
            "[On Validation] ==> Val loss: 0.332263210, Total Time: 745.09s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 35.26s, Train Loss: 0.223705886, Train Accuracy: 92.09%\n",
            "[On Validation] ==> Val loss: 0.330954911, Total Time: 780.35s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task3A.mdl\n",
            "[On Testing] Time: 2.857330083847046, Test Accuracy: 87.60%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 40.43s, Train Loss: 0.692922032, Train Accuracy: 50.02%\n",
            "[On Validation] ==> Val loss: 0.692548030, Total Time: 40.43s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 41.46s, Train Loss: 0.692221851, Train Accuracy: 51.05%\n",
            "[On Validation] ==> Val loss: 0.691717098, Total Time: 81.90s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 40.99s, Train Loss: 0.691286394, Train Accuracy: 57.38%\n",
            "[On Validation] ==> Val loss: 0.690668257, Total Time: 122.89s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 41.74s, Train Loss: 0.690016294, Train Accuracy: 64.82%\n",
            "[On Validation] ==> Val loss: 0.689124106, Total Time: 164.63s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 42.47s, Train Loss: 0.688054048, Train Accuracy: 67.40%\n",
            "[On Validation] ==> Val loss: 0.686661194, Total Time: 207.10s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 42.08s, Train Loss: 0.685037139, Train Accuracy: 68.07%\n",
            "[On Validation] ==> Val loss: 0.683149963, Total Time: 249.18s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 42.86s, Train Loss: 0.680775656, Train Accuracy: 69.08%\n",
            "[On Validation] ==> Val loss: 0.678026176, Total Time: 292.04s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 42.38s, Train Loss: 0.674257148, Train Accuracy: 70.05%\n",
            "[On Validation] ==> Val loss: 0.669998841, Total Time: 334.42s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 41.36s, Train Loss: 0.663931797, Train Accuracy: 71.50%\n",
            "[On Validation] ==> Val loss: 0.657249905, Total Time: 375.78s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 40.35s, Train Loss: 0.647606976, Train Accuracy: 73.11%\n",
            "[On Validation] ==> Val loss: 0.637435409, Total Time: 416.12s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 40.96s, Train Loss: 0.622623753, Train Accuracy: 75.83%\n",
            "[On Validation] ==> Val loss: 0.608034152, Total Time: 457.08s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 40.38s, Train Loss: 0.586528413, Train Accuracy: 78.69%\n",
            "[On Validation] ==> Val loss: 0.568007868, Total Time: 497.47s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 40.33s, Train Loss: 0.539210069, Train Accuracy: 81.52%\n",
            "[On Validation] ==> Val loss: 0.519889277, Total Time: 537.80s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 41.18s, Train Loss: 0.484387338, Train Accuracy: 83.32%\n",
            "[On Validation] ==> Val loss: 0.469757878, Total Time: 578.98s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 41.29s, Train Loss: 0.428426012, Train Accuracy: 84.96%\n",
            "[On Validation] ==> Val loss: 0.424862300, Total Time: 620.27s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 40.25s, Train Loss: 0.378075504, Train Accuracy: 86.40%\n",
            "[On Validation] ==> Val loss: 0.390314365, Total Time: 660.52s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 40.24s, Train Loss: 0.336153139, Train Accuracy: 87.76%\n",
            "[On Validation] ==> Val loss: 0.365942463, Total Time: 700.75s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 40.50s, Train Loss: 0.301975215, Train Accuracy: 89.02%\n",
            "[On Validation] ==> Val loss: 0.349901755, Total Time: 741.25s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 40.95s, Train Loss: 0.273746590, Train Accuracy: 90.25%\n",
            "[On Validation] ==> Val loss: 0.339827666, Total Time: 782.20s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 40.46s, Train Loss: 0.250034703, Train Accuracy: 91.14%\n",
            "[On Validation] ==> Val loss: 0.334280307, Total Time: 822.66s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 43.09s, Train Loss: 0.229609306, Train Accuracy: 91.94%\n",
            "[On Validation] ==> Val loss: 0.332138664, Total Time: 865.75s\n",
            "--- AFTER TRAINING ---\tModel: Task3B.mdl\n",
            "[On Testing] Time: 2.899967908859253, Test Accuracy: 87.68%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGf7IdbRdbk7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task3A.mdl')\n",
        "files.download('Task3B.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-MYVmtv9jn7n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "quMcuqqyjqP2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TASK-4"
      ]
    },
    {
      "metadata": {
        "id": "FznXcSrri_l6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task4 = [(30, 20, 10, 'Task4A.mdl'), (100, 100, 0, 'Task4B.mdl'), (100, 10, 0, 'Task4C.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TMTr6ZqQjoZA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3437
        },
        "outputId": "3f37bcbf-4bcc-4900-d1d8-04d978250d2a"
      },
      "cell_type": "code",
      "source": [
        "k = 1\n",
        "for num_of_hidden1, num_of_hidden2, num_of_hidden3, task_name in task4:\n",
        "    if(k == 1):\n",
        "        k = 2\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "    elif(k == 2):\n",
        "        k = 2\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h2h = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases i2h\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h2o = nn.Linear(hidden_size2, output_size) # initialises weights and biases h2o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h2h(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h2o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "\n",
        "    # define a loss function and an optimizer\n",
        "    loss_function = nn.BCELoss()\n",
        "    opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "    \n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "\n",
        "    torch.save(bow, task_name)\n",
        "    \n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 33.35s, Train Loss: 0.694767215, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.693907171, Total Time: 33.35s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 33.38s, Train Loss: 0.693389675, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.692973473, Total Time: 66.73s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 33.82s, Train Loss: 0.692659883, Train Accuracy: 50.04%\n",
            "[On Validation] ==> Val loss: 0.692368075, Total Time: 100.55s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 33.79s, Train Loss: 0.692084617, Train Accuracy: 51.22%\n",
            "[On Validation] ==> Val loss: 0.691792813, Total Time: 134.34s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 32.06s, Train Loss: 0.691481333, Train Accuracy: 56.62%\n",
            "[On Validation] ==> Val loss: 0.691124821, Total Time: 166.40s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 31.25s, Train Loss: 0.690742162, Train Accuracy: 62.57%\n",
            "[On Validation] ==> Val loss: 0.690270678, Total Time: 197.65s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.17s, Train Loss: 0.689755137, Train Accuracy: 66.46%\n",
            "[On Validation] ==> Val loss: 0.689115704, Total Time: 228.82s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.15s, Train Loss: 0.688349802, Train Accuracy: 68.33%\n",
            "[On Validation] ==> Val loss: 0.687378670, Total Time: 259.96s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 31.80s, Train Loss: 0.686079432, Train Accuracy: 69.51%\n",
            "[On Validation] ==> Val loss: 0.684424669, Total Time: 291.77s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 31.13s, Train Loss: 0.682300931, Train Accuracy: 70.14%\n",
            "[On Validation] ==> Val loss: 0.679790312, Total Time: 322.89s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 31.58s, Train Loss: 0.676687604, Train Accuracy: 71.29%\n",
            "[On Validation] ==> Val loss: 0.673053866, Total Time: 354.47s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 31.60s, Train Loss: 0.668098983, Train Accuracy: 72.46%\n",
            "[On Validation] ==> Val loss: 0.662496956, Total Time: 386.07s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 32.12s, Train Loss: 0.654313671, Train Accuracy: 73.87%\n",
            "[On Validation] ==> Val loss: 0.645443142, Total Time: 418.19s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 31.48s, Train Loss: 0.632220966, Train Accuracy: 75.78%\n",
            "[On Validation] ==> Val loss: 0.618577530, Total Time: 449.67s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 31.90s, Train Loss: 0.598201746, Train Accuracy: 77.99%\n",
            "[On Validation] ==> Val loss: 0.578972436, Total Time: 481.57s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 31.77s, Train Loss: 0.549723354, Train Accuracy: 80.70%\n",
            "[On Validation] ==> Val loss: 0.526750825, Total Time: 513.34s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 32.59s, Train Loss: 0.489710230, Train Accuracy: 82.98%\n",
            "[On Validation] ==> Val loss: 0.470252169, Total Time: 545.93s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 32.36s, Train Loss: 0.429002372, Train Accuracy: 84.60%\n",
            "[On Validation] ==> Val loss: 0.422607613, Total Time: 578.29s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 32.53s, Train Loss: 0.377376308, Train Accuracy: 86.10%\n",
            "[On Validation] ==> Val loss: 0.388394738, Total Time: 610.81s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 33.34s, Train Loss: 0.335577039, Train Accuracy: 87.60%\n",
            "[On Validation] ==> Val loss: 0.365006846, Total Time: 644.15s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 32.44s, Train Loss: 0.301345689, Train Accuracy: 88.95%\n",
            "[On Validation] ==> Val loss: 0.349208662, Total Time: 676.59s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 32.64s, Train Loss: 0.272979760, Train Accuracy: 90.16%\n",
            "[On Validation] ==> Val loss: 0.339509051, Total Time: 709.23s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 33.28s, Train Loss: 0.249292713, Train Accuracy: 90.96%\n",
            "[On Validation] ==> Val loss: 0.334336225, Total Time: 742.51s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 33.17s, Train Loss: 0.228966995, Train Accuracy: 91.81%\n",
            "[On Validation] ==> Val loss: 0.332504831, Total Time: 775.68s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task4A.mdl\n",
            "[On Testing] Time: 2.9076828956604004, Test Accuracy: 87.52%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 31.86s, Train Loss: 0.691614258, Train Accuracy: 49.98%\n",
            "[On Validation] ==> Val loss: 0.688385615, Total Time: 31.86s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 31.30s, Train Loss: 0.683821628, Train Accuracy: 55.48%\n",
            "[On Validation] ==> Val loss: 0.678329603, Total Time: 63.16s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 31.64s, Train Loss: 0.670527282, Train Accuracy: 68.45%\n",
            "[On Validation] ==> Val loss: 0.661184870, Total Time: 94.79s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 31.72s, Train Loss: 0.648115321, Train Accuracy: 72.71%\n",
            "[On Validation] ==> Val loss: 0.633014937, Total Time: 126.51s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 31.77s, Train Loss: 0.612384750, Train Accuracy: 75.70%\n",
            "[On Validation] ==> Val loss: 0.590897451, Total Time: 158.28s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 31.24s, Train Loss: 0.562413207, Train Accuracy: 78.64%\n",
            "[On Validation] ==> Val loss: 0.537921602, Total Time: 189.52s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.52s, Train Loss: 0.504972331, Train Accuracy: 81.13%\n",
            "[On Validation] ==> Val loss: 0.485258416, Total Time: 221.04s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.07s, Train Loss: 0.451692876, Train Accuracy: 83.13%\n",
            "[On Validation] ==> Val loss: 0.442964299, Total Time: 252.12s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 31.05s, Train Loss: 0.408098381, Train Accuracy: 84.58%\n",
            "[On Validation] ==> Val loss: 0.411809077, Total Time: 283.17s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 31.07s, Train Loss: 0.372747313, Train Accuracy: 85.84%\n",
            "[On Validation] ==> Val loss: 0.388584092, Total Time: 314.24s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 31.05s, Train Loss: 0.343072831, Train Accuracy: 87.09%\n",
            "[On Validation] ==> Val loss: 0.370827908, Total Time: 345.30s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 31.08s, Train Loss: 0.317544146, Train Accuracy: 88.21%\n",
            "[On Validation] ==> Val loss: 0.357193258, Total Time: 376.37s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 32.13s, Train Loss: 0.295432068, Train Accuracy: 89.02%\n",
            "[On Validation] ==> Val loss: 0.346934657, Total Time: 408.50s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 31.57s, Train Loss: 0.276233565, Train Accuracy: 89.82%\n",
            "[On Validation] ==> Val loss: 0.339441353, Total Time: 440.08s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 32.15s, Train Loss: 0.259443299, Train Accuracy: 90.53%\n",
            "[On Validation] ==> Val loss: 0.334159112, Total Time: 472.22s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 32.50s, Train Loss: 0.244574227, Train Accuracy: 91.19%\n",
            "[On Validation] ==> Val loss: 0.330582667, Total Time: 504.72s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 33.11s, Train Loss: 0.231232920, Train Accuracy: 91.71%\n",
            "[On Validation] ==> Val loss: 0.328344795, Total Time: 537.83s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 33.11s, Train Loss: 0.219112934, Train Accuracy: 92.22%\n",
            "[On Validation] ==> Val loss: 0.327231016, Total Time: 570.94s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 32.62s, Train Loss: 0.207988097, Train Accuracy: 92.69%\n",
            "[On Validation] ==> Val loss: 0.327066619, Total Time: 603.56s\n",
            "--- AFTER TRAINING ---\tModel: Task4B.mdl\n",
            "[On Testing] Time: 2.605039119720459, Test Accuracy: 87.42%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 32.12s, Train Loss: 0.695555229, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.690231321, Total Time: 32.12s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 31.24s, Train Loss: 0.684513336, Train Accuracy: 50.73%\n",
            "[On Validation] ==> Val loss: 0.677292636, Total Time: 63.35s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 31.22s, Train Loss: 0.668548356, Train Accuracy: 59.67%\n",
            "[On Validation] ==> Val loss: 0.658209414, Total Time: 94.58s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 30.83s, Train Loss: 0.645213365, Train Accuracy: 70.84%\n",
            "[On Validation] ==> Val loss: 0.630098964, Total Time: 125.41s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 30.74s, Train Loss: 0.610437976, Train Accuracy: 75.95%\n",
            "[On Validation] ==> Val loss: 0.589706238, Total Time: 156.15s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 31.18s, Train Loss: 0.563128984, Train Accuracy: 79.35%\n",
            "[On Validation] ==> Val loss: 0.539537649, Total Time: 187.33s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.20s, Train Loss: 0.508353697, Train Accuracy: 81.58%\n",
            "[On Validation] ==> Val loss: 0.488889708, Total Time: 218.53s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.39s, Train Loss: 0.456119829, Train Accuracy: 83.20%\n",
            "[On Validation] ==> Val loss: 0.447053155, Total Time: 249.92s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 31.28s, Train Loss: 0.412346166, Train Accuracy: 84.76%\n",
            "[On Validation] ==> Val loss: 0.415629766, Total Time: 281.20s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 31.02s, Train Loss: 0.376522529, Train Accuracy: 85.91%\n",
            "[On Validation] ==> Val loss: 0.392057396, Total Time: 312.22s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 31.24s, Train Loss: 0.346428265, Train Accuracy: 87.05%\n",
            "[On Validation] ==> Val loss: 0.374011131, Total Time: 343.46s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 31.49s, Train Loss: 0.320639337, Train Accuracy: 88.07%\n",
            "[On Validation] ==> Val loss: 0.360113360, Total Time: 374.95s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 31.59s, Train Loss: 0.298345336, Train Accuracy: 88.85%\n",
            "[On Validation] ==> Val loss: 0.349604130, Total Time: 406.54s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 31.89s, Train Loss: 0.278983333, Train Accuracy: 89.70%\n",
            "[On Validation] ==> Val loss: 0.341945248, Total Time: 438.42s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 31.40s, Train Loss: 0.262044426, Train Accuracy: 90.58%\n",
            "[On Validation] ==> Val loss: 0.336553683, Total Time: 469.83s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 31.72s, Train Loss: 0.247065698, Train Accuracy: 91.07%\n",
            "[On Validation] ==> Val loss: 0.332881333, Total Time: 501.55s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 32.16s, Train Loss: 0.233633344, Train Accuracy: 91.62%\n",
            "[On Validation] ==> Val loss: 0.330522880, Total Time: 533.71s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 32.27s, Train Loss: 0.221427791, Train Accuracy: 92.21%\n",
            "[On Validation] ==> Val loss: 0.329262396, Total Time: 565.98s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 32.23s, Train Loss: 0.210235543, Train Accuracy: 92.68%\n",
            "[On Validation] ==> Val loss: 0.328942986, Total Time: 598.21s\n",
            "--- AFTER TRAINING ---\tModel: Task4C.mdl\n",
            "[On Testing] Time: 2.5783963203430176, Test Accuracy: 87.44%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qD-kkwEKW0iM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task4A.mdl')\n",
        "files.download('Task4B.mdl')\n",
        "files.download('Task4C.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "12KQYM1RYuiH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task-5"
      ]
    },
    {
      "metadata": {
        "id": "cd6rex2FYwmp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task5 = [('relu', 'Task5A.mdl'), ('tanh', 'Task5B.mdl'), ('sigmoid', 'Task5C.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-lCj7dx6ZB-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 4967
        },
        "outputId": "438649a2-2063-405e-ba47-3fc90c41ea9e"
      },
      "cell_type": "code",
      "source": [
        "for activation, task_name in task5:\n",
        "    if(activation == 'relu'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "    if(activation == 'tanh'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.tanh(self.i2h1(x)) # tanh activation @ hidden layer\n",
        "                x = torch.tanh(self.h12h2(x)) # tanh activation @ hidden layer\n",
        "                x = torch.tanh(self.h22h3(x)) # tanh activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "    if(activation == 'sigmoid'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.sigmoid(self.i2h1(x)) # sigmoid activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h12h2(x)) # sigmoid activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h22h3(x)) # sigmoid activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "    # define a loss function and an optimizer\n",
        "    loss_function = nn.BCELoss()\n",
        "    if(activation == 'sigmoid'):\n",
        "        opt = torch.optim.SGD(bow.parameters(), lr = 0.001) ## sigmoid activation converges slowly\n",
        "    else:\n",
        "        opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "\n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "\n",
        "    torch.save(bow, task_name)\n",
        "    \n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 29.70s, Train Loss: 0.694767215, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.693907171, Total Time: 29.70s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 30.03s, Train Loss: 0.693389675, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.692973473, Total Time: 59.73s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 29.63s, Train Loss: 0.692659883, Train Accuracy: 50.04%\n",
            "[On Validation] ==> Val loss: 0.692368075, Total Time: 89.36s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 30.53s, Train Loss: 0.692084617, Train Accuracy: 51.22%\n",
            "[On Validation] ==> Val loss: 0.691792813, Total Time: 119.89s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 30.67s, Train Loss: 0.691481333, Train Accuracy: 56.62%\n",
            "[On Validation] ==> Val loss: 0.691124821, Total Time: 150.56s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 30.41s, Train Loss: 0.690742162, Train Accuracy: 62.57%\n",
            "[On Validation] ==> Val loss: 0.690270678, Total Time: 180.97s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 29.96s, Train Loss: 0.689755137, Train Accuracy: 66.46%\n",
            "[On Validation] ==> Val loss: 0.689115704, Total Time: 210.94s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 29.86s, Train Loss: 0.688349802, Train Accuracy: 68.33%\n",
            "[On Validation] ==> Val loss: 0.687378670, Total Time: 240.80s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 30.45s, Train Loss: 0.686079432, Train Accuracy: 69.51%\n",
            "[On Validation] ==> Val loss: 0.684424669, Total Time: 271.25s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 29.71s, Train Loss: 0.682300931, Train Accuracy: 70.14%\n",
            "[On Validation] ==> Val loss: 0.679790312, Total Time: 300.96s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 29.61s, Train Loss: 0.676687604, Train Accuracy: 71.29%\n",
            "[On Validation] ==> Val loss: 0.673053866, Total Time: 330.58s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 29.78s, Train Loss: 0.668098983, Train Accuracy: 72.46%\n",
            "[On Validation] ==> Val loss: 0.662496956, Total Time: 360.36s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 29.71s, Train Loss: 0.654313671, Train Accuracy: 73.87%\n",
            "[On Validation] ==> Val loss: 0.645443142, Total Time: 390.07s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 29.80s, Train Loss: 0.632220966, Train Accuracy: 75.78%\n",
            "[On Validation] ==> Val loss: 0.618577530, Total Time: 419.87s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 29.85s, Train Loss: 0.598201746, Train Accuracy: 77.99%\n",
            "[On Validation] ==> Val loss: 0.578972436, Total Time: 449.72s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 30.73s, Train Loss: 0.549723354, Train Accuracy: 80.70%\n",
            "[On Validation] ==> Val loss: 0.526750825, Total Time: 480.45s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 30.67s, Train Loss: 0.489710230, Train Accuracy: 82.98%\n",
            "[On Validation] ==> Val loss: 0.470252169, Total Time: 511.11s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 30.36s, Train Loss: 0.429002372, Train Accuracy: 84.60%\n",
            "[On Validation] ==> Val loss: 0.422607613, Total Time: 541.47s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 31.33s, Train Loss: 0.377376308, Train Accuracy: 86.10%\n",
            "[On Validation] ==> Val loss: 0.388394738, Total Time: 572.81s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 30.59s, Train Loss: 0.335577039, Train Accuracy: 87.60%\n",
            "[On Validation] ==> Val loss: 0.365006846, Total Time: 603.39s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 30.11s, Train Loss: 0.301345689, Train Accuracy: 88.95%\n",
            "[On Validation] ==> Val loss: 0.349208662, Total Time: 633.51s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 30.16s, Train Loss: 0.272979760, Train Accuracy: 90.16%\n",
            "[On Validation] ==> Val loss: 0.339509051, Total Time: 663.67s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 30.06s, Train Loss: 0.249292713, Train Accuracy: 90.96%\n",
            "[On Validation] ==> Val loss: 0.334336225, Total Time: 693.73s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 29.97s, Train Loss: 0.228966995, Train Accuracy: 91.81%\n",
            "[On Validation] ==> Val loss: 0.332504831, Total Time: 723.70s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task5A.mdl\n",
            "[On Testing] Time: 2.761873722076416, Test Accuracy: 87.52%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 30.44s, Train Loss: 0.691333151, Train Accuracy: 52.21%\n",
            "[On Validation] ==> Val loss: 0.688294692, Total Time: 30.44s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 30.01s, Train Loss: 0.685687966, Train Accuracy: 63.18%\n",
            "[On Validation] ==> Val loss: 0.682286099, Total Time: 60.45s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 29.92s, Train Loss: 0.678707658, Train Accuracy: 67.53%\n",
            "[On Validation] ==> Val loss: 0.673533288, Total Time: 90.37s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 31.10s, Train Loss: 0.667702568, Train Accuracy: 69.17%\n",
            "[On Validation] ==> Val loss: 0.659153392, Total Time: 121.47s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 30.06s, Train Loss: 0.649059623, Train Accuracy: 70.87%\n",
            "[On Validation] ==> Val loss: 0.635048339, Total Time: 151.52s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 31.60s, Train Loss: 0.617592714, Train Accuracy: 73.31%\n",
            "[On Validation] ==> Val loss: 0.595951639, Total Time: 183.13s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 32.02s, Train Loss: 0.567766511, Train Accuracy: 76.94%\n",
            "[On Validation] ==> Val loss: 0.538667672, Total Time: 215.15s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.40s, Train Loss: 0.502377667, Train Accuracy: 80.51%\n",
            "[On Validation] ==> Val loss: 0.474746211, Total Time: 246.55s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 30.67s, Train Loss: 0.439233289, Train Accuracy: 82.93%\n",
            "[On Validation] ==> Val loss: 0.424056862, Total Time: 277.22s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 30.29s, Train Loss: 0.388973352, Train Accuracy: 84.91%\n",
            "[On Validation] ==> Val loss: 0.388488214, Total Time: 307.52s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 30.53s, Train Loss: 0.348703112, Train Accuracy: 86.62%\n",
            "[On Validation] ==> Val loss: 0.362998341, Total Time: 338.05s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 30.36s, Train Loss: 0.314697018, Train Accuracy: 87.94%\n",
            "[On Validation] ==> Val loss: 0.344539539, Total Time: 368.40s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 30.40s, Train Loss: 0.285493559, Train Accuracy: 89.26%\n",
            "[On Validation] ==> Val loss: 0.331726715, Total Time: 398.81s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 31.15s, Train Loss: 0.260525845, Train Accuracy: 90.36%\n",
            "[On Validation] ==> Val loss: 0.323262212, Total Time: 429.96s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 30.08s, Train Loss: 0.239191344, Train Accuracy: 91.33%\n",
            "[On Validation] ==> Val loss: 0.317973610, Total Time: 460.03s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 30.11s, Train Loss: 0.220529159, Train Accuracy: 92.18%\n",
            "[On Validation] ==> Val loss: 0.315155719, Total Time: 490.15s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 30.31s, Train Loss: 0.203774893, Train Accuracy: 92.93%\n",
            "[On Validation] ==> Val loss: 0.314612845, Total Time: 520.46s\n",
            "--- AFTER TRAINING ---\tModel: Task5B.mdl\n",
            "[On Testing] Time: 2.702239990234375, Test Accuracy: 87.54%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 30.09s, Train Loss: 0.693641285, Train Accuracy: 50.32%\n",
            "[On Validation] ==> Val loss: 0.693286532, Total Time: 30.09s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 30.26s, Train Loss: 0.693346157, Train Accuracy: 50.35%\n",
            "[On Validation] ==> Val loss: 0.693274024, Total Time: 60.35s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 31.03s, Train Loss: 0.693334032, Train Accuracy: 50.36%\n",
            "[On Validation] ==> Val loss: 0.693261413, Total Time: 91.38s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 30.52s, Train Loss: 0.693321748, Train Accuracy: 50.37%\n",
            "[On Validation] ==> Val loss: 0.693248597, Total Time: 121.90s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 32.36s, Train Loss: 0.693309201, Train Accuracy: 50.37%\n",
            "[On Validation] ==> Val loss: 0.693235478, Total Time: 154.26s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 32.25s, Train Loss: 0.693296296, Train Accuracy: 50.40%\n",
            "[On Validation] ==> Val loss: 0.693221940, Total Time: 186.51s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 30.76s, Train Loss: 0.693282918, Train Accuracy: 50.43%\n",
            "[On Validation] ==> Val loss: 0.693207876, Total Time: 217.28s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 30.09s, Train Loss: 0.693268948, Train Accuracy: 50.46%\n",
            "[On Validation] ==> Val loss: 0.693193166, Total Time: 247.36s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 30.13s, Train Loss: 0.693254256, Train Accuracy: 50.46%\n",
            "[On Validation] ==> Val loss: 0.693177653, Total Time: 277.49s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 30.07s, Train Loss: 0.693238696, Train Accuracy: 50.48%\n",
            "[On Validation] ==> Val loss: 0.693161199, Total Time: 307.56s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 30.10s, Train Loss: 0.693222109, Train Accuracy: 50.50%\n",
            "[On Validation] ==> Val loss: 0.693143614, Total Time: 337.66s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 30.10s, Train Loss: 0.693204302, Train Accuracy: 50.53%\n",
            "[On Validation] ==> Val loss: 0.693124701, Total Time: 367.76s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 30.21s, Train Loss: 0.693185066, Train Accuracy: 50.55%\n",
            "[On Validation] ==> Val loss: 0.693104234, Total Time: 397.97s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 30.23s, Train Loss: 0.693164155, Train Accuracy: 50.61%\n",
            "[On Validation] ==> Val loss: 0.693081929, Total Time: 428.20s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 30.13s, Train Loss: 0.693141273, Train Accuracy: 50.63%\n",
            "[On Validation] ==> Val loss: 0.693057478, Total Time: 458.33s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 30.67s, Train Loss: 0.693116081, Train Accuracy: 50.68%\n",
            "[On Validation] ==> Val loss: 0.693030499, Total Time: 489.00s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 30.26s, Train Loss: 0.693088171, Train Accuracy: 50.72%\n",
            "[On Validation] ==> Val loss: 0.693000541, Total Time: 519.27s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 30.02s, Train Loss: 0.693057052, Train Accuracy: 50.75%\n",
            "[On Validation] ==> Val loss: 0.692967054, Total Time: 549.28s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 30.12s, Train Loss: 0.693022130, Train Accuracy: 50.78%\n",
            "[On Validation] ==> Val loss: 0.692929368, Total Time: 579.40s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 30.11s, Train Loss: 0.692982676, Train Accuracy: 50.87%\n",
            "[On Validation] ==> Val loss: 0.692886683, Total Time: 609.51s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 32.17s, Train Loss: 0.692937797, Train Accuracy: 50.90%\n",
            "[On Validation] ==> Val loss: 0.692837969, Total Time: 641.68s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 31.88s, Train Loss: 0.692886376, Train Accuracy: 50.98%\n",
            "[On Validation] ==> Val loss: 0.692781959, Total Time: 673.57s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 31.16s, Train Loss: 0.692827007, Train Accuracy: 51.08%\n",
            "[On Validation] ==> Val loss: 0.692717055, Total Time: 704.72s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 30.65s, Train Loss: 0.692757906, Train Accuracy: 51.23%\n",
            "[On Validation] ==> Val loss: 0.692641189, Total Time: 735.37s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 30.66s, Train Loss: 0.692676763, Train Accuracy: 51.28%\n",
            "[On Validation] ==> Val loss: 0.692551697, Total Time: 766.04s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 30.92s, Train Loss: 0.692580573, Train Accuracy: 51.40%\n",
            "[On Validation] ==> Val loss: 0.692445081, Total Time: 796.96s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 30.85s, Train Loss: 0.692465353, Train Accuracy: 51.60%\n",
            "[On Validation] ==> Val loss: 0.692316644, Total Time: 827.81s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 30.32s, Train Loss: 0.692325734, Train Accuracy: 51.80%\n",
            "[On Validation] ==> Val loss: 0.692160048, Total Time: 858.13s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 30.36s, Train Loss: 0.692154377, Train Accuracy: 51.91%\n",
            "[On Validation] ==> Val loss: 0.691966489, Total Time: 888.49s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 30.46s, Train Loss: 0.691941019, Train Accuracy: 52.18%\n",
            "[On Validation] ==> Val loss: 0.691723568, Total Time: 918.95s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 30.51s, Train Loss: 0.691670980, Train Accuracy: 52.53%\n",
            "[On Validation] ==> Val loss: 0.691413333, Total Time: 949.46s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 30.74s, Train Loss: 0.691322736, Train Accuracy: 53.02%\n",
            "[On Validation] ==> Val loss: 0.691009130, Total Time: 980.20s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 30.43s, Train Loss: 0.690863813, Train Accuracy: 53.56%\n",
            "[On Validation] ==> Val loss: 0.690470138, Total Time: 1010.63s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 30.27s, Train Loss: 0.690243513, Train Accuracy: 54.30%\n",
            "[On Validation] ==> Val loss: 0.689731565, Total Time: 1040.89s\n",
            "Epoch 35/100\n",
            "[On Training] ==> Time: 30.34s, Train Loss: 0.689379574, Train Accuracy: 55.38%\n",
            "[On Validation] ==> Val loss: 0.688686331, Total Time: 1071.24s\n",
            "Epoch 36/100\n",
            "[On Training] ==> Time: 30.28s, Train Loss: 0.688132453, Train Accuracy: 56.96%\n",
            "[On Validation] ==> Val loss: 0.687149006, Total Time: 1101.52s\n",
            "Epoch 37/100\n",
            "[On Training] ==> Time: 31.94s, Train Loss: 0.686252823, Train Accuracy: 59.41%\n",
            "[On Validation] ==> Val loss: 0.684780568, Total Time: 1133.45s\n",
            "Epoch 38/100\n",
            "[On Training] ==> Time: 32.03s, Train Loss: 0.683268483, Train Accuracy: 62.14%\n",
            "[On Validation] ==> Val loss: 0.680923949, Total Time: 1165.48s\n",
            "Epoch 39/100\n",
            "[On Training] ==> Time: 31.24s, Train Loss: 0.678228843, Train Accuracy: 65.18%\n",
            "[On Validation] ==> Val loss: 0.674231447, Total Time: 1196.71s\n",
            "Epoch 40/100\n",
            "[On Training] ==> Time: 30.79s, Train Loss: 0.669122508, Train Accuracy: 67.89%\n",
            "[On Validation] ==> Val loss: 0.661851458, Total Time: 1227.50s\n",
            "Epoch 41/100\n",
            "[On Training] ==> Time: 30.30s, Train Loss: 0.651701744, Train Accuracy: 70.03%\n",
            "[On Validation] ==> Val loss: 0.638080023, Total Time: 1257.80s\n",
            "Epoch 42/100\n",
            "[On Training] ==> Time: 30.74s, Train Loss: 0.618111326, Train Accuracy: 72.73%\n",
            "[On Validation] ==> Val loss: 0.594005082, Total Time: 1288.53s\n",
            "Epoch 43/100\n",
            "[On Training] ==> Time: 30.29s, Train Loss: 0.558626038, Train Accuracy: 76.87%\n",
            "[On Validation] ==> Val loss: 0.523327236, Total Time: 1318.83s\n",
            "Epoch 44/100\n",
            "[On Training] ==> Time: 30.28s, Train Loss: 0.478574982, Train Accuracy: 81.24%\n",
            "[On Validation] ==> Val loss: 0.448801493, Total Time: 1349.10s\n",
            "Epoch 45/100\n",
            "[On Training] ==> Time: 30.23s, Train Loss: 0.409485941, Train Accuracy: 83.84%\n",
            "[On Validation] ==> Val loss: 0.399178281, Total Time: 1379.34s\n",
            "Epoch 46/100\n",
            "[On Training] ==> Time: 30.20s, Train Loss: 0.358656598, Train Accuracy: 85.92%\n",
            "[On Validation] ==> Val loss: 0.366599603, Total Time: 1409.53s\n",
            "Epoch 47/100\n",
            "[On Training] ==> Time: 31.21s, Train Loss: 0.317354892, Train Accuracy: 87.67%\n",
            "[On Validation] ==> Val loss: 0.344098133, Total Time: 1440.74s\n",
            "Epoch 48/100\n",
            "[On Training] ==> Time: 30.69s, Train Loss: 0.282565835, Train Accuracy: 89.26%\n",
            "[On Validation] ==> Val loss: 0.329820388, Total Time: 1471.43s\n",
            "Epoch 49/100\n",
            "[On Training] ==> Time: 30.96s, Train Loss: 0.253844971, Train Accuracy: 90.57%\n",
            "[On Validation] ==> Val loss: 0.321745627, Total Time: 1502.39s\n",
            "Epoch 50/100\n",
            "[On Training] ==> Time: 30.39s, Train Loss: 0.230097854, Train Accuracy: 91.59%\n",
            "[On Validation] ==> Val loss: 0.317845066, Total Time: 1532.78s\n",
            "Epoch 51/100\n",
            "[On Training] ==> Time: 30.55s, Train Loss: 0.209586617, Train Accuracy: 92.57%\n",
            "[On Validation] ==> Val loss: 0.317303116, Total Time: 1563.32s\n",
            "--- AFTER TRAINING ---\tModel: Task5C.mdl\n",
            "[On Testing] Time: 2.7564449310302734, Test Accuracy: 87.58%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lB4CfOgdF6l4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task5A.mdl')\n",
        "files.download('Task5B.mdl')\n",
        "files.download('Task5C.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-gTTJ8yE1o9F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task-6"
      ]
    },
    {
      "metadata": {
        "id": "3EitRXhg_Q4p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bigram_build_vocabulary(sentences):\n",
        "    # Build bigram vocabulary\n",
        "    bigrams_dictWordCount = {}\n",
        "    bigrams_dictWordCount = {word+' '+sent.split()[i+1]:int(0) for sent in sentences  for i, word in enumerate(sent.split()) if i < len(sent.split())-1}\n",
        "\n",
        "    for word in sent:\n",
        "        dictWordCount[word] = 0 # initialising the dict value to zero\n",
        "    for word in sent:\n",
        "        dictWordCount[word] += 1 # updating the dictionary count\n",
        "    \n",
        "    temp = dictWordCount.copy()\n",
        "    for key, val in temp.items():\n",
        "        if(dictWordCount[key] <= 10):\n",
        "            del dictWordCount[key]\n",
        "    \n",
        "    # Mapping from index to word\n",
        "    vocabulary_inv = sorted(dictWordCount, key=dictWordCount.__getitem__, reverse=True)\n",
        "    \n",
        "    # Mapping from word to index\n",
        "    vocabulary = {x: i for i, x in enumerate(vocabulary_inv)}\n",
        "    return vocabulary, vocabulary_inv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t2ywCp1R_WlD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bigram_word_to_ix, bigram_ix_to_word = build_vocabulary(train_text_reviews+val_text_reviews+test_text_reviews)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7J2XQOoF_a9g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "BIGRAM_VOCAB_SIZE = len(bigram_word_to_ix)\n",
        "bigram_ix_to_word[bigram_word_to_ix['kick']]=='kick', bigram_word_to_ix['kick'], BIGRAM_VOCAB_SIZE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "W6xGAkhM_cHp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hmF5hYmn1ome",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def bigram_make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix)).to('cuda:0') #, device=device) # make 1D vector of len = vocab size\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "#             raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "            pass\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3b0G-yVN1sGe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Task-7"
      ]
    },
    {
      "metadata": {
        "id": "aZ-uxYYw1t8z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "task7 = [('ce', 'Task7A.mdl'), ('mse', 'Task7B.mdl'), ('hinge', 'Task7C.mdl')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jWoJ_I333ACf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7619
        },
        "outputId": "970553bb-a5ab-4caf-9f70-a1081c3eea63"
      },
      "cell_type": "code",
      "source": [
        "for loss_fun, task_name in task7:\n",
        "    if(loss_fun == 'ce'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "        # define a loss function and \n",
        "        loss_function = nn.BCELoss()\n",
        "        \n",
        "    if(loss_fun == 'mse'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "        # define a loss function and \n",
        "        loss_function = nn.MSELoss()\n",
        "        \n",
        "    if(loss_fun == 'hinge'):\n",
        "        class BOWClassifier(nn.Module):\n",
        "            def __init__(self, input_size, hidden_size1, hidden_size2, hidden_size3, output_size):\n",
        "                super(BOWClassifier, self).__init__()\n",
        "                SEED = 42\n",
        "                torch.manual_seed(SEED)\n",
        "                torch.cuda.manual_seed(SEED)\n",
        "                self.i2h1 = nn.Linear(input_size, hidden_size1) # initialises weights and biases i2h1\n",
        "                self.drop1 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h12h2 = nn.Linear(hidden_size1, hidden_size2) # initialises weights and biases h12h2\n",
        "                self.drop2 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h22h3 = nn.Linear(hidden_size2, hidden_size3) # initialises weights and biases h22h3\n",
        "                self.drop3 = nn.Dropout(0.5) # Adding dropout layer\n",
        "                \n",
        "                self.h32o = nn.Linear(hidden_size3, output_size) # initialises weights and biases h32o\n",
        "\n",
        "            def forward(self, x):\n",
        "                x = torch.relu(self.i2h1(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h12h2(x)) # relu activation @ hidden layer\n",
        "                x = torch.relu(self.h22h3(x)) # relu activation @ hidden layer\n",
        "                x = torch.sigmoid(self.h32o(x)) # sigmoid activation @ output layer\n",
        "                return x\n",
        "\n",
        "        num_of_input = VOCAB_SIZE # Bag word restriction has to be equal to vocabulary\n",
        "        num_of_hidden1 = 30\n",
        "        num_of_hidden2 = 20\n",
        "        num_of_hidden3 = 10\n",
        "        num_of_output = 1 # binary sentiment classes (+ve, -ve)\n",
        "\n",
        "        bow = BOWClassifier(num_of_input, num_of_hidden1, num_of_hidden2, num_of_hidden3, num_of_output).to('cuda:0') # initialises weights and biases\n",
        "        \n",
        "        # define a loss function and \n",
        "        loss_function = nn.HingeEmbeddingLoss()\n",
        "        \n",
        "    # define an optimizer\n",
        "    if(loss_fun == 'ce'):\n",
        "        opt = torch.optim.SGD(bow.parameters(), lr = 0.0001)\n",
        "    elif(loss_fun == 'mse'):\n",
        "        opt = torch.optim.SGD(bow.parameters(), lr = 0.0003)\n",
        "    elif(loss_fun == 'hinge'):\n",
        "        opt = torch.optim.SGD(bow.parameters(), lr = 0.01)\n",
        "    gc.collect()\n",
        "\n",
        "    # Train The Model\n",
        "    epochs = 100\n",
        "    # the training loop\n",
        "    total_time = 0.0\n",
        "    prev_val_loss = float('inf')\n",
        "    val_loss = 0\n",
        "    early_stop_bow = 0\n",
        "\n",
        "    for e in range(epochs):\n",
        "        tic = time.time() # start the timer\n",
        "        correct = 0\n",
        "        cumulative_loss = 0\n",
        "        incorrect = 0\n",
        "\n",
        "        for i, instance in enumerate(train_data): # train_text_reviews \n",
        "            # get the training data\n",
        "            label = train_text_labels[i] # get the label of the corresponding instace\n",
        "            label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "            bow.zero_grad() # reset the gradient for each instance\n",
        "\n",
        "            pred = bow.forward(instance)\n",
        "\n",
        "            loss = loss_function(pred, label) # compute the loss\n",
        "            loss.backward() # backprop the loss\n",
        "            opt.step() # performs parameter updation based on the current gradient\n",
        "\n",
        "            cumulative_loss += float(loss.item()) # accumulate the loss over whole training sample\n",
        "\n",
        "            pred_class = 1 if pred.item() > 0.5 else 0 # as sigmoid activated\n",
        "            if(int(label) == pred_class): # counting correct prediction in each epoch\n",
        "                correct += 1\n",
        "\n",
        "        train_loss = float(cumulative_loss)/num_train_data\n",
        "        train_accuracy = correct*float(100)/num_train_data\n",
        "\n",
        "#         val_loss, val_accuracy, p, r, f = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "        val_loss = evaluate_validation_accuracy(val_data, bow) # test val-data-set on currently trained model\n",
        "\n",
        "        if(prev_val_loss-val_loss < 0.0): # early stop if nearly no change\n",
        "            bow = copy.deepcopy(early_stop_bow)\n",
        "            break\n",
        "\n",
        "        early_stop_bow = copy.deepcopy(bow)\n",
        "\n",
        "        prev_val_loss = val_loss\n",
        "\n",
        "        toc = time.time() # final time\n",
        "        total_time += (toc-tic)\n",
        "\n",
        "        print(\"Epoch {}/{}\\n[On Training] ==> Time: {:.2f}s, Train Loss: {:.9f}, Train Accuracy: {:.2f}%\".format(e+1, epochs, (toc-tic), train_loss, train_accuracy))\n",
        "#         print(\"[On Validation] ==> Precision: {:.3f}, Recall: {:.3f}, F-Score: {:.3f}, Val loss: {:.9f}, Val Accuracy: {:.2f}% Total Time: {:.2f}s\".format(p, r, f, val_loss, val_accuracy, total_time))\n",
        "        print(\"[On Validation] ==> Val loss: {:.9f}, Total Time: {:.2f}s\".format(val_loss, total_time))\n",
        "\n",
        "    torch.save(bow, task_name)\n",
        "    \n",
        "    print('--- AFTER TRAINING ---\\tModel: {}'.format(task_name))\n",
        "    correct = 0\n",
        "    tic = time.time()\n",
        "    for i, instance in enumerate(data_test):\n",
        "        label = test_text_labels[i] # get the label of the corresponding instace\n",
        "        label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "\n",
        "        pred = bow.forward(instance)\n",
        "        pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "\n",
        "        if(int(label) == pred_class):\n",
        "            correct += 1\n",
        "    toc = time.time()\n",
        "    print(\"[On Testing] Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))\n",
        "\n",
        "    print(\"\\n\")"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "[On Training] ==> Time: 31.21s, Train Loss: 0.694767215, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.693907171, Total Time: 31.21s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 31.66s, Train Loss: 0.693389675, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.692973473, Total Time: 62.87s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 32.71s, Train Loss: 0.692659883, Train Accuracy: 50.04%\n",
            "[On Validation] ==> Val loss: 0.692368075, Total Time: 95.59s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 32.01s, Train Loss: 0.692084617, Train Accuracy: 51.22%\n",
            "[On Validation] ==> Val loss: 0.691792813, Total Time: 127.60s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 32.12s, Train Loss: 0.691481333, Train Accuracy: 56.62%\n",
            "[On Validation] ==> Val loss: 0.691124821, Total Time: 159.72s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 30.84s, Train Loss: 0.690742162, Train Accuracy: 62.57%\n",
            "[On Validation] ==> Val loss: 0.690270678, Total Time: 190.57s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.08s, Train Loss: 0.689755137, Train Accuracy: 66.46%\n",
            "[On Validation] ==> Val loss: 0.689115704, Total Time: 221.65s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.66s, Train Loss: 0.688349802, Train Accuracy: 68.33%\n",
            "[On Validation] ==> Val loss: 0.687378670, Total Time: 253.31s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 31.26s, Train Loss: 0.686079432, Train Accuracy: 69.51%\n",
            "[On Validation] ==> Val loss: 0.684424669, Total Time: 284.57s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 31.70s, Train Loss: 0.682300931, Train Accuracy: 70.14%\n",
            "[On Validation] ==> Val loss: 0.679790312, Total Time: 316.27s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 31.05s, Train Loss: 0.676687604, Train Accuracy: 71.29%\n",
            "[On Validation] ==> Val loss: 0.673053866, Total Time: 347.32s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 31.43s, Train Loss: 0.668098983, Train Accuracy: 72.46%\n",
            "[On Validation] ==> Val loss: 0.662496956, Total Time: 378.75s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 31.48s, Train Loss: 0.654313671, Train Accuracy: 73.87%\n",
            "[On Validation] ==> Val loss: 0.645443142, Total Time: 410.23s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 31.65s, Train Loss: 0.632220966, Train Accuracy: 75.78%\n",
            "[On Validation] ==> Val loss: 0.618577530, Total Time: 441.88s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 31.39s, Train Loss: 0.598201746, Train Accuracy: 77.99%\n",
            "[On Validation] ==> Val loss: 0.578972436, Total Time: 473.27s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 31.18s, Train Loss: 0.549723354, Train Accuracy: 80.70%\n",
            "[On Validation] ==> Val loss: 0.526750825, Total Time: 504.45s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 30.88s, Train Loss: 0.489710230, Train Accuracy: 82.98%\n",
            "[On Validation] ==> Val loss: 0.470252169, Total Time: 535.33s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 30.85s, Train Loss: 0.429002372, Train Accuracy: 84.60%\n",
            "[On Validation] ==> Val loss: 0.422607613, Total Time: 566.18s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 31.82s, Train Loss: 0.377376308, Train Accuracy: 86.10%\n",
            "[On Validation] ==> Val loss: 0.388394738, Total Time: 598.00s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 32.54s, Train Loss: 0.335577039, Train Accuracy: 87.60%\n",
            "[On Validation] ==> Val loss: 0.365006846, Total Time: 630.54s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 32.11s, Train Loss: 0.301345689, Train Accuracy: 88.95%\n",
            "[On Validation] ==> Val loss: 0.349208662, Total Time: 662.65s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 31.38s, Train Loss: 0.272979760, Train Accuracy: 90.16%\n",
            "[On Validation] ==> Val loss: 0.339509051, Total Time: 694.04s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 31.13s, Train Loss: 0.249292713, Train Accuracy: 90.96%\n",
            "[On Validation] ==> Val loss: 0.334336225, Total Time: 725.17s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 32.24s, Train Loss: 0.228966995, Train Accuracy: 91.81%\n",
            "[On Validation] ==> Val loss: 0.332504831, Total Time: 757.40s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\tModel: Task7A.mdl\n",
            "[On Testing] Time: 2.860544443130493, Test Accuracy: 87.52%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 31.02s, Train Loss: 0.250621006, Train Accuracy: 50.03%\n",
            "[On Validation] ==> Val loss: 0.250113133, Total Time: 31.02s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 30.89s, Train Loss: 0.249846335, Train Accuracy: 50.04%\n",
            "[On Validation] ==> Val loss: 0.249615604, Total Time: 61.91s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 31.00s, Train Loss: 0.249405547, Train Accuracy: 52.49%\n",
            "[On Validation] ==> Val loss: 0.249171863, Total Time: 92.91s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 31.53s, Train Loss: 0.248906647, Train Accuracy: 61.12%\n",
            "[On Validation] ==> Val loss: 0.248571691, Total Time: 124.43s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 30.82s, Train Loss: 0.248160170, Train Accuracy: 66.38%\n",
            "[On Validation] ==> Val loss: 0.247620425, Total Time: 155.26s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 30.96s, Train Loss: 0.246818637, Train Accuracy: 69.01%\n",
            "[On Validation] ==> Val loss: 0.245703773, Total Time: 186.21s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 31.13s, Train Loss: 0.244030642, Train Accuracy: 70.32%\n",
            "[On Validation] ==> Val loss: 0.241944227, Total Time: 217.34s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 31.17s, Train Loss: 0.238879201, Train Accuracy: 72.19%\n",
            "[On Validation] ==> Val loss: 0.235068884, Total Time: 248.51s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 31.99s, Train Loss: 0.228914587, Train Accuracy: 74.36%\n",
            "[On Validation] ==> Val loss: 0.221677980, Total Time: 280.50s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 30.73s, Train Loss: 0.210412011, Train Accuracy: 77.51%\n",
            "[On Validation] ==> Val loss: 0.198539459, Total Time: 311.22s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 32.35s, Train Loss: 0.181533090, Train Accuracy: 81.05%\n",
            "[On Validation] ==> Val loss: 0.167470984, Total Time: 343.58s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 32.03s, Train Loss: 0.148774451, Train Accuracy: 83.87%\n",
            "[On Validation] ==> Val loss: 0.140139426, Total Time: 375.61s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 31.95s, Train Loss: 0.122731815, Train Accuracy: 85.76%\n",
            "[On Validation] ==> Val loss: 0.122807379, Total Time: 407.56s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 32.06s, Train Loss: 0.104399513, Train Accuracy: 87.50%\n",
            "[On Validation] ==> Val loss: 0.112346235, Total Time: 439.62s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 31.45s, Train Loss: 0.090861791, Train Accuracy: 89.07%\n",
            "[On Validation] ==> Val loss: 0.105841996, Total Time: 471.07s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 31.11s, Train Loss: 0.080360328, Train Accuracy: 90.39%\n",
            "[On Validation] ==> Val loss: 0.101769663, Total Time: 502.18s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 31.13s, Train Loss: 0.072015344, Train Accuracy: 91.61%\n",
            "[On Validation] ==> Val loss: 0.099005241, Total Time: 533.30s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 31.32s, Train Loss: 0.065160711, Train Accuracy: 92.42%\n",
            "[On Validation] ==> Val loss: 0.096965394, Total Time: 564.62s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 31.52s, Train Loss: 0.059334658, Train Accuracy: 93.32%\n",
            "[On Validation] ==> Val loss: 0.095604905, Total Time: 596.14s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 31.30s, Train Loss: 0.054173599, Train Accuracy: 93.92%\n",
            "[On Validation] ==> Val loss: 0.094958182, Total Time: 627.45s\n",
            "--- AFTER TRAINING ---\tModel: Task7B.mdl\n",
            "[On Testing] Time: 2.804802179336548, Test Accuracy: 87.38%\n",
            "\n",
            "\n",
            "Epoch 1/100\n",
            "[On Training] ==> Time: 36.95s, Train Loss: 0.511422329, Train Accuracy: 49.95%\n",
            "[On Validation] ==> Val loss: 0.499894099, Total Time: 36.95s\n",
            "Epoch 2/100\n",
            "[On Training] ==> Time: 37.68s, Train Loss: 0.499794435, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499797137, Total Time: 74.63s\n",
            "Epoch 3/100\n",
            "[On Training] ==> Time: 36.85s, Train Loss: 0.499744041, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499769294, Total Time: 111.48s\n",
            "Epoch 4/100\n",
            "[On Training] ==> Time: 37.25s, Train Loss: 0.499726118, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499756292, Total Time: 148.73s\n",
            "Epoch 5/100\n",
            "[On Training] ==> Time: 38.77s, Train Loss: 0.499717023, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499748815, Total Time: 187.50s\n",
            "Epoch 6/100\n",
            "[On Training] ==> Time: 37.77s, Train Loss: 0.499711565, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499743977, Total Time: 225.27s\n",
            "Epoch 7/100\n",
            "[On Training] ==> Time: 38.72s, Train Loss: 0.499707944, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499740600, Total Time: 263.99s\n",
            "Epoch 8/100\n",
            "[On Training] ==> Time: 37.43s, Train Loss: 0.499705376, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499738113, Total Time: 301.42s\n",
            "Epoch 9/100\n",
            "[On Training] ==> Time: 37.49s, Train Loss: 0.499703466, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499736208, Total Time: 338.91s\n",
            "Epoch 10/100\n",
            "[On Training] ==> Time: 37.56s, Train Loss: 0.499701992, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499734704, Total Time: 376.47s\n",
            "Epoch 11/100\n",
            "[On Training] ==> Time: 37.15s, Train Loss: 0.499700823, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499733487, Total Time: 413.62s\n",
            "Epoch 12/100\n",
            "[On Training] ==> Time: 37.20s, Train Loss: 0.499699874, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499732482, Total Time: 450.82s\n",
            "Epoch 13/100\n",
            "[On Training] ==> Time: 37.14s, Train Loss: 0.499699090, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499731640, Total Time: 487.96s\n",
            "Epoch 14/100\n",
            "[On Training] ==> Time: 37.35s, Train Loss: 0.499698430, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499730924, Total Time: 525.31s\n",
            "Epoch 15/100\n",
            "[On Training] ==> Time: 37.84s, Train Loss: 0.499697870, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499730307, Total Time: 563.15s\n",
            "Epoch 16/100\n",
            "[On Training] ==> Time: 37.30s, Train Loss: 0.499697387, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499729771, Total Time: 600.45s\n",
            "Epoch 17/100\n",
            "[On Training] ==> Time: 37.12s, Train Loss: 0.499696967, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499729301, Total Time: 637.57s\n",
            "Epoch 18/100\n",
            "[On Training] ==> Time: 38.27s, Train Loss: 0.499696599, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499728886, Total Time: 675.83s\n",
            "Epoch 19/100\n",
            "[On Training] ==> Time: 38.28s, Train Loss: 0.499696274, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499728516, Total Time: 714.11s\n",
            "Epoch 20/100\n",
            "[On Training] ==> Time: 38.04s, Train Loss: 0.499695984, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499728185, Total Time: 752.15s\n",
            "Epoch 21/100\n",
            "[On Training] ==> Time: 37.21s, Train Loss: 0.499695726, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499727887, Total Time: 789.36s\n",
            "Epoch 22/100\n",
            "[On Training] ==> Time: 37.07s, Train Loss: 0.499695493, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499727617, Total Time: 826.43s\n",
            "Epoch 23/100\n",
            "[On Training] ==> Time: 37.77s, Train Loss: 0.499695282, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499727372, Total Time: 864.21s\n",
            "Epoch 24/100\n",
            "[On Training] ==> Time: 36.97s, Train Loss: 0.499695090, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499727148, Total Time: 901.17s\n",
            "Epoch 25/100\n",
            "[On Training] ==> Time: 36.91s, Train Loss: 0.499694916, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726942, Total Time: 938.09s\n",
            "Epoch 26/100\n",
            "[On Training] ==> Time: 37.25s, Train Loss: 0.499694756, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726753, Total Time: 975.33s\n",
            "Epoch 27/100\n",
            "[On Training] ==> Time: 37.47s, Train Loss: 0.499694609, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726579, Total Time: 1012.80s\n",
            "Epoch 28/100\n",
            "[On Training] ==> Time: 36.85s, Train Loss: 0.499694473, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726417, Total Time: 1049.66s\n",
            "Epoch 29/100\n",
            "[On Training] ==> Time: 36.62s, Train Loss: 0.499694348, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726268, Total Time: 1086.28s\n",
            "Epoch 30/100\n",
            "[On Training] ==> Time: 36.55s, Train Loss: 0.499694232, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499726128, Total Time: 1122.83s\n",
            "Epoch 31/100\n",
            "[On Training] ==> Time: 36.59s, Train Loss: 0.499694124, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725998, Total Time: 1159.42s\n",
            "Epoch 32/100\n",
            "[On Training] ==> Time: 39.73s, Train Loss: 0.499694023, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725877, Total Time: 1199.15s\n",
            "Epoch 33/100\n",
            "[On Training] ==> Time: 38.17s, Train Loss: 0.499693929, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725763, Total Time: 1237.32s\n",
            "Epoch 34/100\n",
            "[On Training] ==> Time: 37.42s, Train Loss: 0.499693841, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725656, Total Time: 1274.74s\n",
            "Epoch 35/100\n",
            "[On Training] ==> Time: 37.34s, Train Loss: 0.499693758, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725555, Total Time: 1312.08s\n",
            "Epoch 36/100\n",
            "[On Training] ==> Time: 36.84s, Train Loss: 0.499693681, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725461, Total Time: 1348.93s\n",
            "Epoch 37/100\n",
            "[On Training] ==> Time: 36.64s, Train Loss: 0.499693608, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725371, Total Time: 1385.56s\n",
            "Epoch 38/100\n",
            "[On Training] ==> Time: 36.79s, Train Loss: 0.499693539, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725287, Total Time: 1422.35s\n",
            "Epoch 39/100\n",
            "[On Training] ==> Time: 36.46s, Train Loss: 0.499693474, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725207, Total Time: 1458.81s\n",
            "Epoch 40/100\n",
            "[On Training] ==> Time: 37.49s, Train Loss: 0.499693413, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725131, Total Time: 1496.30s\n",
            "Epoch 41/100\n",
            "[On Training] ==> Time: 36.66s, Train Loss: 0.499693354, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499725059, Total Time: 1532.96s\n",
            "Epoch 42/100\n",
            "[On Training] ==> Time: 36.85s, Train Loss: 0.499693299, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724990, Total Time: 1569.81s\n",
            "Epoch 43/100\n",
            "[On Training] ==> Time: 37.30s, Train Loss: 0.499693247, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724925, Total Time: 1607.11s\n",
            "Epoch 44/100\n",
            "[On Training] ==> Time: 36.85s, Train Loss: 0.499693197, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724863, Total Time: 1643.96s\n",
            "Epoch 45/100\n",
            "[On Training] ==> Time: 36.62s, Train Loss: 0.499693149, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724804, Total Time: 1680.58s\n",
            "Epoch 46/100\n",
            "[On Training] ==> Time: 38.73s, Train Loss: 0.499693104, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724748, Total Time: 1719.30s\n",
            "Epoch 47/100\n",
            "[On Training] ==> Time: 38.43s, Train Loss: 0.499693061, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724694, Total Time: 1757.74s\n",
            "Epoch 48/100\n",
            "[On Training] ==> Time: 38.22s, Train Loss: 0.499693020, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724642, Total Time: 1795.96s\n",
            "Epoch 49/100\n",
            "[On Training] ==> Time: 36.94s, Train Loss: 0.499692980, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724592, Total Time: 1832.90s\n",
            "Epoch 50/100\n",
            "[On Training] ==> Time: 36.56s, Train Loss: 0.499692943, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724545, Total Time: 1869.46s\n",
            "Epoch 51/100\n",
            "[On Training] ==> Time: 37.05s, Train Loss: 0.499692906, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724500, Total Time: 1906.51s\n",
            "Epoch 52/100\n",
            "[On Training] ==> Time: 36.54s, Train Loss: 0.499692872, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724456, Total Time: 1943.05s\n",
            "Epoch 53/100\n",
            "[On Training] ==> Time: 36.66s, Train Loss: 0.499692839, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724414, Total Time: 1979.71s\n",
            "Epoch 54/100\n",
            "[On Training] ==> Time: 36.50s, Train Loss: 0.499692807, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724374, Total Time: 2016.21s\n",
            "Epoch 55/100\n",
            "[On Training] ==> Time: 35.93s, Train Loss: 0.499692776, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724335, Total Time: 2052.14s\n",
            "Epoch 56/100\n",
            "[On Training] ==> Time: 35.93s, Train Loss: 0.499692747, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724297, Total Time: 2088.06s\n",
            "Epoch 57/100\n",
            "[On Training] ==> Time: 36.77s, Train Loss: 0.499692718, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724261, Total Time: 2124.83s\n",
            "Epoch 58/100\n",
            "[On Training] ==> Time: 35.82s, Train Loss: 0.499692691, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724227, Total Time: 2160.65s\n",
            "Epoch 59/100\n",
            "[On Training] ==> Time: 35.89s, Train Loss: 0.499692665, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724193, Total Time: 2196.53s\n",
            "Epoch 60/100\n",
            "[On Training] ==> Time: 36.80s, Train Loss: 0.499692639, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724161, Total Time: 2233.34s\n",
            "Epoch 61/100\n",
            "[On Training] ==> Time: 39.44s, Train Loss: 0.499692615, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724130, Total Time: 2272.78s\n",
            "Epoch 62/100\n",
            "[On Training] ==> Time: 38.18s, Train Loss: 0.499692591, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724099, Total Time: 2310.96s\n",
            "Epoch 63/100\n",
            "[On Training] ==> Time: 37.04s, Train Loss: 0.499692569, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724070, Total Time: 2348.00s\n",
            "Epoch 64/100\n",
            "[On Training] ==> Time: 36.32s, Train Loss: 0.499692547, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724042, Total Time: 2384.32s\n",
            "Epoch 65/100\n",
            "[On Training] ==> Time: 37.19s, Train Loss: 0.499692525, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499724015, Total Time: 2421.51s\n",
            "Epoch 66/100\n",
            "[On Training] ==> Time: 36.29s, Train Loss: 0.499692505, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723988, Total Time: 2457.80s\n",
            "Epoch 67/100\n",
            "[On Training] ==> Time: 36.41s, Train Loss: 0.499692485, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723963, Total Time: 2494.21s\n",
            "Epoch 68/100\n",
            "[On Training] ==> Time: 36.98s, Train Loss: 0.499692465, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723938, Total Time: 2531.19s\n",
            "Epoch 69/100\n",
            "[On Training] ==> Time: 36.50s, Train Loss: 0.499692447, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723914, Total Time: 2567.69s\n",
            "Epoch 70/100\n",
            "[On Training] ==> Time: 36.39s, Train Loss: 0.499692429, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723890, Total Time: 2604.09s\n",
            "Epoch 71/100\n",
            "[On Training] ==> Time: 36.33s, Train Loss: 0.499692411, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723867, Total Time: 2640.42s\n",
            "Epoch 72/100\n",
            "[On Training] ==> Time: 36.24s, Train Loss: 0.499692394, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723845, Total Time: 2676.66s\n",
            "Epoch 73/100\n",
            "[On Training] ==> Time: 36.64s, Train Loss: 0.499692377, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723824, Total Time: 2713.30s\n",
            "Epoch 74/100\n",
            "[On Training] ==> Time: 38.85s, Train Loss: 0.499692361, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723803, Total Time: 2752.15s\n",
            "Epoch 75/100\n",
            "[On Training] ==> Time: 38.66s, Train Loss: 0.499692346, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723783, Total Time: 2790.80s\n",
            "Epoch 76/100\n",
            "[On Training] ==> Time: 37.98s, Train Loss: 0.499692331, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723763, Total Time: 2828.78s\n",
            "Epoch 77/100\n",
            "[On Training] ==> Time: 37.11s, Train Loss: 0.499692316, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723744, Total Time: 2865.89s\n",
            "Epoch 78/100\n",
            "[On Training] ==> Time: 36.86s, Train Loss: 0.499692301, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723725, Total Time: 2902.75s\n",
            "Epoch 79/100\n",
            "[On Training] ==> Time: 36.82s, Train Loss: 0.499692288, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723707, Total Time: 2939.57s\n",
            "Epoch 80/100\n",
            "[On Training] ==> Time: 36.59s, Train Loss: 0.499692274, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723689, Total Time: 2976.16s\n",
            "Epoch 81/100\n",
            "[On Training] ==> Time: 36.66s, Train Loss: 0.499692261, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723672, Total Time: 3012.82s\n",
            "Epoch 82/100\n",
            "[On Training] ==> Time: 37.33s, Train Loss: 0.499692248, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723655, Total Time: 3050.15s\n",
            "Epoch 83/100\n",
            "[On Training] ==> Time: 36.74s, Train Loss: 0.499692235, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723639, Total Time: 3086.89s\n",
            "Epoch 84/100\n",
            "[On Training] ==> Time: 37.11s, Train Loss: 0.499692223, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723623, Total Time: 3124.00s\n",
            "Epoch 85/100\n",
            "[On Training] ==> Time: 36.48s, Train Loss: 0.499692211, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723607, Total Time: 3160.48s\n",
            "Epoch 86/100\n",
            "[On Training] ==> Time: 36.44s, Train Loss: 0.499692200, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723592, Total Time: 3196.92s\n",
            "Epoch 87/100\n",
            "[On Training] ==> Time: 36.59s, Train Loss: 0.499692188, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723577, Total Time: 3233.51s\n",
            "Epoch 88/100\n",
            "[On Training] ==> Time: 36.70s, Train Loss: 0.499692177, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723563, Total Time: 3270.21s\n",
            "Epoch 89/100\n",
            "[On Training] ==> Time: 39.17s, Train Loss: 0.499692166, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723549, Total Time: 3309.38s\n",
            "Epoch 90/100\n",
            "[On Training] ==> Time: 38.62s, Train Loss: 0.499692156, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723535, Total Time: 3348.00s\n",
            "Epoch 91/100\n",
            "[On Training] ==> Time: 36.97s, Train Loss: 0.499692146, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723521, Total Time: 3384.97s\n",
            "Epoch 92/100\n",
            "[On Training] ==> Time: 36.44s, Train Loss: 0.499692136, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723508, Total Time: 3421.40s\n",
            "Epoch 93/100\n",
            "[On Training] ==> Time: 37.10s, Train Loss: 0.499692126, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723495, Total Time: 3458.51s\n",
            "Epoch 94/100\n",
            "[On Training] ==> Time: 36.22s, Train Loss: 0.499692116, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723483, Total Time: 3494.73s\n",
            "Epoch 95/100\n",
            "[On Training] ==> Time: 36.24s, Train Loss: 0.499692107, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723470, Total Time: 3530.96s\n",
            "Epoch 96/100\n",
            "[On Training] ==> Time: 36.23s, Train Loss: 0.499692098, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723458, Total Time: 3567.19s\n",
            "Epoch 97/100\n",
            "[On Training] ==> Time: 36.27s, Train Loss: 0.499692089, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723446, Total Time: 3603.46s\n",
            "Epoch 98/100\n",
            "[On Training] ==> Time: 38.12s, Train Loss: 0.499692080, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723435, Total Time: 3641.58s\n",
            "Epoch 99/100\n",
            "[On Training] ==> Time: 37.19s, Train Loss: 0.499692071, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723423, Total Time: 3678.78s\n",
            "Epoch 100/100\n",
            "[On Training] ==> Time: 36.65s, Train Loss: 0.499692063, Train Accuracy: 49.97%\n",
            "[On Validation] ==> Val loss: 0.499723412, Total Time: 3715.43s\n",
            "--- AFTER TRAINING ---\tModel: Task7C.mdl\n",
            "[On Testing] Time: 2.851572275161743, Test Accuracy: 49.64%\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "00HZEnQGGKYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download('Task7A.mdl')\n",
        "files.download('Task7B.mdl')\n",
        "files.download('Task7C.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FDUyFfwmXSew",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# plt.figure(\"Image\")\n",
        "# plt.title(\"Loss vs Epoch\")\n",
        "# val_loss_history_plt =  [float(i)/sum(val_loss_history) for i in val_loss_history] # normalised between 0-1\n",
        "# train_loss_history_plt =  [float(i)/sum(train_loss_history) for i in train_loss_history] # normalised between 0-1\n",
        "# f_score_plt = [float(i)/sum(f_score) for i in f_score] # normalised between 0-1\n",
        "# plt.plot(val_loss_history_plt, c=\"red\", label=\"Validation Loss\")\n",
        "# plt.plot(train_loss_history_plt, c=\"blue\", label = \"Training Loss\")\n",
        "# plt.plot(f_score_plt, c=\"green\", label = \"F-Score\")\n",
        "# plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zz5PwYjVudEk",
        "colab_type": "code",
        "outputId": "b827a586-3ef1-4a92-8a95-3bbf68dabc54",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7063ed6b-ee9a-4382-bd21-300e434055d5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-7063ed6b-ee9a-4382-bd21-300e434055d5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Task3A.mdl to Task3A.mdl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "29twCfxpuc8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# _model_ = torch.load(io.BytesIO(temp_test['Task2C.mdl']))\n",
        "_model_ = torch.load('Task5C.mdl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ixy30WkrH3_-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for params in _model_.parameters():\n",
        "#     print (params)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ffYv5PAmjyp-",
        "colab_type": "code",
        "outputId": "12c75d6c-19bc-40e1-b61c-751576ec467b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "correct = 0\n",
        "tic = time.time()\n",
        "for i, instance in enumerate(data_test):\n",
        "    label = test_text_labels[i] # get the label of the corresponding instace\n",
        "    label = Variable(torch.FloatTensor([label])).resize_((1,1)).to('cuda:0') # wraps a tensor for label\n",
        "    \n",
        "    pred = _model_.forward(instance)\n",
        "    pred_class = 1 if pred.item() > 0.5 else 0 # sigmoid activated\n",
        "    \n",
        "    if(int(label) == pred_class):\n",
        "        correct += 1\n",
        "toc = time.time()\n",
        "print(\"Time: {}, Test Accuracy: {:.2f}%\".format((toc-tic), correct*100/len(data_test)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n",
            "Time: 2.400538921356201, Test Accuracy: 87.58%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hBL6jT8ReP6p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# predict on test dataset\n",
        "# with open(\"Task1A.csv\", \"wb\") as _f:\n",
        "#     writer = csv.writer(_f)\n",
        "#     writer.writerows(a)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0VkVoMzMUdeh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "np.save('vocab.npy', word_to_ix)\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"vocab.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ub0HKgL8H37z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lCraW41hH32S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mhftDt1DH3x6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kE_TcX1KH3tQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T60wqxmoH3Zl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}