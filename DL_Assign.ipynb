{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Assign.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/DL_Assign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "wuB0HM37teAc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "_NV6CE-qtvGO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import Header Files"
      ]
    },
    {
      "metadata": {
        "id": "WE7OEcPOtzJf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import io"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v4037ccUuFFp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the Dataset and Visualise"
      ]
    },
    {
      "metadata": {
        "id": "EhWFepP2t3eA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_train = pd.read_csv(io.StringIO(uploaded['Train_20K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_train.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/Train_20K.csv?token=As1EmHVd_04h8pxz2Rr5aHldCB3DdRV1ks5cn3UowA%3D%3D\"\n",
        "df_train = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "T9FBTqABuRlO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_val = pd.read_csv(io.StringIO(uploaded['check.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_val.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/check.csv?token=As1EmGDbgpndOWYhmX4VqD7m4N3zVaa0ks5cn3UrwA%3D%3D\"\n",
        "df_val = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uuZxOMpkQoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# import io\n",
        "# df_test = pd.read_csv(io.StringIO(uploaded['Test_5K.csv'].decode('utf-8')), sep='\\t')\n",
        "# df_test.head()\n",
        "url = \"https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/Test_5K.csv?token=As1EmLgiSJtng6_pWA552sBVIdXROwEgks5cn3XOwA%3D%3D\"\n",
        "df_test = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0WFB1TtsxD3F",
        "colab_type": "code",
        "outputId": "07030131-5efb-47ac-80bf-74ad29254b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df_train[df_train['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df_train[df_train['label']==1]))\n",
        "print('Number of movie reviews', len(df_train['label']))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 8994\n",
            "Number of Positive movie reviews 9005\n",
            "Number of movie reviews 17999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TVzhPcGGxf2-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data pre-processing"
      ]
    },
    {
      "metadata": {
        "id": "JprKnOXgxXkE",
        "colab_type": "code",
        "outputId": "31f94f5b-2d66-4319-99c9-400f837daa8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "raw_text_reviews = df_train['text'].astype(str).tolist()\n",
        "len(raw_text_reviews), raw_text_reviews[-2]"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999,\n",
              " 'Anyone notice that Tommy only has 3 facial expressions.<br /><br />1. The angry eyes look he gives every enemy. 2. The holding of the hands to face, mouth agape and frightened eyes. 3. The smiling Tommy Turnbull.<br /><br />I have to say that i pretty much hate this show, i don\\'t watch it but it\\'s like Code Lyoko, we\\'ve all watched at least one, i must say that this show is borderline racist, uninteresting and pointless.<br /><br />every episode ends with robotboy winning, except for one exception when robotboy basically let this overly geeky freakazoid fly away on a jetpack.<br /><br />The jokes are pretty crude too, i think it\\'s mostly people saying the word \"Suck\" or farting, i think the bullies of the show are quite shocking too.<br /><br />Isn\\'t there one that hides a bowling ball under his hate, and the other uses a chain, for god sake, what kind of school is he going to. Not to mention his older brother, who is borderline psychopathic and has no other character qualities.<br /><br />The whole show i feel is ripping off megas XLR and Fosters. Like you could say the trio of coop, jamie and Kiva, as well as Robotboy being similar to Megas where he beats everyone no matter what the odds and he\\'s free spirited despite being a robot.<br /><br />There is simply no appeal to this show, i\\'m surprised that it\\'s still running.')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "6pyMLy0NyHVx",
        "colab_type": "code",
        "outputId": "06481fca-224b-40d1-c6bf-a9c18c88612a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_labels = df_train['label'].astype(int)\n",
        "len(train_text_labels), train_text_labels[len(train_text_labels)-2]"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17999, 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "metadata": {
        "id": "s3AxEhD_z1DM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "def preprocess_document(doc):\n",
        "  # negative sense should not be eleminated + some short representation\n",
        "  CONTRACTIONS = {\"mayn't\":\"may not\", \"can't\":\"can not\", \"won't\":\"will not\", \"isn't\":\"is not\", \"amn't\":\"am not\",\\\n",
        "                  \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\", \"couldn't\":\"could not\", \\\n",
        "                  \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\\\n",
        "                  \"i'll\":\"i will\", \"you'll\":\"you will\", \"they'll\":\"they have\",\\\n",
        "                  \"may've\":\"may have\", \"can've\":\"can have\", \"will've\":\"will have\", \"you've\":\"you have\", \\\n",
        "                  \"could've\":\"could have\", \"would've\":\"would have\", \"they\":\"they have\",\\\n",
        "                  \"i've\":\"i have\", \"you've\":\"you have\", \"we've\":\"we have\", \"there's\":\"there is\", \"i'am\":\"i am\", \"it's\":\"it is\"}\n",
        "  punctuation = string.punctuation + \"\\n\\n\"\n",
        "  punc_replace = ''.join([' ' for s in punctuation]); # required for replacing punctuation with null ('')\n",
        "  doc_clean = doc.replace('-', ' '); # replace - with null str\n",
        "  doc_clean = (doc_clean.encode('ascii', 'ignore')).decode(\"utf-8\")\n",
        "  doc_clean = doc_clean.replace('<br />', ''); # replace <br /> with ''\n",
        "  doc_clean = doc_clean.replace(\"â€™\", \"'\"); # replace <br /> with null str\n",
        "  doc_clean = [CONTRACTIONS[word] if word in CONTRACTIONS else word for word in doc_clean.split(' ')] # replacing some common short forms\n",
        "  doc_clean = \" \".join(doc_clean) # list to sentence of strings\n",
        "  doc_clean = re.sub(r'\\W +', ' ', doc_clean) # except [a-zA-Z0-9_]\n",
        "  doc_clean = re.sub(r'\\d+', ' ', doc_clean) # remove numbers [0-9]\n",
        "  trans_table = str.maketrans(punctuation, punc_replace); # replace punctuations with ' '\n",
        "  doc_clean = ' '.join([word.translate(trans_table) for word in doc_clean.split(' ')]);\n",
        "  doc_clean = doc_clean.split(' ');\n",
        "  doc_clean = [word for word in doc_clean if len(word) > 0];\n",
        "\n",
        "  return doc_clean;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rSNuXUopzavX",
        "colab_type": "code",
        "outputId": "13a01d44-ce1b-4a48-cf45-c4de4e96db7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "train_text_reviews = [preprocess_document(review.lower()) for review in raw_text_reviews]\n",
        "print (train_text_reviews[len(train_text_reviews)-2])\n",
        "print (text_labels[len(text_labels)-2])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['anyone', 'notice', 'that', 'tommy', 'only', 'has', 'facial', 'expressions', 'the', 'angry', 'eyes', 'look', 'he', 'gives', 'every', 'enemy', 'the', 'holding', 'of', 'the', 'hands', 'to', 'face', 'mouth', 'agape', 'and', 'frightened', 'eyes', 'the', 'smiling', 'tommy', 'turnbull', 'i', 'have', 'to', 'say', 'that', 'i', 'pretty', 'much', 'hate', 'this', 'show', 'i', 'do', 'not', 'watch', 'it', 'but', 'it', 'is', 'like', 'code', 'lyoko', 'we', 'have', 'all', 'watched', 'at', 'least', 'one', 'i', 'must', 'say', 'that', 'this', 'show', 'is', 'borderline', 'racist', 'uninteresting', 'and', 'pointless', 'every', 'episode', 'ends', 'with', 'robotboy', 'winning', 'except', 'for', 'one', 'exception', 'when', 'robotboy', 'basically', 'let', 'this', 'overly', 'geeky', 'freakazoid', 'fly', 'away', 'on', 'a', 'jetpack', 'the', 'jokes', 'are', 'pretty', 'crude', 'too', 'i', 'think', 'it', 'is', 'mostly', 'people', 'saying', 'the', 'word', 'suck', 'or', 'farting', 'i', 'think', 'the', 'bullies', 'of', 'the', 'show', 'are', 'quite', 'shocking', 'too', 'isn', 't', 'there', 'one', 'that', 'hides', 'a', 'bowling', 'ball', 'under', 'his', 'hate', 'and', 'the', 'other', 'uses', 'a', 'chain', 'for', 'god', 'sake', 'what', 'kind', 'of', 'school', 'is', 'he', 'going', 'to', 'not', 'to', 'mention', 'his', 'older', 'brother', 'who', 'is', 'borderline', 'psychopathic', 'and', 'has', 'no', 'other', 'character', 'qualities', 'the', 'whole', 'show', 'i', 'feel', 'is', 'ripping', 'off', 'megas', 'xlr', 'and', 'fosters', 'like', 'you', 'could', 'say', 'the', 'trio', 'of', 'coop', 'jamie', 'and', 'kiva', 'as', 'well', 'as', 'robotboy', 'being', 'similar', 'to', 'megas', 'where', 'he', 'beats', 'everyone', 'no', 'matter', 'what', 'the', 'odds', 'and', 'he', 's', 'free', 'spirited', 'despite', 'being', 'a', 'robot', 'there', 'is', 'simply', 'no', 'appeal', 'to', 'this', 'show', 'i', 'm', 'surprised', 'that', 'it', 'is', 'still', 'running']\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MKifaS85Dkap",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "dyQJIGVw4Dau",
        "colab_type": "code",
        "outputId": "3d34bd33-0b80-4094-89e3-b737479650d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Fetching the tokens (all words in a doc) and types(unique words in a doc) in the document\n",
        "types = ()\n",
        "tokens = []\n",
        "for row in train_text_reviews:\n",
        "    tokens += [words for words in row]\n",
        "types = set(tokens)\n",
        "\n",
        "VOCAB_SIZE, TOKEN_SIZE = len(types), len(tokens)\n",
        "VOCAB_SIZE, TOKEN_SIZE"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(65218, 4275850)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "metadata": {
        "id": "B20xEKK-Hwn7",
        "colab_type": "code",
        "outputId": "7602395c-d031-49cc-aede-62e9982e768d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = {x:i for i, x in enumerate(types)}\n",
        "ix_to_word = [x for i, x in enumerate(types)]\n",
        "\n",
        "ix_to_word[word_to_ix['kick']]=='kick', word_to_ix['kick'], len(ix_to_word)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 32089, 65218)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "metadata": {
        "id": "Tf9alcVgJSgM",
        "colab_type": "code",
        "outputId": "dfec43c2-d0d3-4bd0-81f0-a80927364ca6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "for i, (key, value) in enumerate(word_to_ix.items()):\n",
        "  if(i > 10):\n",
        "    break\n",
        "  print (key,':', value)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "vanesa : 0\n",
            "ignacio : 1\n",
            "specialty : 2\n",
            "arkham : 3\n",
            "bathhouses : 4\n",
            "muccino : 5\n",
            "aggravate : 6\n",
            "nudity : 7\n",
            "ssg : 8\n",
            "hitchhikers : 9\n",
            "alaska : 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yNUlKuJeNJEu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Intro to PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "SqLOymKPLPug",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable # for automatically implement backprop\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SaSwXEBh6565",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Model Definition for the BOWClassifier"
      ]
    },
    {
      "metadata": {
        "id": "PM5I4GP6lFGu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BOWClassifier(nn.Module):\n",
        "  def __init__(self, num_labels, vocab_size):\n",
        "    super(BOWClassifier, self).__init__()\n",
        "    SEED = 42\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    self.lin = nn.Linear(vocab_size, num_labels) # initialises weights and biases\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return F.softmax(self.lin(x), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sWqAwOAI7D54",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "UZK9TAQI7Fbm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1 # count the number of occurance of same word in a sentences\n",
        "            \n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label):\n",
        "    return torch.LongTensor([label])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MlMeX6577J9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "98e55d5c-09bb-4f04-f08e-3d9fa4eeaf08"
      },
      "cell_type": "code",
      "source": [
        "NUM_LABELS = 2\n",
        "bow = BOWClassifier(NUM_LABELS, VOCAB_SIZE) # initialises weights and biases\n",
        "bow.lin # desc linear layer"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=65218, out_features=2, bias=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "metadata": {
        "id": "PRhDPFx87Ptm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a2675ece-48f1-438e-d605-e064e8143101"
      },
      "cell_type": "code",
      "source": [
        "# visualise the parameter\n",
        "for param in bow.parameters(): # desc the parameter value\n",
        "    print(param,param.size())"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0030,  0.0033, -0.0009,  ..., -0.0018, -0.0014,  0.0025],\n",
            "        [-0.0028, -0.0018, -0.0008,  ...,  0.0033,  0.0018,  0.0016]],\n",
            "       requires_grad=True) torch.Size([2, 65218])\n",
            "Parameter containing:\n",
            "tensor([ 0.0021, -0.0028], requires_grad=True) torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "04LpXPa99z4v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's check with a sample case how our model is working"
      ]
    },
    {
      "metadata": {
        "id": "TQd4B8jo7o2l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "5ea34704-7e2a-446b-f9e3-e0fdb3f85732"
      },
      "cell_type": "code",
      "source": [
        "sample_data, sample_label = train_text_reviews[0], train_text_labels[0]\n",
        "bow_vector = torch.autograd.Variable(make_bow_vector(sample_data, word_to_ix))\n",
        "print (bow_vector)\n",
        "logprobs = bow.forward(bow_vector) # calls forward function\n",
        "print(train_text_reviews[0])\n",
        "print(logprobs.data)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "['john', 'waters', 'has', 'given', 'us', 'a', 'genuinely', 'enjoyable', 'film', 'this', 'certainly', 'is', 'not', 'without', 'its', 'shocking', 'waters', 'esque', 'moments', 'but', 'it', 'is', 'tamer', 'than', 'his', 'older', 'culty', 'stuff', 'such', 'as', 'pink', 'flamingoes', 'pecker', 'harkens', 'back', 'to', 'john', 's', 'early', 'mainstream', 'stage', 'in', 'that', 'it', 'reminds', 'the', 'viewer', 'of', 'the', 'same', 'kind', 'of', 'humor', 'that', 'was', 'evident', 'in', 'polyester', 'overall', 'a', 'really', 'fun', 'comedy', 'with', 'some', 'great', 'moments']\n",
            "tensor([[0.5013, 0.4987]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "REIlwRONHCox",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Testing with normal variable"
      ]
    },
    {
      "metadata": {
        "id": "p0zesRPzDjE2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "e6f5effb-55d4-4964-c842-655dea7ee3d3"
      },
      "cell_type": "code",
      "source": [
        "bow_vec = Variable(make_bow_vector(preprocess_document(df_train['text'][1].lower()), word_to_ix)) # encoding test data\n",
        "logprobs = bow(bow_vec) # call to forward\n",
        "print(logprobs)\n",
        "pred = np.argmax(logprobs.data.numpy())\n",
        "print('prediction: {}'.format(pred))\n",
        "print('actual: {}'.format(df_train['label'][0]))\n",
        "\n",
        "\n",
        "bow_vec = Variable(make_bow_vector(preprocess_document(df_train['text'][10].lower()), word_to_ix)) # encoding test data\n",
        "logprobs = bow(bow_vec) # call to forward\n",
        "print(logprobs)\n",
        "pred = np.argmax(logprobs.data.numpy())\n",
        "print('prediction: {}'.format(pred))\n",
        "print('actual: {}'.format(df_train['label'][0]))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5022, 0.4978]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: 0\n",
            "actual: 1\n",
            "tensor([[0.4940, 0.5060]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: 1\n",
            "actual: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nw0OYbTzBwJ8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Define Loss fun"
      ]
    },
    {
      "metadata": {
        "id": "PbQcwSIb96V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.NLLLoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tuYAAQh2F6J8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ]
    },
    {
      "metadata": {
        "id": "ad6MFVt7F5X8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# the training loop\n",
        "for epoch in range(1):\n",
        "  print(epoch)\n",
        "  for i, instance in enumerate(train_text_reviews):\n",
        "    # get the training data\n",
        "    label = train_text_labels[i]\n",
        "#     print ('actual label :', label)\n",
        "    bow.zero_grad()\n",
        "    bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "    label = Variable(make_target(label))\n",
        "#     print ('tensor actual label :', label)\n",
        "    probs = bow(bow_vec) # forward pass\n",
        "    print ('pred :', probs)\n",
        "    loss = loss_function(probs, label)\n",
        "    loss.backward()\n",
        "#     print('CURRENT LOSS: {}'.format(loss.data))\n",
        "    opt.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fkYBaktsF-sm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}