{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshsahu09/CS69002_9A_18CS60R19/blob/master/MLP_Tutorial_New.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "GvYHwzMigOg9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Movie Review Sentiment Analysis"
      ]
    },
    {
      "metadata": {
        "id": "hJRJTkHYgbNm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Header files"
      ]
    },
    {
      "metadata": {
        "id": "FhEievieSXKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BD18oPehUVrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56919fce-8858-4625-b2db-30a4e56ecac1"
      },
      "cell_type": "code",
      "source": [
        "print('Welcome to Computing Lab 2. The current PyTorch version is ', torch.__version__)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to Computing Lab 2. The current PyTorch version is  1.0.1.post2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gukcTUtThMZJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the dataset and visualize\n",
        "\n",
        "\n",
        "There are 3 ways to do this:\n",
        "\n",
        "(a)  From Github (Files < 25MB)\n",
        "\n",
        "The easiest way to upload a CSV file is from your GitHub repository. Click on the dataset in your repository, then click on View Raw. Copy the link to the raw dataset and store it as a string variable called url in Colab as shown below (a cleaner method but it’s not necessary). The last step is to load the url into Pandas read_csv to get the dataframe.\n",
        "\n",
        "\n",
        "```\n",
        "url = 'copied_raw_GH_link'\n",
        "df1 = pd.read_csv(url)\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "(b) From a local drive\n",
        "\n",
        "To upload from your local drive, start with the following code:\n",
        "\n",
        "```\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "```\n",
        "\n",
        "It will prompt you to select a file. Click on “Choose Files” then select and upload the file. Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "\n",
        "Finally, type in the following code to import it into a dataframe (make sure the filename matches the name of the uploaded file).\n",
        "```\n",
        "import io\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['Filename.csv']))\n",
        "# Dataset is now stored in a Pandas Dataframe\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "(c) From Google drive\n",
        "\n",
        "This the most complicated of the three methods. Follow this [link](https://medium.freecodecamp.org/how-to-transfer-large-files-to-google-colab-and-remote-jupyter-notebooks-26ca252892fa) to learn more."
      ]
    },
    {
      "metadata": {
        "id": "rYepeso8OiD1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/rajeshsahu09/CS69002_9A_18CS60R19/master/Dataset/check.csv?token=As1EmLNK6ueuuXJ9qHTb6sk1CQdMCZ2bks5cnkkMwA%3D%3D'\n",
        "df = pd.read_csv(url, sep='\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "J5ITVAYmiy5H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fQLFDGIQjrh-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# type(uploaded), uploaded.keys(), type(uploaded['check.csv'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o7sqK9HKoGzv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "# df = pd.read_csv(io.StringIO(uploaded['check.csv'].decode('utf-8')), sep='\\t')\n",
        "# df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n3E2eUKolVBI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Pandas\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) is a high-performance, easy-to-use data structure and data analytics tool for Python.\n",
        "\n",
        "Tutorials:\n",
        "\n",
        "*   [Link 1](https://pandas.pydata.org/pandas-docs/stable/getting_started/tutorials.html)\n",
        "*   [Link 2](https://www.tutorialspoint.com/python_pandas)\n",
        "*   [Link 3](https://www.dataquest.io/blog/pandas-python-tutorial/)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "sgLdaButozDS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f5dc732c-fd69-497f-b614-21d1d56525a1"
      },
      "cell_type": "code",
      "source": [
        "print('Number of Negative movie reviews', len(df[df['label']==0]))\n",
        "print('Number of Positive movie reviews', len(df[df['label']==1]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Negative movie reviews 246\n",
            "Number of Positive movie reviews 253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KHLUDV8ZoZLG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data pre-processing\n",
        "The first step when building a neural network model is getting your data into the proper form to feed into the network. We'll need to encode each word with an integer. We'll also want to clean it up a bit.\n",
        "\n",
        "You can use any type of pre-processing that you see fit, based on the task. For the tutorial, i will show just one pre-processing step: **lowercasing**."
      ]
    },
    {
      "metadata": {
        "id": "eafpV8pgk5kp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "8d3c1072-abf5-45b9-a900-f8521d8725e7"
      },
      "cell_type": "code",
      "source": [
        "text_reviews = df['text'].astype(str).tolist()\n",
        "text_labels = df['label'].astype(int)\n",
        "\n",
        "text_reviews = [x.lower() for x in text_reviews]\n",
        "text_reviews[0], text_labels[0]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('john waters has given us a genuinely enjoyable film. this certainly isn\\'t without its shocking waters-esque moments, but it is tamer than his older culty stuff, such as \"pink flamingoes\". \"pecker\" harkens back to john\\'s early mainstream stage in that it reminds the viewer of the same kind of humor that was evident in \"polyester\". overall, a really fun comedy with some great moments!',\n",
              " 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "s7IWD6ZXuLFc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37ca653f-0ca7-440a-c51e-22a61766db57"
      },
      "cell_type": "code",
      "source": [
        "len(text_reviews)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "499"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "HLlNt4uVv_J-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zydP-RKS0GgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating Bag Of Word (BOW) representation of sentences."
      ]
    },
    {
      "metadata": {
        "id": "COY4uTBU2OSj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_word_ids(dataset):\n",
        "  word_to_ix = {}\n",
        "  print(dataset)\n",
        "  for sent,_ in dataset:\n",
        "      for word in sent.split():\n",
        "          if word not in word_to_ix:\n",
        "              word_to_ix[word] = len(word_to_ix)\n",
        "  return word_to_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_6P4L4p2Xvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "17e2a77f-df94-45c8-ab7f-01f4230ced82"
      },
      "cell_type": "code",
      "source": [
        "generate_word_ids([['welcome to computing lab 2','1']])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['welcome to computing lab 2', '1']]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'2': 4, 'computing': 2, 'lab': 3, 'to': 1, 'welcome': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "myexGL002a65",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = [(\"me gusta comer en la cafeteria\", \"SPANISH\"),\n",
        "        (\"Give it to me\", \"ENGLISH\"),\n",
        "        (\"No creo que sea una buena idea\", \"SPANISH\"),\n",
        "        (\"No it is not a good idea to get lost at sea\", \"ENGLISH\")]\n",
        "\n",
        "test_data = [(\"Yo creo que si\", \"SPANISH\"),\n",
        "             (\"it is lost on me\", \"ENGLISH\")]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yLSUWPvg-tvm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3ebc4546-b501-4315-e556-7ecc2f5b4ec1"
      },
      "cell_type": "code",
      "source": [
        "word_to_ix = generate_word_ids(data+test_data)\n",
        "\n",
        "VOCAB_SIZE = len(word_to_ix)\n",
        "NUM_LABELS = 2\n",
        "print(VOCAB_SIZE, word_to_ix)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('me gusta comer en la cafeteria', 'SPANISH'), ('Give it to me', 'ENGLISH'), ('No creo que sea una buena idea', 'SPANISH'), ('No it is not a good idea to get lost at sea', 'ENGLISH'), ('Yo creo que si', 'SPANISH'), ('it is lost on me', 'ENGLISH')]\n",
            "26 {'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dE4gEe--uqy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Intro to PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "ShtFBLsF-ts1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "lin = nn.Linear(5,3)\n",
        "data1 = Variable(torch.randn(10,5)) # create a 10 * 5 matrix of random vars"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i_Fg0hRz_7oA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1849e024-3a37-47e1-a003-ecf25f9c1030"
      },
      "cell_type": "code",
      "source": [
        "data1, data1.size()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.4974,  0.4396, -0.7581,  1.0783,  0.8008],\n",
              "         [ 1.6806,  0.3559, -0.6866,  0.6105,  1.3347],\n",
              "         [-0.2316,  0.0418, -0.2516,  0.8599, -0.3097],\n",
              "         [-0.3957, -0.2234,  1.7174,  0.3189, -0.4245],\n",
              "         [ 0.3057, -0.7746,  0.0349,  0.3211, -0.8798],\n",
              "         [-0.6011, -1.2742,  2.1228, -1.2347, -0.4879],\n",
              "         [-1.4181,  0.8963,  0.0780,  0.5258,  0.3466],\n",
              "         [-0.1973, -1.0546,  1.2780,  0.1453,  0.2311],\n",
              "         [ 0.0087, -0.1423,  0.5750, -0.6417, -2.2064],\n",
              "         [-0.7508,  2.8140,  0.3598, -0.0898,  0.4584]]), torch.Size([10, 5]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "metadata": {
        "id": "mq7AeDVN_7lI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a28e864d-b499-44d8-988d-467cb500ba90"
      },
      "cell_type": "code",
      "source": [
        "lin(data1), lin(data1).size()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.3739,  0.1674, -0.1029],\n",
              "         [ 0.8355,  0.0414,  0.8471],\n",
              "         [ 0.2831,  0.6893, -0.1183],\n",
              "         [-0.2887,  1.0737,  0.3888],\n",
              "         [-0.0317,  0.9654, -0.0386],\n",
              "         [-1.4234,  0.7988,  0.2472],\n",
              "         [-0.0414,  0.1357, -0.2777],\n",
              "         [-0.6189,  0.8737,  0.3820],\n",
              "         [-0.2207,  0.9984, -0.2671],\n",
              "         [ 0.6052, -0.4270,  0.2221]], grad_fn=<AddmmBackward>),\n",
              " torch.Size([10, 3]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "id": "NveD4hezA8AN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6aa651ee-3b3f-4db7-935c-6ca870a07164"
      },
      "cell_type": "code",
      "source": [
        "lin.weight.size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "bI_h0ltKCf6c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**BE VERY CAREFUL WITH THE DIMENSIONS**"
      ]
    },
    {
      "metadata": {
        "id": "nfDBZ-j1C_BT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "894bf19f-8a2c-456e-91a4-d8bc30f22144"
      },
      "cell_type": "code",
      "source": [
        "F.relu(lin(data1))  # Activation Function"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3739, 0.1674, 0.0000],\n",
              "        [0.8355, 0.0414, 0.8471],\n",
              "        [0.2831, 0.6893, 0.0000],\n",
              "        [0.0000, 1.0737, 0.3888],\n",
              "        [0.0000, 0.9654, 0.0000],\n",
              "        [0.0000, 0.7988, 0.2472],\n",
              "        [0.0000, 0.1357, 0.0000],\n",
              "        [0.0000, 0.8737, 0.3820],\n",
              "        [0.0000, 0.9984, 0.0000],\n",
              "        [0.6052, 0.0000, 0.2221]], grad_fn=<ReluBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "metadata": {
        "id": "4KnJSJrwCtXV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Definition for the BOWClassifier"
      ]
    },
    {
      "metadata": {
        "id": "4120zYv8_Uvv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class BOWClassifier(nn.Module):\n",
        "  def __init__(self, num_labels, vocab_size):\n",
        "    super(BOWClassifier, self).__init__()\n",
        "    self.lin = nn.Linear(vocab_size, num_labels)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return F.softmax(self.lin(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7F1gFDZOJV3N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Generate the BOW Vectors"
      ]
    },
    {
      "metadata": {
        "id": "7kVLsLD6JQtj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_bow_vector(sentence, word_to_ix):\n",
        "    # create a vector of zeros of vocab size = len(word_to_idx)\n",
        "    vec = torch.zeros(len(word_to_ix))\n",
        "    for word in sentence.split():\n",
        "        if word not in word_to_ix:\n",
        "            raise ValueError('Word',word,' not present in the dictionary. Sorry!')\n",
        "        else:\n",
        "            vec[word_to_ix[word]]+=1\n",
        "    return vec.view(1, -1)\n",
        "\n",
        "def make_target(label, label_to_ix):\n",
        "    return torch.LongTensor([label_to_ix[label]])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wK61RhS_JotP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "bow = BOWClassifier(NUM_LABELS, VOCAB_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NzPrffWtJpo1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c98f2f8b-2a06-4182-ce11-f885ec6963a6"
      },
      "cell_type": "code",
      "source": [
        "for param in bow.parameters():\n",
        "    print(param,param.size())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1190, -0.0465,  0.1122, -0.1524, -0.0990,  0.0598,  0.0415, -0.0500,\n",
            "          0.1169,  0.1333, -0.1422, -0.1047,  0.1796, -0.0662, -0.0695, -0.1898,\n",
            "         -0.1123,  0.0490, -0.0259, -0.1424,  0.0046, -0.1340, -0.1664, -0.1080,\n",
            "         -0.1716, -0.1249],\n",
            "        [ 0.1960,  0.0370,  0.0604, -0.1829, -0.1288, -0.0653,  0.0307, -0.1726,\n",
            "         -0.0845, -0.1174,  0.0005, -0.0730, -0.0136, -0.1329, -0.1346, -0.1144,\n",
            "         -0.0671, -0.1548,  0.1644, -0.0389,  0.1687,  0.0611, -0.1661,  0.1357,\n",
            "         -0.0540, -0.0752]], requires_grad=True) torch.Size([2, 26])\n",
            "Parameter containing:\n",
            "tensor([-0.1628, -0.1950], requires_grad=True) torch.Size([2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "muH5n2PGKk5j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Let's check with a sample case how our model is working"
      ]
    },
    {
      "metadata": {
        "id": "G4_OMpkDJuDM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "62e97ac7-708d-404b-e49e-c838e505c8ad"
      },
      "cell_type": "code",
      "source": [
        "sample_data, sample_label = data[0]\n",
        "bow_vector = torch.autograd.Variable(make_bow_vector(sample_data, word_to_ix))\n",
        "logprobs = bow(bow_vector)\n",
        "print(data[0])\n",
        "print(logprobs)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('me gusta comer en la cafeteria', 'SPANISH')\n",
            "tensor([[0.5272, 0.4728]], grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DITYJwjIKust",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08a9a3b0-7f5a-4352-edd1-805c522b6163"
      },
      "cell_type": "code",
      "source": [
        "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}\n",
        "ix_to_label = {v: k for k, v in label_to_ix.items()}\n",
        "\n",
        "label_to_ix, ix_to_label"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'ENGLISH': 1, 'SPANISH': 0}, {0: 'SPANISH', 1: 'ENGLISH'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "9_AdvKxRNgY8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "c2983fb4-b862-4716-c3d9-a956f1bacde0"
      },
      "cell_type": "code",
      "source": [
        "for instance, label in test_data:\n",
        "    bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "    logprobs = bow(bow_vec)\n",
        "    print(logprobs)\n",
        "    pred = np.argmax(logprobs.data.numpy())\n",
        "    print('prediction: {}'.format(ix_to_label[pred]))\n",
        "    print('actual: {}'.format(label))\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3767, 0.6233]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: ENGLISH\n",
            "actual: SPANISH\n",
            "tensor([[0.4471, 0.5529]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: ENGLISH\n",
            "actual: ENGLISH\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "SDxwccp1Ngdm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# define a loss function and an optimizer\n",
        "loss_function = nn.NLLLoss()\n",
        "opt = torch.optim.SGD(bow.parameters(), lr = 0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1VmI9iMkODWr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "3253d40d-172f-4c43-f1a8-e7ca94385f6c"
      },
      "cell_type": "code",
      "source": [
        "# the training loop\n",
        "for epoch in range(100):\n",
        "#     print(epoch)\n",
        "    for instance, label in data:\n",
        "        # get the training data\n",
        "        bow.zero_grad()\n",
        "        bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "        label = Variable(make_target(label, label_to_ix))\n",
        "        probs = bow(bow_vec) # forward pass\n",
        "        loss = loss_function(probs, label)\n",
        "        loss.backward()\n",
        "#        print('CURRENT LOSS: {}'.format(loss.data))\n",
        "        opt.step()\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "YsfIolPXNgih",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "5ffad12b-b5b5-408a-9c21-b1fc5b7877a0"
      },
      "cell_type": "code",
      "source": [
        "print('--- AFTER TRAINING ---')\n",
        "for instance, label in test_data:\n",
        "    bow_vec = Variable(make_bow_vector(instance, word_to_ix))\n",
        "    logprobs = bow(bow_vec)\n",
        "    print(logprobs)\n",
        "    pred = np.argmax(logprobs.data.numpy())\n",
        "    print('prediction: {}'.format(ix_to_label[pred]))\n",
        "    print('actual: {}'.format(label))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- AFTER TRAINING ---\n",
            "tensor([[0.7725, 0.2275]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: SPANISH\n",
            "actual: SPANISH\n",
            "tensor([[0.0491, 0.9509]], grad_fn=<SoftmaxBackward>)\n",
            "prediction: ENGLISH\n",
            "actual: ENGLISH\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "LUAx6baDNgld",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "28dc8fbd-2741-47ad-81ee-751c1992a140"
      },
      "cell_type": "code",
      "source": [
        "torch.save(bow,'model.json')\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"model.json\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type BOWClassifier. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "kt0wHhXjNgoZ",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "d219b7df-a08f-4e0d-c6cf-9ceca4319765"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "temp_test = files.upload()\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edb4b834-68cc-4893-ad34-ff3d9f5b43fc\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-edb4b834-68cc-4893-ad34-ff3d9f5b43fc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model.json to model (1).json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vGYbYaIsy6Iw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9bd72e72-4928-40b7-d85f-5de66eb9c5a2"
      },
      "cell_type": "code",
      "source": [
        "torch.load(io.BytesIO(temp_test['model.json']))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BOWClassifier(\n",
              "  (lin): Linear(in_features=26, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "m9i8PVtgz0NS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}